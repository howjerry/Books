# 第 12 章：自動化評估與 A/B 測試——科學化的系統優化

> **本章任務：** 建立自動化的 RAG 測試框架，支援版本對比與 A/B 測試。

---

## 學習目標

完成本章後，你將能夠：

- [ ] 建立標準化的 RAG 測試集
- [ ] 實作多維度的自動化評估（Precision@K、MRR、幻覺率等）
- [ ] 執行科學的 A/B 測試並分析統計顯著性
- [ ] 設計回歸測試防止效能退化
- [ ] 將評估整合到 CI/CD 流程

---

## 核心產出物

- `test_set.json` - 標準化測試集格式
- `evaluation_framework.py` - 自動化評估框架
- `ab_tester.py` - A/B 測試執行器
- `ci_evaluation.yml` - CI/CD 評估整合設定

---

## 章節內容

<!-- TODO: 撰寫完整章節內容 -->

### 12.1 評估測試集設計

### 12.2 檢索階段評估指標

### 12.3 生成階段評估指標

### 12.4 實作自動化評估框架

### 12.5 A/B 測試設計

### 12.6 統計顯著性分析

### 12.7 回歸測試與 CI/CD 整合

### 12.8 本章小結

---

## 下一步

評估框架就緒後，我們將在第 13 章建立完整的持續學習 Pipeline，讓系統能夠自動進化。
