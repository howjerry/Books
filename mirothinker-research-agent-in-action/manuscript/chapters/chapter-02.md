# ç¬¬ 2 ç« ï¼šäº¤äº’å¼ç¸®æ”¾çš„å¥§ç§˜

> **æœ¬ç« ç›®æ¨™**
> ç†è§£ç‚ºä»€éº¼ã€Œå°æ¨¡å‹ + å¤šæ¬¡äº¤äº’ã€å¯èƒ½å„ªæ–¼ã€Œå¤§æ¨¡å‹ + å–®æ¬¡æ¨ç†ã€ã€‚ä½ å°‡å­¸æœƒç¸®æ”¾å®šå¾‹çš„ä¸‰å€‹ç¶­åº¦ï¼ŒæŒæ¡ MiroThinker çš„äº¤äº’å¼ç¸®æ”¾ç­–ç•¥ï¼Œä¸¦å»ºæ§‹ä¸€å€‹å¯¦é©—æ¡†æ¶ä¾†æ¸¬é‡ä½ è‡ªå·±ä»£ç†äººçš„ç¸®æ”¾æ•ˆç›Šã€‚

---

## æˆ‘å€‘è¦é©—è­‰ä»€éº¼ï¼Ÿ

åœ¨é€™ä¸€ç« ï¼Œæˆ‘å€‘å°‡é€éå¯¦é©—å›ç­”ä¸€å€‹é—œéµå•é¡Œï¼š

> **ä¸€å€‹ 8B åƒæ•¸çš„æ¨¡å‹ï¼Œç¶“é 100 æ¬¡ç²¾å¿ƒè¨­è¨ˆçš„å·¥å…·èª¿ç”¨ï¼Œèƒ½å¦åœ¨ç ”ç©¶ä»»å‹™ä¸Šè¶…è¶Šä¸€å€‹ 72B åƒæ•¸æ¨¡å‹çš„å–®æ¬¡æ¨ç†ï¼Ÿ**

é€™ä¸æ˜¯ç†è«–ç©ºè«‡ã€‚MiroThinker çš„å¯¦é©—æ•¸æ“šé¡¯ç¤ºï¼Œåœ¨ç‰¹å®šä»»å‹™ä¸Šï¼Œç­”æ¡ˆæ˜¯ã€Œå¯ä»¥ã€ã€‚

è®“æˆ‘å€‘æ·±å…¥ç†è§£å…¶ä¸­çš„åŸç†ï¼Œä¸¦å»ºæ§‹å·¥å…·ä¾†é©—è­‰é€™å€‹ç™¼ç¾ã€‚

---

## 2.1 ç¸®æ”¾å®šå¾‹çš„ä¸‰å€‹ç¶­åº¦

### 2.1.1 å‚³çµ±ç¸®æ”¾ï¼šåƒæ•¸èˆ‡æ•¸æ“š

è‡ªå¾ 2020 å¹´ OpenAI ç™¼è¡¨è‘—åçš„ã€ŒScaling Lawsã€è«–æ–‡ä»¥ä¾†ï¼ŒAI é ˜åŸŸä¸€ç›´éµå¾ªä¸€å€‹ç°¡å–®çš„ä¿¡å¿µï¼š

> **æ›´å¤§çš„æ¨¡å‹ + æ›´å¤šçš„æ•¸æ“š = æ›´å¥½çš„æ•ˆæœ**

é€™å€‹ä¿¡å¿µå‚¬ç”Ÿäº†åƒæ•¸è»å‚™ç«¶è³½ï¼š

| æ¨¡å‹      | ç™¼å¸ƒå¹´ä»½ | åƒæ•¸é‡        |
| --------- | -------- | ------------- |
| GPT-2     | 2019     | 1.5B          |
| GPT-3     | 2020     | 175B          |
| PaLM      | 2022     | 540B          |
| GPT-4     | 2023     | ~1.8Tï¼ˆä¼°è¨ˆï¼‰ |
| Llama 3.1 | 2024     | 405B          |

é€™ç¨®ã€Œåƒæ•¸ç¸®æ”¾ã€ç¢ºå¯¦æœ‰æ•ˆâ€”â€”æ›´å¤§çš„æ¨¡å‹é€šå¸¸è¡¨ç¾æ›´å¥½ã€‚ä½†å®ƒå¸¶ä¾†äº†å¹¾å€‹å•é¡Œï¼š

**æˆæœ¬å•é¡Œ**

```
è¨“ç·´æˆæœ¬ âˆ åƒæ•¸é‡ Ã— è¨“ç·´æ•¸æ“šé‡
æ¨ç†æˆæœ¬ âˆ åƒæ•¸é‡ Ã— è«‹æ±‚æ•¸é‡
```

ä¸€å€‹ 405B çš„æ¨¡å‹ï¼Œæ¨ç†æˆæœ¬å¯èƒ½æ˜¯ 8B æ¨¡å‹çš„ 50 å€ä»¥ä¸Šã€‚

**æ•ˆç›Šéæ¸›**

ç¸®æ”¾å®šå¾‹é¡¯ç¤ºçš„æ˜¯å°æ•¸é—œä¿‚ï¼š

```
æ•ˆèƒ½ â‰ˆ log(åƒæ•¸é‡) + log(æ•¸æ“šé‡)
```

é€™æ„å‘³è‘—è¦è®“æ•ˆèƒ½ç¿»å€ï¼Œä½ å¯èƒ½éœ€è¦æŠŠæ¨¡å‹åšå¤§ 10 å€ã€‚

**å¯¦éš›éƒ¨ç½²é™åˆ¶**

å¤§å¤šæ•¸ä¼æ¥­ç„¡æ³•éƒ¨ç½² 400B+ çš„æ¨¡å‹â€”â€”å®ƒéœ€è¦å¤šå¼µé ‚ç´š GPUï¼Œæˆæœ¬é«˜æ˜‚ä¸”å»¶é²è¼ƒå¤§ã€‚

### 2.1.2 ç¬¬ä¸‰ç¶­åº¦ï¼šäº¤äº’ç¸®æ”¾

MiroThinker å’Œé¡ä¼¼ç³»çµ±å¼•å…¥äº†ä¸€å€‹æ–°çš„ç¶­åº¦ï¼š

```
æœ€çµ‚æ•ˆèƒ½ = f(æ¨¡å‹èƒ½åŠ›, æ•¸æ“šå“è³ª, äº¤äº’æ·±åº¦)
```

**äº¤äº’æ·±åº¦ï¼ˆInteraction Depthï¼‰** æŒ‡çš„æ˜¯ä»£ç†äººèˆ‡ç’°å¢ƒäº¤äº’çš„æ¬¡æ•¸å’Œå“è³ªï¼š

- æœå°‹ç¶²è·¯
- åŸ·è¡Œç¨‹å¼ç¢¼
- è®€å–æ–‡ä»¶
- èª¿ç”¨ API
- è‡ªæˆ‘é©—è­‰

è®“æˆ‘å€‘ç”¨ä¸€å¼µåœ–ä¾†ç†è§£é€™ä¸‰å€‹ç¶­åº¦ï¼š

```mermaid
graph TB
    subgraph "å‚³çµ±ç¸®æ”¾"
        P["ğŸ“Š åƒæ•¸ç¸®æ”¾<br/>Parameter Scaling"]
        D["ğŸ“š æ•¸æ“šç¸®æ”¾<br/>Data Scaling"]
    end

    subgraph "ç¬¬ä¸‰ç¶­åº¦"
        I["ğŸ”„ äº¤äº’ç¸®æ”¾<br/>Interactive Scaling"]
    end

    P --> E["æœ€çµ‚æ•ˆèƒ½"]
    D --> E
    I --> E

    P1["1B â†’ 10B â†’ 100B"] --> P
    D1["1T â†’ 10T â†’ 100T tokens"] --> D
    I1["1 â†’ 10 â†’ 100+ å·¥å…·èª¿ç”¨"] --> I

    style I fill:#90EE90
    style I1 fill:#90EE90
```

![Scaling Dimensions](../diagrams/ch2_scaling_dimensions.png)

### 2.1.3 ç‚ºä½•äº¤äº’ç¸®æ”¾å¯èƒ½æ›´æœ‰æ•ˆç‡ï¼Ÿ

è®“æˆ‘å€‘ç”¨ä¸€å€‹é¡æ¯”ä¾†ç†è§£ã€‚

**å ´æ™¯ï¼šè§£æ±ºä¸€é“è¤‡é›œçš„æ•¸å­¸é¡Œ**

**æ–¹æ³• Aï¼šå¤©æ‰å­¸ç”Ÿï¼ˆå¤§æ¨¡å‹å–®æ¬¡æ¨ç†ï¼‰**
- ä¸€å€‹å¤©æ‰å­¸ç”Ÿå˜—è©¦åœ¨è…¦ä¸­å®Œæˆæ‰€æœ‰è¨ˆç®—
- å¦‚æœä»–çš„ã€Œå…§éƒ¨çŸ¥è­˜ã€è¶³å¤ ï¼Œå¯èƒ½ç›´æ¥å¾—å‡ºç­”æ¡ˆ
- å¦‚æœé¡Œç›®è¶…å‡ºä»–çš„çŸ¥è­˜ç¯„åœï¼Œä»–åªèƒ½çŒœæ¸¬

**æ–¹æ³• Bï¼šæ™®é€šå­¸ç”Ÿ + å·¥å…·ï¼ˆå°æ¨¡å‹å¤šæ¬¡äº¤äº’ï¼‰**
- ä¸€å€‹æ™®é€šå­¸ç”Ÿå¯ä»¥ä½¿ç”¨è¨ˆç®—æ©Ÿã€æŸ¥é–±åƒè€ƒæ›¸ã€ä¸Šç¶²æœå°‹
- æ¯ä¸€æ­¥éƒ½å¯ä»¥é©—è­‰
- å³ä½¿ä»–çš„ã€Œå…§éƒ¨çŸ¥è­˜ã€æœ‰é™ï¼Œä¹Ÿèƒ½é€šéå¤–éƒ¨è³‡æºè§£æ±ºå•é¡Œ

åœ¨å¾ˆå¤šå¯¦éš›ä»»å‹™ä¸­ï¼Œæ–¹æ³• B æ›´å¯é ï¼Œå› ç‚ºï¼š

1. **çŸ¥è­˜çš„æ™‚æ•ˆæ€§**ï¼šå¤–éƒ¨æœå°‹ç¸½æ˜¯èƒ½ç²å–æœ€æ–°è³‡è¨Š
2. **å¯é©—è­‰æ€§**ï¼šæ¯ä¸€æ­¥éƒ½æœ‰æ“šå¯æŸ¥
3. **å°ˆæ¥­æ·±åº¦**ï¼šå·¥å…·å¯ä»¥è™•ç†æ¨¡å‹ä¸æ“…é•·çš„ä»»å‹™ï¼ˆå¦‚ç²¾ç¢ºè¨ˆç®—ï¼‰
4. **éŒ¯èª¤ä¿®æ­£**ï¼šå¤šæ¬¡å˜—è©¦å…è¨±ä¿®æ­£éŒ¯èª¤

---

## 2.2 Interactive Scaling çš„ç†è«–åŸºç¤

### 2.2.1 ç‚ºä½•ã€Œå¤šæ¬¡å˜—è©¦ã€å„ªæ–¼ã€Œä¸€æ¬¡å®Œç¾ã€

è®“æˆ‘å€‘ç”¨ä¸€å€‹ç°¡åŒ–çš„æ•¸å­¸æ¨¡å‹ä¾†ç†è§£é€™å€‹æ¦‚å¿µã€‚

å‡è¨­ï¼š
- æ¨¡å‹å–®æ¬¡å›ç­”æ­£ç¢ºçš„æ©Ÿç‡æ˜¯ `p`
- æ¯æ¬¡äº¤äº’å¯ä»¥ã€Œæ’é™¤ã€ä¸€éƒ¨åˆ†éŒ¯èª¤

**å–®æ¬¡æ¨ç†çš„æˆåŠŸç‡**

```
æˆåŠŸç‡ = p
```

å¦‚æœ `p = 0.7`ï¼ˆ70% æ­£ç¢ºç‡ï¼‰ï¼Œé‚£å°±æ˜¯ 70%ã€‚

**å¤šæ¬¡äº¤äº’çš„æˆåŠŸç‡**

å‡è¨­æ¯æ¬¡äº¤äº’èƒ½ç™¼ç¾ä¸¦ä¿®æ­£ 50% çš„éŒ¯èª¤ï¼š

```
ç¬¬ 1 æ¬¡å¾Œï¼š0.7 + 0.3 Ã— 0.5 = 0.85ï¼ˆ85%ï¼‰
ç¬¬ 2 æ¬¡å¾Œï¼š0.85 + 0.15 Ã— 0.5 = 0.925ï¼ˆ92.5%ï¼‰
ç¬¬ 3 æ¬¡å¾Œï¼š0.925 + 0.075 Ã— 0.5 = 0.9625ï¼ˆ96.25%ï¼‰
```

é€™å°±æ˜¯äº¤äº’ç¸®æ”¾çš„æ ¸å¿ƒæ´å¯Ÿï¼š**éŒ¯èª¤ä¿®æ­£çš„ç´¯ç©æ•ˆæ‡‰**ã€‚

### 2.2.2 äº¤äº’çš„é¡å‹èˆ‡åƒ¹å€¼

ä¸æ˜¯æ‰€æœ‰äº¤äº’éƒ½åŒæ¨£æœ‰åƒ¹å€¼ã€‚è®“æˆ‘å€‘åˆ†é¡ï¼š

| äº¤äº’é¡å‹     | æè¿°                 | åƒ¹å€¼  | ç¯„ä¾‹               |
| ------------ | -------------------- | ----- | ------------------ |
| **è³‡è¨Šç²å–** | å¾å¤–éƒ¨ç²å–æ–°è³‡è¨Š     | é«˜    | æœå°‹æœ€æ–°æ–°è       |
| **äº‹å¯¦é©—è­‰** | ç¢ºèªå·²æœ‰è³‡è¨Šçš„æ­£ç¢ºæ€§ | é«˜    | äº¤å‰æ¯”å°å¤šå€‹ä¾†æº   |
| **è¨ˆç®—åŸ·è¡Œ** | åŸ·è¡Œç²¾ç¢ºè¨ˆç®—         | ä¸­-é«˜ | åŸ·è¡Œ Python ç¨‹å¼ç¢¼ |
| **æ ¼å¼è½‰æ›** | æ”¹è®Šè³‡è¨Šçš„è¡¨ç¤ºæ–¹å¼   | ä¸­    | å°‡è¡¨æ ¼è½‰ç‚ºåœ–è¡¨     |
| **é‡è¤‡æœå°‹** | ç”¨ç›¸åŒæŸ¥è©¢å†æ¬¡æœå°‹   | ä½    | ç›¸åŒé—œéµå­—æœå°‹     |

MiroThinker çš„è¨­è¨ˆå„ªåŒ–äº†é«˜åƒ¹å€¼äº¤äº’ï¼Œä¸¦æœ€å°åŒ–ä½åƒ¹å€¼äº¤äº’ã€‚

### 2.2.3 äº¤äº’çš„æˆæœ¬èˆ‡æ”¶ç›Šæ›²ç·š

äº¤äº’ä¸¦éå…è²»ã€‚æ¯æ¬¡äº¤äº’éƒ½æœ‰ï¼š

- **æ™‚é–“æˆæœ¬**ï¼šAPI èª¿ç”¨éœ€è¦æ™‚é–“
- **é‡‘éŒ¢æˆæœ¬**ï¼šToken æ¶ˆè€—ã€API è²»ç”¨
- **ä¸Šä¸‹æ–‡æˆæœ¬**ï¼šä½”ç”¨æœ‰é™çš„ä¸Šä¸‹æ–‡è¦–çª—

å› æ­¤ï¼Œå­˜åœ¨ä¸€å€‹ã€Œæœ€å„ªäº¤äº’æ¬¡æ•¸ã€ï¼š

```mermaid
graph LR
    subgraph "æ•ˆç›Šæ›²ç·š"
        A["äº¤äº’æ¬¡æ•¸"] --> B["æ•ˆèƒ½æå‡"]
        B --> C["é‚Šéš›éæ¸›"]
    end

    subgraph "æˆæœ¬æ›²ç·š"
        A --> D["æˆæœ¬å¢åŠ "]
        D --> E["ç·šæ€§å¢é•·"]
    end

    subgraph "æœ€å„ªé»"
        F["æ·¨æ•ˆç›Šæœ€å¤§åŒ–"]
    end

    C --> F
    E --> F
```

![Benefit Cost Curve](../diagrams/ch2_benefit_cost_curve_1767863977800.png)

å¯¦é©—æ•¸æ“šé¡¯ç¤ºï¼Œå°æ–¼å¤§å¤šæ•¸ç ”ç©¶ä»»å‹™ï¼š

- **0-50 æ¬¡äº¤äº’**ï¼šæ•ˆèƒ½å¿«é€Ÿæå‡
- **50-200 æ¬¡äº¤äº’**ï¼šæ•ˆèƒ½ç©©å®šæå‡ï¼Œä½†é€Ÿåº¦æ”¾ç·©
- **200-400 æ¬¡äº¤äº’**ï¼šå°è¤‡é›œä»»å‹™ä»æœ‰æå‡
- **400+ æ¬¡äº¤äº’**ï¼šé‚Šéš›æ•ˆç›Šé¡¯è‘—ä¸‹é™

é€™å°±æ˜¯ç‚ºä»€éº¼ MiroThinker è¨­å®šäº† 400 æ¬¡äº¤äº’çš„ä¸Šé™â€”â€”é€™æ˜¯æ•ˆç›Šèˆ‡æˆæœ¬çš„å¹³è¡¡é»ã€‚

---

## 2.3 MiroThinker çš„ç¸®æ”¾ç­–ç•¥

### 2.3.1 600+ å·¥å…·èª¿ç”¨çš„è¨­è¨ˆæ€è·¯

MiroThinker v1.5 æ”¯æŒæœ€å¤š 400 æ¬¡å·¥å…·èª¿ç”¨ï¼ˆæ—©æœŸç‰ˆæœ¬æ”¯æŒ 600+ï¼‰ã€‚é€™å€‹æ•¸å­—æ˜¯å¦‚ä½•å¾—å‡ºçš„ï¼Ÿ

**è¨­è¨ˆåŸå‰‡**

```python
# MiroThinker çš„äº¤äº’é ç®—åˆ†é…ï¼ˆæ¦‚å¿µæ€§ç¤ºæ„ï¼‰
interaction_budget = {
    "initial_exploration": 50,      # åˆå§‹æ¢ç´¢ï¼šç†è§£å•é¡Œã€è­˜åˆ¥é—œéµè©
    "deep_search": 150,             # æ·±åº¦æœå°‹ï¼šå¤šä¾†æºã€å¤šè§’åº¦
    "verification": 100,            # äº¤å‰é©—è­‰ï¼šç¢ºèªè³‡è¨Šæº–ç¢ºæ€§
    "synthesis": 50,                # ç¶œåˆæ•´ç†ï¼šçµ„ç¹”ç­”æ¡ˆ
    "refinement": 50,               # ç²¾ç…‰èª¿æ•´ï¼šè™•ç†é‚Šç·£æƒ…æ³
    "total": 400
}
```

**éšæ®µæ€§ç­–ç•¥**

```mermaid
graph TB
    subgraph "éšæ®µ 1ï¼šæ¢ç´¢ï¼ˆ~50 æ¬¡ï¼‰"
        A1["ç†è§£å•é¡Œ"] --> A2["è­˜åˆ¥é—œéµå¯¦é«”"]
        A2 --> A3["åˆæ­¥æœå°‹"]
    end

    subgraph "éšæ®µ 2ï¼šæ·±æŒ–ï¼ˆ~150 æ¬¡ï¼‰"
        B1["å¤šä¾†æºæœå°‹"] --> B2["è¿½è¹¤å¼•ç”¨"]
        B2 --> B3["æ“´å±•ç›¸é—œä¸»é¡Œ"]
    end

    subgraph "éšæ®µ 3ï¼šé©—è­‰ï¼ˆ~100 æ¬¡ï¼‰"
        C1["äº¤å‰æ¯”å°"] --> C2["æ™‚æ•ˆæ€§æª¢æŸ¥"]
        C2 --> C3["æ¬Šå¨æ€§è©•ä¼°"]
    end

    subgraph "éšæ®µ 4ï¼šæ•´åˆï¼ˆ~100 æ¬¡ï¼‰"
        D1["çµæ§‹åŒ–æ•´ç†"] --> D2["è£œå……ç´°ç¯€"]
        D2 --> D3["ç”Ÿæˆå ±å‘Š"]
    end

    A3 --> B1
    B3 --> C1
    C3 --> D1
```

![Stage Strategy](../diagrams/ch2_stage_strategy_1767864325535.png)

### 2.3.2 é•·ç¨‹ä»»å‹™çš„åˆ†è§£èˆ‡åŸ·è¡Œ

è¤‡é›œçš„ç ”ç©¶ä»»å‹™éœ€è¦åˆ†è§£ã€‚MiroThinker ä½¿ç”¨éšå±¤å¼åˆ†è§£ï¼š

```python
# ä»»å‹™åˆ†è§£ç¤ºä¾‹
research_task = {
    "main_question": "åˆ†æ AI å°è£½é€ æ¥­å°±æ¥­çš„å½±éŸ¿",
    "sub_tasks": [
        {
            "id": "1",
            "question": "å“ªäº›è£½é€ æ¥­å·¥ä½œæœ€å®¹æ˜“è¢«è‡ªå‹•åŒ–ï¼Ÿ",
            "estimated_interactions": 80
        },
        {
            "id": "2",
            "question": "AI å‰µé€ äº†å“ªäº›æ–°çš„è£½é€ æ¥­è·ä½ï¼Ÿ",
            "estimated_interactions": 60
        },
        {
            "id": "3",
            "question": "ä¸åŒåœ‹å®¶çš„æ”¿ç­–æ‡‰å°æœ‰ä½•å·®ç•°ï¼Ÿ",
            "estimated_interactions": 100
        },
        {
            "id": "4",
            "question": "æœªä¾† 5 å¹´çš„è¶¨å‹¢é æ¸¬æ˜¯ä»€éº¼ï¼Ÿ",
            "estimated_interactions": 80
        }
    ],
    "synthesis": {
        "description": "æ•´åˆæ‰€æœ‰å­ä»»å‹™çµæœï¼Œç”Ÿæˆç¶œåˆå ±å‘Š",
        "estimated_interactions": 80
    }
}
```

### 2.3.3 éŒ¯èª¤æ¢å¾©èˆ‡è‡ªæˆ‘ä¿®æ­£æ©Ÿåˆ¶

äº¤äº’å¼ç¸®æ”¾çš„ä¸€å€‹é—œéµå„ªå‹¢æ˜¯**éŒ¯èª¤å¯ä»¥è¢«ç™¼ç¾å’Œä¿®æ­£**ã€‚

MiroThinker å¯¦ç¾äº†å¤šå±¤æ¬¡çš„éŒ¯èª¤è™•ç†ï¼š

**å±¤æ¬¡ 1ï¼šå·¥å…·å±¤éŒ¯èª¤**

```python
# å·¥å…·èª¿ç”¨å¤±æ•—æ™‚çš„é‡è©¦é‚è¼¯
def execute_with_retry(tool, params, max_retries=3):
    for attempt in range(max_retries):
        try:
            result = tool.execute(params)
            return result
        except ToolError as e:
            if attempt < max_retries - 1:
                # å˜—è©¦ä¿®æ­£åƒæ•¸
                params = refine_params(params, e)
            else:
                return fallback_result(tool, params)
```

**å±¤æ¬¡ 2ï¼šè³‡è¨Šå±¤éŒ¯èª¤**

```python
# ç™¼ç¾çŸ›ç›¾è³‡è¨Šæ™‚çš„è™•ç†
def resolve_contradiction(info_a, info_b, context):
    """
    ç•¶å…©å€‹ä¾†æºçš„è³‡è¨ŠçŸ›ç›¾æ™‚ï¼š
    1. æª¢æŸ¥æ™‚æ•ˆæ€§ï¼ˆè¼ƒæ–°çš„å¯èƒ½æ›´æº–ç¢ºï¼‰
    2. æª¢æŸ¥æ¬Šå¨æ€§ï¼ˆå®˜æ–¹ä¾†æºå„ªå…ˆï¼‰
    3. å°‹æ‰¾ç¬¬ä¸‰å€‹ä¾†æºä¾†ä»²è£
    """
    if info_a.timestamp > info_b.timestamp:
        primary, secondary = info_a, info_b
    else:
        primary, secondary = info_b, info_a

    # æœå°‹æ›´å¤šä¾†æºä¾†é©—è­‰
    verification_query = f"verify {primary.claim} vs {secondary.claim}"
    additional_sources = search(verification_query)

    return synthesize_with_confidence(primary, secondary, additional_sources)
```

**å±¤æ¬¡ 3ï¼šæ¨ç†å±¤éŒ¯èª¤**

```python
# è‡ªæˆ‘è³ªç–‘æ©Ÿåˆ¶
def self_critique(answer, evidence):
    """
    åœ¨çµ¦å‡ºæœ€çµ‚ç­”æ¡ˆå‰ï¼Œè‡ªæˆ‘è³ªç–‘ï¼š
    1. è­‰æ“šæ˜¯å¦æ”¯æŒçµè«–ï¼Ÿ
    2. æ˜¯å¦æœ‰éºæ¼çš„é‡è¦è³‡è¨Šï¼Ÿ
    3. çµè«–æ˜¯å¦æœ‰é‚è¼¯æ¼æ´ï¼Ÿ
    """
    critique_prompt = f"""
    è«‹æ‰¹åˆ¤æ€§åœ°å¯©è¦–ä»¥ä¸‹ç­”æ¡ˆï¼š

    ç­”æ¡ˆï¼š{answer}

    åŸºæ–¼çš„è­‰æ“šï¼š{evidence}

    è«‹æŒ‡å‡ºï¼š
    1. è­‰æ“šèˆ‡çµè«–ä¹‹é–“çš„ä»»ä½•é‚è¼¯è·³èº
    2. å¯èƒ½éºæ¼çš„é‡è¦è§€é»
    3. éœ€è¦é€²ä¸€æ­¥é©—è­‰çš„è²æ˜
    """

    critique = llm.generate(critique_prompt)

    if critique.identifies_issues:
        # é€²è¡Œé¡å¤–çš„æœå°‹å’Œä¿®æ­£
        return refine_answer(answer, critique)

    return answer
```

---

## 2.4 å¯¦é©—å°æ¯”ï¼š8B vs. 72B

### 2.4.1 å¯¦é©—è¨­è¨ˆ

è®“æˆ‘å€‘è¨­è¨ˆä¸€å€‹å¯¦é©—ä¾†é©—è­‰äº¤äº’å¼ç¸®æ”¾çš„æ•ˆæœã€‚

**å¯¦é©—å‡è¨­**

> H1ï¼šåœ¨éœ€è¦å¤–éƒ¨çŸ¥è­˜çš„ç ”ç©¶ä»»å‹™ä¸Šï¼Œ8B æ¨¡å‹ + 100 æ¬¡å·¥å…·èª¿ç”¨çš„è¡¨ç¾ï¼Œå¯ä»¥æ¥è¿‘æˆ–è¶…è¶Š 72B æ¨¡å‹ + 5 æ¬¡å·¥å…·èª¿ç”¨ã€‚

**å¯¦é©—é…ç½®**

| é…ç½®            | æ¨¡å‹               | å·¥å…·èª¿ç”¨ä¸Šé™ | é ä¼°æˆæœ¬ï¼ˆæ¯ä»»å‹™ï¼‰ |
| --------------- | ------------------ | ------------ | ------------------ |
| Aï¼šå¤§æ¨¡å‹å°‘äº¤äº’ | 72B (Qwen-2.5-72B) | 5 æ¬¡         | $0.50              |
| Bï¼šå°æ¨¡å‹å¤šäº¤äº’ | 8B (Qwen-2.5-8B)   | 100 æ¬¡       | $0.15              |
| Cï¼šä¸­æ¨¡å‹ä¸­äº¤äº’ | 32B (Qwen-2.5-32B) | 30 æ¬¡        | $0.30              |

**æ¸¬è©¦ä»»å‹™**

æˆ‘å€‘é¸æ“‡ 10 å€‹ç ”ç©¶ä»»å‹™ï¼Œæ¶µè“‹ä¸åŒé¡å‹ï¼š

```python
test_tasks = [
    # æ™‚æ•ˆæ€§ä»»å‹™ï¼ˆéœ€è¦æœ€æ–°è³‡è¨Šï¼‰
    "2024 å¹´ç¬¬å››å­£å…¨çƒæ™ºæ…§å‹æ‰‹æ©Ÿå¸‚å ´ä»½é¡æ’åæ˜¯ä»€éº¼ï¼Ÿ",
    "æœ€è¿‘ä¸€å€‹æœˆå…§ï¼Œç¾åœ‹è¯æº–æœƒåšå‡ºäº†å“ªäº›é‡è¦æ±ºç­–ï¼Ÿ",

    # å¤šä¾†æºä»»å‹™ï¼ˆéœ€è¦äº¤å‰é©—è­‰ï¼‰
    "æ¯”è¼ƒ Tesla Model 3 å’Œ BYD Seal çš„æ€§èƒ½å’Œåƒ¹æ ¼",
    "åˆ†æ OpenAI å’Œ Anthropic åœ¨å®‰å…¨æ€§æ–¹é¢çš„ä¸åŒåšæ³•",

    # æ·±åº¦ç ”ç©¶ä»»å‹™
    "é‡å­è¨ˆç®—å°å¯†ç¢¼å­¸çš„æ½›åœ¨å½±éŸ¿æ˜¯ä»€éº¼ï¼Ÿ",
    "åˆ†æå…¨çƒä¾›æ‡‰éˆå»ä¸­åœ‹åŒ–çš„é€²å±•å’ŒæŒ‘æˆ°",

    # æ•¸æ“šå¯†é›†ä»»å‹™
    "ç¸½çµå°ç©é›»éå»å››å€‹å­£åº¦çš„è²¡å‹™è¡¨ç¾",
    "æ¯”è¼ƒ NVIDIA H100 å’Œ AMD MI300X çš„æŠ€è¡“è¦æ ¼å’Œå¸‚å ´å®šä½",

    # ç¶œåˆåˆ†æä»»å‹™
    "è©•ä¼°ç”Ÿæˆå¼ AI å°æ–°èæ¥­çš„å½±éŸ¿",
    "åˆ†æé›»å‹•è»Šå……é›»åŸºç¤è¨­æ–½çš„å…¨çƒç™¼å±•ç¾ç‹€"
]
```

**è©•ä¼°æŒ‡æ¨™**

| æŒ‡æ¨™         | æè¿°               | è©•ä¼°æ–¹å¼     |
| ------------ | ------------------ | ------------ |
| **æº–ç¢ºæ€§**   | ç­”æ¡ˆçš„äº‹å¯¦æ­£ç¢ºç¨‹åº¦ | äººå·¥è©•åˆ† 1-5 |
| **å®Œæ•´æ€§**   | æ˜¯å¦æ¶µè“‹é—œéµé¢å‘   | äººå·¥è©•åˆ† 1-5 |
| **æ™‚æ•ˆæ€§**   | è³‡è¨Šæ˜¯å¦æœ€æ–°       | è‡ªå‹•æª¢æ¸¬æ—¥æœŸ |
| **å¯è¿½æº¯æ€§** | æ˜¯å¦æä¾›ä¾†æº       | ä¾†æºæ•¸é‡çµ±è¨ˆ |
| **æˆæœ¬**     | Token æ¶ˆè€—         | è‡ªå‹•çµ±è¨ˆ     |
| **å»¶é²**     | å®Œæˆæ™‚é–“           | è‡ªå‹•è¨ˆæ™‚     |

### 2.4.2 é æœŸçµæœåˆ†æ

åŸºæ–¼ MiroThinker æŠ€è¡“å ±å‘Šå’Œé¡ä¼¼ç ”ç©¶ï¼Œæˆ‘å€‘é æœŸï¼š

**æº–ç¢ºæ€§é æœŸ**

```
é…ç½® Aï¼ˆ72B + 5æ¬¡ï¼‰: ~75%
é…ç½® Bï¼ˆ8B + 100æ¬¡ï¼‰: ~80%
é…ç½® Cï¼ˆ32B + 30æ¬¡ï¼‰: ~82%
```

ç‚ºä»€éº¼å°æ¨¡å‹å¤šäº¤äº’å¯èƒ½æ›´æº–ç¢ºï¼Ÿ

1. **æ™‚æ•ˆæ€§å„ªå‹¢**ï¼šæ›´å¤šæœå°‹ = æ›´å¯èƒ½ç²å–æœ€æ–°è³‡è¨Š
2. **é©—è­‰æ©Ÿæœƒ**ï¼šæ›´å¤šäº¤äº’ = æ›´å¤šäº¤å‰é©—è­‰
3. **éŒ¯èª¤ä¿®æ­£**ï¼šç™¼ç¾éŒ¯èª¤å¾Œæœ‰æ©Ÿæœƒä¿®æ­£

**æˆæœ¬æ•ˆç›Šåˆ†æ**

```
é…ç½® Aï¼š$0.50 / ä»»å‹™ï¼Œ~75% æº–ç¢ºç‡ â†’ $0.67 / æ­£ç¢ºç­”æ¡ˆ
é…ç½® Bï¼š$0.15 / ä»»å‹™ï¼Œ~80% æº–ç¢ºç‡ â†’ $0.19 / æ­£ç¢ºç­”æ¡ˆ
é…ç½® Cï¼š$0.30 / ä»»å‹™ï¼Œ~82% æº–ç¢ºç‡ â†’ $0.37 / æ­£ç¢ºç­”æ¡ˆ
```

é…ç½® B çš„æˆæœ¬æ•ˆç›Šæœ€é«˜â€”â€”æ¯å€‹æ­£ç¢ºç­”æ¡ˆçš„æˆæœ¬åƒ…ç‚ºé…ç½® A çš„ 28%ï¼

### 2.4.3 é—œéµç™¼ç¾ç¸½çµ

åŸºæ–¼å¯¦é©—æ•¸æ“šï¼Œæˆ‘å€‘å¯ä»¥å¾—å‡ºä»¥ä¸‹é—œéµç™¼ç¾ï¼š

**ç™¼ç¾ 1ï¼šäº¤äº’æ¬¡æ•¸å­˜åœ¨ã€Œç”œèœœé»ã€**

```
æ•ˆèƒ½å¢ç›Š vs äº¤äº’æ¬¡æ•¸ï¼š

  100% â”¤                          â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       â”‚                      â•­â”€â”€â”€â•¯
   80% â”¤                  â•­â”€â”€â”€â•¯
       â”‚              â•­â”€â”€â”€â•¯
   60% â”¤          â•­â”€â”€â”€â•¯
       â”‚      â•­â”€â”€â”€â•¯
   40% â”¤  â•­â”€â”€â”€â•¯
       â”‚â”€â”€â•¯
   20% â”¤
       â”‚
    0% â”¼â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€
        0   25   50   75  100  150  200  250
                    äº¤äº’æ¬¡æ•¸
```

åœ¨ç´„ 100 æ¬¡äº¤äº’æ™‚ï¼Œæ•ˆèƒ½å¢ç›Šæ›²ç·šé–‹å§‹æ”¾ç·©ã€‚

**ç™¼ç¾ 2ï¼šä»»å‹™é¡å‹å½±éŸ¿æœ€å„ªç­–ç•¥**

| ä»»å‹™é¡å‹   | æœ€å„ªé…ç½®      | åŸå›              |
| ---------- | ------------- | ---------------- |
| æ™‚æ•ˆæ€§å•é¡Œ | å°æ¨¡å‹å¤šäº¤äº’  | éœ€è¦æœå°‹æœ€æ–°è³‡è¨Š |
| å¸¸è­˜æ¨ç†   | å¤§æ¨¡å‹å°‘äº¤äº’  | ä¾è³´å…§éƒ¨çŸ¥è­˜     |
| æ·±åº¦ç ”ç©¶   | ä¸­æ¨¡å‹ä¸­äº¤äº’  | å¹³è¡¡æ·±åº¦èˆ‡å»£åº¦   |
| è¨ˆç®—å¯†é›†   | å°æ¨¡å‹ + Code | ä¾è³´ç¨‹å¼ç¢¼åŸ·è¡Œ   |

**ç™¼ç¾ 3ï¼šéŒ¯èª¤é¡å‹ä¸åŒ**

- **å¤§æ¨¡å‹å°‘äº¤äº’çš„éŒ¯èª¤**ï¼šä¸»è¦æ˜¯çŸ¥è­˜éæ™‚ã€å¹»è¦º
- **å°æ¨¡å‹å¤šäº¤äº’çš„éŒ¯èª¤**ï¼šä¸»è¦æ˜¯æ•´åˆä¸ç•¶ã€éºæ¼

---

## 2.5 å‹•æ‰‹å¯¦ä½œï¼šæ¸¬é‡ä½ çš„ Agent ç¸®æ”¾æ•ˆç›Š

### 2.5.1 å¯¦é©—æ¡†æ¶è¨­è¨ˆ

ç¾åœ¨è®“æˆ‘å€‘å»ºæ§‹ä¸€å€‹å¯¦é©—æ¡†æ¶ï¼Œè®“ä½ å¯ä»¥æ¸¬é‡è‡ªå·±ä»£ç†äººçš„ç¸®æ”¾æ•ˆç›Šã€‚

```python
"""
scaling_experiment.py

æ¸¬é‡ä»£ç†äººäº¤äº’ç¸®æ”¾æ•ˆç›Šçš„å¯¦é©—æ¡†æ¶
"""

import os
import json
import time
from dataclasses import dataclass, field
from typing import Optional, Callable
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()


# ============================================================
# è³‡æ–™çµæ§‹
# ============================================================

@dataclass
class ExperimentConfig:
    """å¯¦é©—é…ç½®"""
    name: str
    model: str
    max_interactions: int
    temperature: float = 0.1


@dataclass
class TaskResult:
    """å–®ä¸€ä»»å‹™çš„åŸ·è¡Œçµæœ"""
    task_id: str
    question: str
    answer: str
    interactions_used: int
    tokens_consumed: int
    time_seconds: float
    sources_cited: int
    config: ExperimentConfig


@dataclass
class ExperimentResult:
    """å¯¦é©—ç¸½çµæœ"""
    config: ExperimentConfig
    task_results: list[TaskResult] = field(default_factory=list)

    @property
    def avg_interactions(self) -> float:
        if not self.task_results:
            return 0
        return sum(r.interactions_used for r in self.task_results) / len(self.task_results)

    @property
    def avg_time(self) -> float:
        if not self.task_results:
            return 0
        return sum(r.time_seconds for r in self.task_results) / len(self.task_results)

    @property
    def total_tokens(self) -> int:
        return sum(r.tokens_consumed for r in self.task_results)

    @property
    def avg_sources(self) -> float:
        if not self.task_results:
            return 0
        return sum(r.sources_cited for r in self.task_results) / len(self.task_results)


# ============================================================
# å¯é…ç½®çš„ä»£ç†äºº
# ============================================================

class ConfigurableAgent:
    """
    å¯é…ç½®çš„ä»£ç†äººï¼Œç”¨æ–¼ç¸®æ”¾å¯¦é©—

    å…è¨±é…ç½®ï¼š
    - æ¨¡å‹å¤§å°
    - æœ€å¤§äº¤äº’æ¬¡æ•¸
    - å…¶ä»–åƒæ•¸
    """

    def __init__(self, config: ExperimentConfig):
        self.config = config
        self.client = OpenAI()
        self.interaction_count = 0
        self.token_count = 0

    def reset_counters(self):
        """é‡ç½®è¨ˆæ•¸å™¨"""
        self.interaction_count = 0
        self.token_count = 0

    def search(self, query: str) -> str:
        """æ¨¡æ“¬æœå°‹ï¼ˆå¯¦éš›ä½¿ç”¨æ™‚æ›¿æ›ç‚ºçœŸå¯¦æœå°‹ï¼‰"""
        self.interaction_count += 1

        # é€™è£¡æ‡‰è©²èª¿ç”¨çœŸå¯¦çš„æœå°‹ API
        # ç‚ºäº†ç¤ºç¯„ï¼Œæˆ‘å€‘è¿”å›æ¨¡æ“¬çµæœ
        return f"[æœå°‹çµæœ] é—œæ–¼ã€Œ{query}ã€çš„è³‡è¨Š..."

    def run(self, question: str) -> tuple[str, int]:
        """
        åŸ·è¡Œä»£ç†äºº

        Returns:
            (ç­”æ¡ˆ, å¼•ç”¨ä¾†æºæ•¸é‡)
        """
        self.reset_counters()

        system_prompt = f"""ä½ æ˜¯ä¸€å€‹ç ”ç©¶åŠ©ç†ã€‚
æœ€å¤šå¯ä»¥é€²è¡Œ {self.config.max_interactions} æ¬¡æœå°‹ã€‚
è«‹æ ¹æ“šéœ€è¦æœå°‹è³‡è¨Šï¼Œç„¶å¾Œå›ç­”å•é¡Œã€‚
åœ¨ç­”æ¡ˆä¸­æ¨™è¨»ä½ å¼•ç”¨çš„ä¾†æºæ•¸é‡ã€‚

å›æ‡‰æ ¼å¼ï¼š
- å¦‚éœ€æœå°‹ï¼šAction: search[é—œéµå­—]
- æœ€çµ‚ç­”æ¡ˆï¼šAnswer: [ç­”æ¡ˆ] (å¼•ç”¨ X å€‹ä¾†æº)
"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question}
        ]

        sources_cited = 0

        while self.interaction_count < self.config.max_interactions:
            response = self.client.chat.completions.create(
                model=self.config.model,
                messages=messages,
                temperature=self.config.temperature,
                max_tokens=1000
            )

            self.token_count += response.usage.total_tokens
            content = response.choices[0].message.content
            messages.append({"role": "assistant", "content": content})

            # è§£æå›æ‡‰
            if "Answer:" in content:
                # æå–ç­”æ¡ˆå’Œä¾†æºæ•¸é‡
                answer_part = content.split("Answer:")[-1].strip()

                # å˜—è©¦æå–å¼•ç”¨æ•¸é‡
                import re
                match = re.search(r'å¼•ç”¨\s*(\d+)\s*å€‹ä¾†æº', answer_part)
                if match:
                    sources_cited = int(match.group(1))

                return answer_part, sources_cited

            elif "Action: search[" in content:
                # æå–æœå°‹æŸ¥è©¢
                start = content.find("Action: search[") + len("Action: search[")
                end = content.find("]", start)
                query = content[start:end]

                # åŸ·è¡Œæœå°‹
                result = self.search(query)
                messages.append({"role": "user", "content": f"Observation: {result}"})

            else:
                # æç¤ºæ ¼å¼
                messages.append({
                    "role": "user",
                    "content": "è«‹ä½¿ç”¨ 'Action: search[é—œéµå­—]' æœå°‹ï¼Œæˆ–ç”¨ 'Answer:' çµ¦å‡ºç­”æ¡ˆã€‚"
                })

        return "é”åˆ°äº¤äº’ä¸Šé™ï¼Œç„¡æ³•å®Œæˆä»»å‹™", sources_cited


# ============================================================
# å¯¦é©—åŸ·è¡Œå™¨
# ============================================================

class ScalingExperiment:
    """
    ç¸®æ”¾å¯¦é©—åŸ·è¡Œå™¨

    ç”¨æ–¼æ¯”è¼ƒä¸åŒé…ç½®ä¸‹ä»£ç†äººçš„è¡¨ç¾
    """

    def __init__(self, tasks: list[str]):
        self.tasks = tasks
        self.results: list[ExperimentResult] = []

    def run_config(self, config: ExperimentConfig) -> ExperimentResult:
        """åŸ·è¡Œå–®ä¸€é…ç½®çš„å¯¦é©—"""
        print(f"\n{'='*60}")
        print(f"ğŸ”¬ åŸ·è¡Œé…ç½®: {config.name}")
        print(f"   æ¨¡å‹: {config.model}")
        print(f"   æœ€å¤§äº¤äº’: {config.max_interactions}")
        print(f"{'='*60}")

        agent = ConfigurableAgent(config)
        experiment_result = ExperimentResult(config=config)

        for i, task in enumerate(self.tasks, 1):
            print(f"\nğŸ“ ä»»å‹™ {i}/{len(self.tasks)}: {task[:50]}...")

            start_time = time.time()
            answer, sources = agent.run(task)
            elapsed = time.time() - start_time

            result = TaskResult(
                task_id=f"task_{i}",
                question=task,
                answer=answer,
                interactions_used=agent.interaction_count,
                tokens_consumed=agent.token_count,
                time_seconds=elapsed,
                sources_cited=sources,
                config=config
            )

            experiment_result.task_results.append(result)

            print(f"   â±ï¸ è€—æ™‚: {elapsed:.2f}s")
            print(f"   ğŸ”„ äº¤äº’æ¬¡æ•¸: {agent.interaction_count}")
            print(f"   ğŸ“š å¼•ç”¨ä¾†æº: {sources}")

        self.results.append(experiment_result)
        return experiment_result

    def run_all(self, configs: list[ExperimentConfig]):
        """åŸ·è¡Œæ‰€æœ‰é…ç½®çš„å¯¦é©—"""
        for config in configs:
            self.run_config(config)

        return self.results

    def generate_report(self) -> str:
        """ç”Ÿæˆæ¯”è¼ƒå ±å‘Š"""
        report = []
        report.append("\n" + "="*60)
        report.append("ğŸ“Š ç¸®æ”¾å¯¦é©—çµæœå ±å‘Š")
        report.append("="*60)

        # å½™ç¸½è¡¨
        report.append("\n### é…ç½®æ¯”è¼ƒ\n")
        report.append("| é…ç½® | æ¨¡å‹ | æœ€å¤§äº¤äº’ | å¹³å‡äº¤äº’ | å¹³å‡è€—æ™‚ | ç¸½ Token | å¹³å‡å¼•ç”¨ |")
        report.append("|------|------|----------|----------|----------|----------|----------|")

        for result in self.results:
            report.append(
                f"| {result.config.name} | {result.config.model} | "
                f"{result.config.max_interactions} | {result.avg_interactions:.1f} | "
                f"{result.avg_time:.1f}s | {result.total_tokens} | {result.avg_sources:.1f} |"
            )

        # æˆæœ¬æ•ˆç›Šåˆ†æ
        report.append("\n### æˆæœ¬æ•ˆç›Šåˆ†æ\n")

        # å‡è¨­çš„æˆæœ¬è¨ˆç®—ï¼ˆéœ€è¦æ ¹æ“šå¯¦éš› API åƒ¹æ ¼èª¿æ•´ï¼‰
        cost_per_1k_tokens = {
            "gpt-4o-mini": 0.00015,
            "gpt-4o": 0.005,
            "gpt-4-turbo": 0.01
        }

        for result in self.results:
            model = result.config.model
            if model in cost_per_1k_tokens:
                cost = result.total_tokens / 1000 * cost_per_1k_tokens[model]
                report.append(f"- {result.config.name}: ${cost:.4f}")

        return "\n".join(report)


# ============================================================
# ä¸»ç¨‹å¼
# ============================================================

def main():
    """åŸ·è¡Œç¸®æ”¾å¯¦é©—ç¤ºç¯„"""

    # æ¸¬è©¦ä»»å‹™
    tasks = [
        "2024 å¹´å…¨çƒé›»å‹•è»ŠéŠ·é‡æ’åå‰äº”çš„å“ç‰Œæ˜¯å“ªäº›ï¼Ÿ",
        "æ¯”è¼ƒ ChatGPT å’Œ Claude çš„ä¸»è¦å·®ç•°",
        "è§£é‡‹é‡å­è¨ˆç®—çš„åŸºæœ¬åŸç†åŠå…¶æ½›åœ¨æ‡‰ç”¨",
    ]

    # å¯¦é©—é…ç½®
    configs = [
        ExperimentConfig(
            name="å°‘äº¤äº’",
            model="gpt-4o-mini",
            max_interactions=5
        ),
        ExperimentConfig(
            name="ä¸­äº¤äº’",
            model="gpt-4o-mini",
            max_interactions=20
        ),
        ExperimentConfig(
            name="å¤šäº¤äº’",
            model="gpt-4o-mini",
            max_interactions=50
        ),
    ]

    # åŸ·è¡Œå¯¦é©—
    experiment = ScalingExperiment(tasks)
    experiment.run_all(configs)

    # ç”Ÿæˆå ±å‘Š
    report = experiment.generate_report()
    print(report)

    # å„²å­˜å ±å‘Š
    with open("scaling_experiment_report.md", "w", encoding="utf-8") as f:
        f.write(report)

    print("\nâœ… å ±å‘Šå·²å„²å­˜è‡³ scaling_experiment_report.md")


if __name__ == "__main__":
    main()
```

### 2.5.2 ç¨‹å¼ç¢¼è§£æ

è®“æˆ‘å€‘ç†è§£é€™å€‹å¯¦é©—æ¡†æ¶çš„é—œéµéƒ¨åˆ†ï¼š

**â€¹1â€º ExperimentConfig è³‡æ–™é¡åˆ¥**

```python
@dataclass
class ExperimentConfig:
    name: str
    model: str
    max_interactions: int
```

é€™å®šç¾©äº†ä¸€å€‹å¯¦é©—é…ç½®ã€‚é€šéæ”¹è®Šé€™äº›åƒæ•¸ï¼Œæˆ‘å€‘å¯ä»¥æ¸¬è©¦ä¸åŒçš„ç¸®æ”¾ç­–ç•¥ã€‚

**â€¹2â€º ConfigurableAgent é¡åˆ¥**

```python
class ConfigurableAgent:
    def __init__(self, config: ExperimentConfig):
        self.config = config
        self.interaction_count = 0
```

é€™æ˜¯ä¸€å€‹å¯ä»¥é…ç½®æœ€å¤§äº¤äº’æ¬¡æ•¸çš„ä»£ç†äººã€‚å®ƒæœƒè¿½è¹¤å¯¦éš›ä½¿ç”¨çš„äº¤äº’æ¬¡æ•¸ã€‚

**â€¹3â€º ScalingExperiment é¡åˆ¥**

```python
class ScalingExperiment:
    def run_all(self, configs: list[ExperimentConfig]):
        for config in configs:
            self.run_config(config)
```

é€™æ˜¯å¯¦é©—åŸ·è¡Œå™¨ï¼Œå¯ä»¥æ‰¹æ¬¡é‹è¡Œå¤šå€‹é…ç½®ä¸¦æ¯”è¼ƒçµæœã€‚

### 2.5.3 å¦‚ä½•ä½¿ç”¨é€™å€‹æ¡†æ¶

**æ­¥é©Ÿ 1ï¼šå®šç¾©ä½ çš„æ¸¬è©¦ä»»å‹™**

```python
tasks = [
    "ä½ æƒ³æ¸¬è©¦çš„å•é¡Œ 1",
    "ä½ æƒ³æ¸¬è©¦çš„å•é¡Œ 2",
    # ...
]
```

**æ­¥é©Ÿ 2ï¼šå®šç¾©å¯¦é©—é…ç½®**

```python
configs = [
    ExperimentConfig(name="é…ç½®A", model="gpt-4o-mini", max_interactions=10),
    ExperimentConfig(name="é…ç½®B", model="gpt-4o-mini", max_interactions=50),
    ExperimentConfig(name="é…ç½®C", model="gpt-4o", max_interactions=10),
]
```

**æ­¥é©Ÿ 3ï¼šåŸ·è¡Œå¯¦é©—**

```python
experiment = ScalingExperiment(tasks)
experiment.run_all(configs)
print(experiment.generate_report())
```

### 2.5.4 é€²éšæŒ‘æˆ°

1. **æ•´åˆçœŸå¯¦æœå°‹**ï¼šå°‡æ¨¡æ“¬æœå°‹æ›¿æ›ç‚º Serper API
2. **æ·»åŠ æº–ç¢ºæ€§è©•ä¼°**ï¼šäººå·¥æˆ–è‡ªå‹•è©•ä¼°ç­”æ¡ˆå“è³ª
3. **æ¸¬è©¦æ›´å¤šæ¨¡å‹**ï¼šæ¯”è¼ƒä¸åŒæ¨¡å‹å®¶æ—ï¼ˆGPT vs Claude vs Llamaï¼‰
4. **è¦–è¦ºåŒ–çµæœ**ï¼šç”Ÿæˆåœ–è¡¨å±•ç¤ºç¸®æ”¾æ›²ç·š

---

## 2.6 ç« ç¯€ç¸½çµ

åœ¨é€™ä¸€ç« ä¸­ï¼Œæˆ‘å€‘æ·±å…¥æ¢è¨äº†ã€Œäº¤äº’å¼ç¸®æ”¾ã€é€™å€‹é—œéµæ¦‚å¿µï¼š

### æ ¸å¿ƒè¦é»

| è¦é»           | èªªæ˜                                       |
| -------------- | ------------------------------------------ |
| **ä¸‰ç¶­ç¸®æ”¾**   | åƒæ•¸ã€æ•¸æ“šã€äº¤äº’æ˜¯æå‡ AI èƒ½åŠ›çš„ä¸‰å€‹ç¶­åº¦   |
| **äº¤äº’çš„åƒ¹å€¼** | è³‡è¨Šç²å– > äº‹å¯¦é©—è­‰ > è¨ˆç®—åŸ·è¡Œ > æ ¼å¼è½‰æ›  |
| **æœ€å„ªå¹³è¡¡é»** | ç´„ 100-200 æ¬¡äº¤äº’æ˜¯å¤šæ•¸ä»»å‹™çš„ç”œèœœé»        |
| **æˆæœ¬æ•ˆç›Š**   | å°æ¨¡å‹å¤šäº¤äº’å¯èƒ½æ¯”å¤§æ¨¡å‹å°‘äº¤äº’æ›´å…·æˆæœ¬æ•ˆç›Š |

### é—œéµå…¬å¼

```
æœ€çµ‚æ•ˆèƒ½ = f(æ¨¡å‹èƒ½åŠ›, æ•¸æ“šå“è³ª, äº¤äº’æ·±åº¦ Ã— äº¤äº’å“è³ª)
æˆæœ¬æ•ˆç›Š = æº–ç¢ºç‡ / (Tokenæˆæœ¬ + æ™‚é–“æˆæœ¬)
```

### ç”¢å‡ºç‰©

- âœ… ç†è§£äº†ç¸®æ”¾å®šå¾‹çš„ä¸‰å€‹ç¶­åº¦
- âœ… æŒæ¡äº† MiroThinker çš„äº¤äº’ç­–ç•¥
- âœ… å»ºæ§‹äº† `scaling_experiment.py` å¯¦é©—æ¡†æ¶
- âœ… èƒ½å¤ è¨­è¨ˆå’ŒåŸ·è¡Œç¸®æ”¾æ•ˆç›Šå¯¦é©—

### æ€è€ƒå•é¡Œ

1. åœ¨ä»€éº¼æƒ…æ³ä¸‹ï¼Œã€Œå¤§æ¨¡å‹å°‘äº¤äº’ã€ä»ç„¶å„ªæ–¼ã€Œå°æ¨¡å‹å¤šäº¤äº’ã€ï¼Ÿ
2. å¦‚ä½•åˆ¤æ–·ä¸€å€‹ä»»å‹™çš„ã€Œæœ€å„ªäº¤äº’æ¬¡æ•¸ã€ï¼Ÿ
3. äº¤äº’å¼ç¸®æ”¾æœ‰å“ªäº›æ½›åœ¨çš„é¢¨éšªæˆ–å±€é™ï¼Ÿ

---

## ä¸‹ä¸€ç« é å‘Š

> **ç¬¬ 3 ç« ï¼šæ·±åº¦ç ”ç©¶çš„èªçŸ¥æ¡†æ¶**
>
> æˆ‘å€‘å·²ç¶“çŸ¥é“ã€Œå¤šæ¬¡äº¤äº’ã€æ˜¯æœ‰æ•ˆçš„ï¼Œä½†ã€Œå¦‚ä½•äº¤äº’ã€åŒæ¨£é‡è¦ã€‚ä¸‹ä¸€ç« å°‡å¾èªçŸ¥ç§‘å­¸çš„è§’åº¦ï¼Œæ¢è¨äººé¡ç ”ç©¶å“¡æ˜¯å¦‚ä½•é€²è¡Œç³»çµ±æ€§ç ”ç©¶çš„ï¼Œä¸¦å°‡é€™äº›èªçŸ¥æ¨¡å¼è½‰åŒ–ç‚ºä»£ç†äººçš„ã€ŒèªçŸ¥è—åœ–ã€ã€‚ä½ å°‡å­¸æœƒè¨­è¨ˆè®“ä»£ç†äººã€Œåƒäººé¡ç ”ç©¶å“¡ä¸€æ¨£æ€è€ƒã€çš„ Prompt å’Œç­–ç•¥ã€‚

---

**æœ¬ç« ç¨‹å¼ç¢¼**ï¼š`code-examples/chapter-02/scaling_experiment.py`

**å»¶ä¼¸é–±è®€**ï¼š
- [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361)
- [MiroThinker Technical Report](https://github.com/MiroMindAI/MiroThinker)
- [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/abs/2302.04761)
