#!/usr/bin/env python3
"""
æ·±åº¦ç ”ç©¶ä»£ç†äººå¯¦æˆ° - ç¬¬ 6 ç« ï¼šé•·çŸ­æ™‚è¨˜æ†¶ç®¡ç†
åµŒå…¥ç”Ÿæˆå™¨å¯¦ç¾

é€™å€‹æ¨¡çµ„å¯¦ç¾äº†æ–‡æœ¬åµŒå…¥ç”ŸæˆåŠŸèƒ½ï¼š
1. å–®æ–‡æœ¬åµŒå…¥
2. æ‰¹æ¬¡åµŒå…¥
3. å¿«å–æ©Ÿåˆ¶
4. ç›¸ä¼¼åº¦è¨ˆç®—

ä½¿ç”¨æ–¹å¼ï¼š
    python embedder.py --demo
    python embedder.py --text "è¦åµŒå…¥çš„æ–‡æœ¬"
"""

import asyncio
import hashlib
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
from dotenv import load_dotenv
from openai import AsyncOpenAI

load_dotenv()


@dataclass
class EmbeddingResult:
    """åµŒå…¥çµæœ"""
    text: str
    embedding: List[float]
    model: str
    dimensions: int

    def to_numpy(self) -> np.ndarray:
        return np.array(self.embedding)


class EmbeddingGenerator:
    """
    åµŒå…¥ç”Ÿæˆå™¨

    â€¹1â€º ä½¿ç”¨ OpenAI embedding API
    â€¹2â€º æ”¯æ´æ‰¹æ¬¡è™•ç†
    â€¹3â€º å…§å»ºå¿«å–æ©Ÿåˆ¶
    """

    def __init__(
        self,
        client: Optional[AsyncOpenAI] = None,
        model: str = "text-embedding-3-small",
        cache_enabled: bool = True
    ):
        self.client = client or AsyncOpenAI()
        self.model = model
        self.cache_enabled = cache_enabled
        self._cache: Dict[str, List[float]] = {}

    @property
    def cache_size(self) -> int:
        return len(self._cache)

    async def embed(self, text: str) -> EmbeddingResult:
        """ç”Ÿæˆå–®å€‹æ–‡æœ¬çš„åµŒå…¥"""
        # æª¢æŸ¥å¿«å–
        if self.cache_enabled:
            cache_key = self._get_cache_key(text)
            if cache_key in self._cache:
                embedding = self._cache[cache_key]
                return EmbeddingResult(
                    text=text,
                    embedding=embedding,
                    model=self.model,
                    dimensions=len(embedding)
                )

        # èª¿ç”¨ API
        response = await self.client.embeddings.create(
            model=self.model,
            input=text
        )

        embedding = response.data[0].embedding

        # å­˜å…¥å¿«å–
        if self.cache_enabled:
            self._cache[cache_key] = embedding

        return EmbeddingResult(
            text=text,
            embedding=embedding,
            model=self.model,
            dimensions=len(embedding)
        )

    async def batch_embed(
        self,
        texts: List[str],
        batch_size: int = 100
    ) -> List[EmbeddingResult]:
        """æ‰¹æ¬¡ç”ŸæˆåµŒå…¥"""
        all_results = []

        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]

            # åˆ†é›¢å·²å¿«å–å’Œæœªå¿«å–çš„
            cached_results = []
            to_embed = []

            for j, text in enumerate(batch):
                if self.cache_enabled:
                    cache_key = self._get_cache_key(text)
                    if cache_key in self._cache:
                        cached_results.append((j, EmbeddingResult(
                            text=text,
                            embedding=self._cache[cache_key],
                            model=self.model,
                            dimensions=len(self._cache[cache_key])
                        )))
                        continue
                to_embed.append((j, text))

            # æ‰¹æ¬¡åµŒå…¥æœªå¿«å–çš„
            if to_embed:
                response = await self.client.embeddings.create(
                    model=self.model,
                    input=[t for _, t in to_embed]
                )

                for k, (j, text) in enumerate(to_embed):
                    embedding = response.data[k].embedding

                    if self.cache_enabled:
                        cache_key = self._get_cache_key(text)
                        self._cache[cache_key] = embedding

                    cached_results.append((j, EmbeddingResult(
                        text=text,
                        embedding=embedding,
                        model=self.model,
                        dimensions=len(embedding)
                    )))

            # æŒ‰åŸå§‹é †åºæ’åˆ—
            cached_results.sort(key=lambda x: x[0])
            all_results.extend([r for _, r in cached_results])

        return all_results

    def embed_sync(self, text: str) -> List[float]:
        """åŒæ­¥ç”ŸæˆåµŒå…¥ï¼ˆè¿”å›åµŒå…¥å‘é‡ï¼‰"""
        result = asyncio.get_event_loop().run_until_complete(self.embed(text))
        return result.embedding

    def _get_cache_key(self, text: str) -> str:
        """ç”Ÿæˆå¿«å–éµ"""
        return hashlib.md5(f"{self.model}:{text}".encode()).hexdigest()

    def clear_cache(self) -> int:
        """æ¸…é™¤å¿«å–"""
        count = len(self._cache)
        self._cache.clear()
        return count


class SimilarityCalculator:
    """
    ç›¸ä¼¼åº¦è¨ˆç®—å™¨

    â€¹1â€º é¤˜å¼¦ç›¸ä¼¼åº¦
    â€¹2â€º æ­å¹¾é‡Œå¾—è·é›¢
    â€¹3â€º é»ç©ç›¸ä¼¼åº¦
    """

    @staticmethod
    def cosine_similarity(
        embedding1: List[float],
        embedding2: List[float]
    ) -> float:
        """è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦"""
        vec1 = np.array(embedding1)
        vec2 = np.array(embedding2)

        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)

        if norm1 == 0 or norm2 == 0:
            return 0.0

        return float(np.dot(vec1, vec2) / (norm1 * norm2))

    @staticmethod
    def euclidean_distance(
        embedding1: List[float],
        embedding2: List[float]
    ) -> float:
        """è¨ˆç®—æ­å¹¾é‡Œå¾—è·é›¢"""
        vec1 = np.array(embedding1)
        vec2 = np.array(embedding2)
        return float(np.linalg.norm(vec1 - vec2))

    @staticmethod
    def dot_product(
        embedding1: List[float],
        embedding2: List[float]
    ) -> float:
        """è¨ˆç®—é»ç©"""
        vec1 = np.array(embedding1)
        vec2 = np.array(embedding2)
        return float(np.dot(vec1, vec2))

    @staticmethod
    def find_most_similar(
        query_embedding: List[float],
        candidate_embeddings: List[List[float]],
        top_k: int = 5
    ) -> List[Tuple[int, float]]:
        """æ‰¾åˆ°æœ€ç›¸ä¼¼çš„ K å€‹å€™é¸"""
        query = np.array(query_embedding)
        candidates = np.array(candidate_embeddings)

        # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
        query_norm = np.linalg.norm(query)
        candidate_norms = np.linalg.norm(candidates, axis=1)

        # é¿å…é™¤ä»¥é›¶
        valid_mask = (candidate_norms > 0) & (query_norm > 0)

        similarities = np.zeros(len(candidates))
        if query_norm > 0:
            similarities[valid_mask] = (
                np.dot(candidates[valid_mask], query) /
                (candidate_norms[valid_mask] * query_norm)
            )

        # ç²å– top-k
        top_indices = np.argsort(similarities)[::-1][:top_k]

        return [(int(idx), float(similarities[idx])) for idx in top_indices]


# =============================================================================
# ç°¡å–®åµŒå…¥å™¨ï¼ˆç”¨æ–¼æ¸¬è©¦å’Œé›¢ç·šå ´æ™¯ï¼‰
# =============================================================================

class SimpleEmbedder:
    """
    ç°¡å–®åµŒå…¥å™¨ï¼ˆä¸éœ€è¦ APIï¼‰

    â€¹1â€º åŸºæ–¼æ–‡æœ¬ç‰¹å¾µç”ŸæˆåµŒå…¥
    â€¹2â€º ç”¨æ–¼æ¸¬è©¦å’Œé›¢ç·šå ´æ™¯
    â€¹3â€º ä¸å…·å‚™èªç¾©ç†è§£èƒ½åŠ›
    """

    def __init__(self, dimensions: int = 128):
        self.dimensions = dimensions

    def embed(self, text: str) -> List[float]:
        """ç”Ÿæˆç°¡å–®åµŒå…¥"""
        # åŸºæ–¼æ–‡æœ¬ç‰¹å¾µç”Ÿæˆå½åµŒå…¥
        embedding = []

        # ç‰¹å¾µ 1: é•·åº¦ç›¸é—œ
        embedding.append(len(text) / 1000)

        # ç‰¹å¾µ 2: å­—ç¬¦åˆ†å¸ƒ
        for c in "abcdefghijklmnopqrstuvwxyz":
            embedding.append(text.lower().count(c) / max(len(text), 1))

        # ç‰¹å¾µ 3: æ•¸å­—å’Œæ¨™é»
        embedding.append(sum(c.isdigit() for c in text) / max(len(text), 1))
        embedding.append(sum(c in ".,!?;:" for c in text) / max(len(text), 1))

        # ç‰¹å¾µ 4: ç©ºæ ¼ï¼ˆè©æ•¸ä¼°è¨ˆï¼‰
        embedding.append(text.count(" ") / max(len(text), 1))

        # å¡«å……æˆ–æˆªæ–·åˆ°æŒ‡å®šç¶­åº¦
        while len(embedding) < self.dimensions:
            embedding.append(0.0)

        embedding = embedding[:self.dimensions]

        # æ­¸ä¸€åŒ–
        norm = np.linalg.norm(embedding)
        if norm > 0:
            embedding = [e / norm for e in embedding]

        return embedding

    def batch_embed(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹æ¬¡ç”ŸæˆåµŒå…¥"""
        return [self.embed(text) for text in texts]


# =============================================================================
# ç¤ºç¯„
# =============================================================================

async def demo():
    """ç¤ºç¯„åµŒå…¥åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ”¢ åµŒå…¥ç”Ÿæˆå™¨ç¤ºç¯„")
    print("=" * 60)

    # ä½¿ç”¨ç°¡å–®åµŒå…¥å™¨ï¼ˆä¸éœ€è¦ APIï¼‰
    print("\nğŸ“ ä½¿ç”¨ SimpleEmbedderï¼ˆé›¢ç·šæ¨¡å¼ï¼‰")
    print("-" * 40)

    simple_embedder = SimpleEmbedder(dimensions=32)
    calc = SimilarityCalculator()

    texts = [
        "NVIDIA åœ¨ AI æ™¶ç‰‡å¸‚å ´ä½”æ“šä¸»å°åœ°ä½",
        "AMD æ­£åœ¨ç©æ¥µè¿½è¶• NVIDIA çš„å¸‚å ´ä»½é¡",
        "Intel æ­£åœ¨è½‰å‹é€²å…¥ AI åŠ é€Ÿå™¨å¸‚å ´",
        "è˜‹æœå…¬å¸ç™¼å¸ƒäº†æ–°æ¬¾ iPhone"
    ]

    embeddings = [simple_embedder.embed(t) for t in texts]

    print("\næ–‡æœ¬åµŒå…¥ç¶­åº¦:", len(embeddings[0]))

    print("\nç›¸ä¼¼åº¦çŸ©é™£:")
    print(" " * 10, end="")
    for i in range(len(texts)):
        print(f"  T{i+1}  ", end="")
    print()

    for i, emb_i in enumerate(embeddings):
        print(f"T{i+1}:      ", end="")
        for emb_j in embeddings:
            sim = calc.cosine_similarity(emb_i, emb_j)
            print(f"{sim:.2f}  ", end="")
        print()

    print("\nèˆ‡ã€ŒAI æ™¶ç‰‡å¸‚å ´ã€æœ€ç›¸é—œçš„æ–‡æœ¬:")
    query_embedding = simple_embedder.embed("AI æ™¶ç‰‡å¸‚å ´ç«¶çˆ­")
    top_results = calc.find_most_similar(query_embedding, embeddings, top_k=3)

    for idx, sim in top_results:
        print(f"  [{sim:.3f}] {texts[idx]}")

    # é¡¯ç¤º OpenAI åµŒå…¥å™¨è³‡è¨Š
    print("\n" + "=" * 60)
    print("ğŸ’¡ OpenAI åµŒå…¥å™¨")
    print("=" * 60)
    print("""
è¦ä½¿ç”¨ OpenAI åµŒå…¥å™¨ï¼Œè«‹è¨­ç½® OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸ï¼š

    from embedder import EmbeddingGenerator

    generator = EmbeddingGenerator()
    result = await generator.embed("ä½ çš„æ–‡æœ¬")
    print(f"åµŒå…¥ç¶­åº¦: {result.dimensions}")
    print(f"æ¨¡å‹: {result.model}")

æ”¯æ´çš„æ¨¡å‹:
  - text-embedding-3-small (1536 ç¶­)
  - text-embedding-3-large (3072 ç¶­)
  - text-embedding-ada-002 (1536 ç¶­)
""")


def main():
    import argparse

    parser = argparse.ArgumentParser(description="åµŒå…¥ç”Ÿæˆå™¨")
    parser.add_argument("--demo", action="store_true", help="åŸ·è¡Œç¤ºç¯„")
    parser.add_argument("--text", type=str, help="è¦åµŒå…¥çš„æ–‡æœ¬")

    args = parser.parse_args()

    if args.text:
        embedder = SimpleEmbedder()
        embedding = embedder.embed(args.text)
        print(f"åµŒå…¥ç¶­åº¦: {len(embedding)}")
        print(f"å‰ 10 ç¶­: {embedding[:10]}")
    else:
        asyncio.run(demo())


if __name__ == "__main__":
    main()
