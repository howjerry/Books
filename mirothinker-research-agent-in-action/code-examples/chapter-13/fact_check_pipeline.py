#!/usr/bin/env python3
"""
æ·±åº¦ç ”ç©¶ä»£ç†äººå¯¦æˆ° - ç¬¬ 13 ç« ï¼šå¹»è¦ºè™•ç†èˆ‡äº‹å¯¦æŸ¥æ ¸
è‡ªå‹•äº‹å¯¦æŸ¥æ ¸ç®¡é“

é€™å€‹æ¨¡çµ„å¯¦ç¾äº†å®Œæ•´çš„äº‹å¯¦æŸ¥æ ¸ç®¡é“ï¼š
1. å¹»è¦ºæª¢æ¸¬èˆ‡åˆ†æ
2. äº‹å¯¦é©—è­‰
3. æ™‚åºæ•æ„Ÿæ€§è™•ç†
4. å› æœå¾‹é©—è­‰

ä½¿ç”¨æ–¹å¼ï¼š
    from fact_check_pipeline import FactCheckPipeline

    pipeline = FactCheckPipeline()
    report = await pipeline.check(text)
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
from enum import Enum
from datetime import datetime, timedelta
import asyncio
import re
import json
import uuid


# =============================================================================
# å¹»è¦ºé¡å‹èˆ‡æˆå› 
# =============================================================================

class HallucinationType(Enum):
    """å¹»è¦ºé¡å‹"""
    FACTUAL = "factual"           # äº‹å¯¦æ€§å¹»è¦º
    FABRICATION = "fabrication"   # è™›æ§‹æ€§å¹»è¦º
    TEMPORAL = "temporal"         # æ™‚åºæ€§å¹»è¦º
    REASONING = "reasoning"       # æ¨ç†æ€§å¹»è¦º
    SOURCE = "source"             # ä¾†æºæ€§å¹»è¦º


class VerificationStatus(Enum):
    """é©—è­‰ç‹€æ…‹"""
    VERIFIED = "verified"           # å·²é©—è­‰æ­£ç¢º
    REFUTED = "refuted"             # å·²é©—è­‰éŒ¯èª¤
    UNCERTAIN = "uncertain"         # ç„¡æ³•ç¢ºå®š
    OUTDATED = "outdated"           # è³‡è¨Šéæ™‚
    UNVERIFIABLE = "unverifiable"   # ç„¡æ³•é©—è­‰


class CausalRelationType(Enum):
    """å› æœé—œä¿‚é¡å‹"""
    CAUSES = "causes"              # A å°è‡´ B
    ENABLES = "enables"            # A ä½¿ B æˆç‚ºå¯èƒ½
    PREVENTS = "prevents"          # A é˜»æ­¢ B
    CORRELATES = "correlates"      # A èˆ‡ B ç›¸é—œ
    CONTRADICTS = "contradicts"    # A èˆ‡ B çŸ›ç›¾


# =============================================================================
# è³‡æ–™çµæ§‹
# =============================================================================

@dataclass
class HallucinationInstance:
    """å¹»è¦ºå¯¦ä¾‹"""
    hallucination_id: str
    content: str
    hallucination_type: HallucinationType
    confidence: float
    context: str
    correct_information: Optional[str] = None

    def to_dict(self) -> dict:
        return {
            "id": self.hallucination_id,
            "content": self.content,
            "type": self.hallucination_type.value,
            "confidence": self.confidence,
            "correct_info": self.correct_information
        }


@dataclass
class Claim:
    """å¯é©—è­‰è²æ˜"""
    claim_id: str
    text: str
    claim_type: str
    entities: List[str] = field(default_factory=list)


@dataclass
class Evidence:
    """è­‰æ“š"""
    source: str
    url: Optional[str]
    content: str
    credibility_score: float
    supports_claim: Optional[bool]


@dataclass
class VerificationResult:
    """é©—è­‰çµæœ"""
    claim: Claim
    status: VerificationStatus
    confidence: float
    evidences: List[Evidence] = field(default_factory=list)
    explanation: str = ""
    correction: Optional[str] = None


@dataclass
class CausalClaim:
    """å› æœè²æ˜"""
    cause: str
    effect: str
    relation_type: CausalRelationType
    confidence: float
    evidence: Optional[str] = None


@dataclass
class FactCheckReport:
    """äº‹å¯¦æŸ¥æ ¸å ±å‘Š"""
    input_text: str
    check_time: datetime
    duration_seconds: float
    hallucination_analysis: Dict[str, Any] = field(default_factory=dict)
    fact_verification: Dict[str, Any] = field(default_factory=dict)
    temporal_analysis: Dict[str, Any] = field(default_factory=dict)
    causal_validation: Dict[str, Any] = field(default_factory=dict)
    overall_credibility: float = 0.0
    risk_level: str = "low"
    summary: str = ""
    recommendations: List[str] = field(default_factory=list)


# =============================================================================
# å¹»è¦ºåˆ†æå™¨
# =============================================================================

class HallucinationAnalyzer:
    """
    å¹»è¦ºåˆ†æå™¨

    â€¹1â€º æª¢æ¸¬æ½›åœ¨çš„å¹»è¦º
    â€¹2â€º åˆ†é¡å¹»è¦ºé¡å‹
    """

    HALLUCINATION_INDICATORS = {
        "temporal": [
            "æœ€æ–°", "ç›®å‰", "ç¾åœ¨", "ç•¶å‰", "ä»Šå¹´",
            "current", "currently", "now", "latest", "recent"
        ],
        "fabrication": [
            "æ ¹æ“šç ”ç©¶", "å°ˆå®¶è¡¨ç¤º", "æ“šå ±å°", "ç ”ç©¶é¡¯ç¤º",
            "according to", "study shows", "research indicates"
        ],
        "factual": [
            "æ˜¯", "ç‚º", "æœ‰", "é”åˆ°", "è¶…é",
            "is", "was", "has", "reached", "exceeded"
        ]
    }

    def __init__(self, llm_client=None, knowledge_cutoff: str = "2024-01"):
        self.llm_client = llm_client
        self.knowledge_cutoff = knowledge_cutoff

    def detect_potential_hallucinations(
        self,
        text: str
    ) -> List[Dict[str, Any]]:
        """æª¢æ¸¬æ½›åœ¨çš„å¹»è¦º"""
        potential = []

        # æª¢æŸ¥æ™‚åºæ€§å•é¡Œ
        for indicator in self.HALLUCINATION_INDICATORS["temporal"]:
            if indicator in text.lower():
                potential.append({
                    "type": HallucinationType.TEMPORAL.value,
                    "indicator": indicator,
                    "reason": "åŒ…å«æ™‚æ•ˆæ€§æ•æ„Ÿè©å½™"
                })
                break

        # æª¢æŸ¥è™›æ§‹å¼•ç”¨
        for indicator in self.HALLUCINATION_INDICATORS["fabrication"]:
            if indicator in text.lower():
                if not self._has_verifiable_source(text):
                    potential.append({
                        "type": HallucinationType.SOURCE.value,
                        "indicator": indicator,
                        "reason": "å¼•ç”¨ä¾†æºä½†ç„¡æ³•é©—è­‰"
                    })
                break

        # æª¢æŸ¥æ•¸å­—å’Œçµ±è¨ˆ
        numbers = self._extract_numbers(text)
        if numbers:
            potential.append({
                "type": HallucinationType.FACTUAL.value,
                "indicator": str(numbers[:3]),
                "reason": "åŒ…å«å…·é«”æ•¸å­—ï¼Œéœ€è¦é©—è­‰"
            })

        return potential

    def _has_verifiable_source(self, text: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰å¯é©—è­‰çš„ä¾†æº"""
        url_pattern = r'https?://[^\s]+'
        if re.search(url_pattern, text):
            return True

        citation_patterns = [
            r'\[\d+\]',
            r'\([A-Z][a-z]+,?\s*\d{4}\)',
            r'doi:\s*\d+\.\d+',
        ]
        for pattern in citation_patterns:
            if re.search(pattern, text):
                return True

        return False

    def _extract_numbers(self, text: str) -> List[str]:
        """æå–æ–‡æœ¬ä¸­çš„æ•¸å­—"""
        patterns = [
            r'\d+\.?\d*%',
            r'\$\d+(?:,\d{3})*(?:\.\d+)?',
            r'\d{4}å¹´',
            r'\d+(?:,\d{3})*',
        ]
        numbers = []
        for pattern in patterns:
            numbers.extend(re.findall(pattern, text))
        return numbers[:5]

    async def analyze_with_llm(
        self,
        text: str
    ) -> List[HallucinationInstance]:
        """ä½¿ç”¨ LLM é€²è¡Œæ·±åº¦åˆ†æ"""
        if not self.llm_client:
            # è¿”å›åŸºæ–¼è¦å‰‡çš„åˆ†æ
            potential = self.detect_potential_hallucinations(text)
            return [
                HallucinationInstance(
                    hallucination_id=str(uuid.uuid4())[:8],
                    content=p["indicator"],
                    hallucination_type=HallucinationType(p["type"]),
                    confidence=0.5,
                    context=text[:200]
                )
                for p in potential
            ]

        prompt = f"""åˆ†æä»¥ä¸‹æ–‡æœ¬ä¸­å¯èƒ½å­˜åœ¨çš„å¹»è¦ºæˆ–ä¸æº–ç¢ºè³‡è¨Šã€‚

æ–‡æœ¬å…§å®¹ï¼š
{text}

æ¨¡å‹çŸ¥è­˜æˆªæ­¢æ—¥æœŸï¼š{self.knowledge_cutoff}

è«‹è­˜åˆ¥å¯èƒ½éæ™‚ã€è™›æ§‹æˆ–ä¸æº–ç¢ºçš„è³‡è¨Šã€‚
ä»¥ JSON é™£åˆ—æ ¼å¼å›è¦†ã€‚"""

        response = await self.llm_client.generate(prompt)
        return self._parse_llm_analysis(response, text)

    def _parse_llm_analysis(
        self,
        response: str,
        original_text: str
    ) -> List[HallucinationInstance]:
        """è§£æ LLM åˆ†æçµæœ"""
        instances = []
        try:
            json_start = response.find("[")
            json_end = response.rfind("]") + 1
            if json_start >= 0 and json_end > json_start:
                data = json.loads(response[json_start:json_end])
                for item in data:
                    instances.append(HallucinationInstance(
                        hallucination_id=str(uuid.uuid4())[:8],
                        content=item.get("content", ""),
                        hallucination_type=HallucinationType(
                            item.get("type", "factual")
                        ),
                        confidence=item.get("confidence", 0.5),
                        context=original_text[:200]
                    ))
        except Exception:
            pass
        return instances


# =============================================================================
# äº‹å¯¦æŸ¥æ ¸å¼•æ“
# =============================================================================

class FactCheckEngine:
    """
    äº‹å¯¦æŸ¥æ ¸å¼•æ“

    â€¹3â€º æå–å¯é©—è­‰è²æ˜
    â€¹4â€º é©—è­‰äº‹å¯¦æº–ç¢ºæ€§
    """

    CLAIM_PATTERNS = {
        "numerical": [
            r"(\d+(?:\.\d+)?%)",
            r"(\$\d+(?:,\d{3})*(?:\.\d+)?)",
            r"(\d+(?:,\d{3})*\s*(?:äºº|å€‹|å®¶|æ¬¡))",
        ],
        "temporal": [
            r"((?:19|20)\d{2}å¹´)",
            r"((?:ä¸Š|æœ¬|å»|ä»Š)å¹´)",
        ],
        "attribution": [
            r"((?:æ“š|æ ¹æ“š).*?(?:è¡¨ç¤º|æŒ‡å‡º|å ±å°))",
        ]
    }

    SOURCE_CREDIBILITY = {
        "academic": 0.95,
        "government": 0.90,
        "major_news": 0.85,
        "tech_news": 0.80,
        "general": 0.60,
        "social": 0.30,
        "unknown": 0.10,
    }

    def __init__(self, llm_client=None, search_engine=None):
        self.llm_client = llm_client
        self.search_engine = search_engine

    def extract_claims(self, text: str) -> List[Claim]:
        """æå–å¯é©—è­‰è²æ˜"""
        claims = []
        claim_id = 0
        sentences = self._split_sentences(text)

        for sentence in sentences:
            claim_type = self._identify_claim_type(sentence)
            if claim_type:
                claim_id += 1
                entities = self._extract_entities(sentence)
                claims.append(Claim(
                    claim_id=f"CLM-{claim_id:03d}",
                    text=sentence.strip(),
                    claim_type=claim_type,
                    entities=entities
                ))

        return claims

    def _split_sentences(self, text: str) -> List[str]:
        """åˆ†å‰²å¥å­"""
        separators = r'[ã€‚ï¼ï¼Ÿ\.!?]'
        sentences = re.split(separators, text)
        return [s.strip() for s in sentences if s.strip() and len(s.strip()) > 5]

    def _identify_claim_type(self, sentence: str) -> Optional[str]:
        """è­˜åˆ¥è²æ˜é¡å‹"""
        for claim_type, patterns in self.CLAIM_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, sentence):
                    return claim_type

        fact_verbs = ["æ˜¯", "ç‚º", "æœ‰", "é”åˆ°", "è¶…é", "å¢é•·"]
        for verb in fact_verbs:
            if verb in sentence and len(sentence) > 10:
                return "factual"

        return None

    def _extract_entities(self, sentence: str) -> List[str]:
        """æå–å¯¦é«”"""
        entities = []
        company_pattern = r'([A-Z][a-z]*(?:\s[A-Z][a-z]*)*)'
        entities.extend(re.findall(company_pattern, sentence))
        return list(set(entities))[:5]

    async def verify_claim(
        self,
        claim: Claim,
        max_sources: int = 3
    ) -> VerificationResult:
        """é©—è­‰è²æ˜"""
        # ç°¡åŒ–ç‰ˆï¼šä¸é€²è¡Œå¯¦éš›æœå°‹
        # å¯¦éš›ä½¿ç”¨æ™‚æ‡‰æ•´åˆæœå°‹å¼•æ“

        return VerificationResult(
            claim=claim,
            status=VerificationStatus.UNCERTAIN,
            confidence=0.5,
            evidences=[],
            explanation="éœ€è¦å¤–éƒ¨é©—è­‰"
        )

    async def check(self, text: str) -> Dict[str, Any]:
        """åŸ·è¡Œäº‹å¯¦æŸ¥æ ¸"""
        start_time = datetime.now()
        claims = self.extract_claims(text)

        results = []
        for claim in claims:
            result = await self.verify_claim(claim)
            results.append(result)

        end_time = datetime.now()

        verified = sum(1 for r in results if r.status == VerificationStatus.VERIFIED)
        refuted = sum(1 for r in results if r.status == VerificationStatus.REFUTED)

        return {
            "summary": f"å…±æª¢æŸ¥ {len(claims)} å€‹è²æ˜",
            "claims_count": len(claims),
            "verified_count": verified,
            "refuted_count": refuted,
            "uncertain_count": len(claims) - verified - refuted,
            "overall_credibility": 0.7 if refuted == 0 else 0.5,
            "duration_seconds": (end_time - start_time).total_seconds(),
            "detailed_results": [
                {
                    "claim": r.claim.text,
                    "status": r.status.value,
                    "confidence": r.confidence
                }
                for r in results
            ]
        }


# =============================================================================
# æ™‚åºæ•æ„Ÿè™•ç†å™¨
# =============================================================================

class TemporalAwareProcessor:
    """
    æ™‚åºæ„ŸçŸ¥è™•ç†å™¨

    â€¹5â€º è­˜åˆ¥æ™‚é–“æ•æ„Ÿè³‡è¨Š
    â€¹6â€º è©•ä¼°è³‡è¨Šæ™‚æ•ˆæ€§
    """

    TEMPORAL_INDICATORS = {
        "current": ["ç›®å‰", "ç¾åœ¨", "ç•¶å‰", "current", "currently", "now"],
        "recent": ["æœ€è¿‘", "è¿‘æœŸ", "æœ€æ–°", "recent", "recently", "latest"],
        "future": ["å°‡", "é è¨ˆ", "å³å°‡", "will", "expected", "upcoming"],
        "past": ["æ›¾", "éå»", "ä»¥å‰", "was", "were", "previously"],
    }

    VALIDITY_PERIODS = {
        "stock_price": 0,
        "exchange_rate": 0,
        "news": 1,
        "market_data": 7,
        "company_info": 30,
        "research_data": 90,
        "historical_fact": 36500,
    }

    def __init__(self, model_cutoff: str = "2024-01-01"):
        self.model_cutoff = datetime.fromisoformat(model_cutoff)
        self.current_time = datetime.now()

    def analyze_temporal_sensitivity(self, text: str) -> Dict[str, Any]:
        """åˆ†ææ™‚åºæ•æ„Ÿæ€§"""
        analysis = {
            "has_temporal_references": False,
            "temporal_markers": [],
            "requires_update": False,
            "sensitive_phrases": [],
            "recommended_actions": []
        }

        for category, indicators in self.TEMPORAL_INDICATORS.items():
            for indicator in indicators:
                if indicator in text.lower():
                    analysis["has_temporal_references"] = True
                    analysis["temporal_markers"].append({
                        "marker": indicator,
                        "category": category
                    })

        # æª¢æŸ¥å¹´ä»½
        year_matches = re.findall(r"((?:19|20)\d{2})", text)
        for year_str in year_matches:
            analysis["sensitive_phrases"].append(f"{year_str}å¹´")
            year = int(year_str)
            if year >= self.model_cutoff.year:
                analysis["requires_update"] = True
                analysis["recommended_actions"].append(
                    f"é©—è­‰ {year} å¹´çš„è³‡è¨Š"
                )

        return analysis

    def estimate_information_age(
        self,
        text: str,
        source_date: Optional[datetime] = None
    ) -> Dict[str, Any]:
        """ä¼°è¨ˆè³‡è¨Šå¹´é½¡"""
        if source_date:
            age_days = (self.current_time - source_date).days
        else:
            age_days = (self.current_time - self.model_cutoff).days

        info_type = self._classify_information_type(text)
        validity_days = self.VALIDITY_PERIODS.get(info_type, 30)

        is_stale = age_days > validity_days
        freshness_score = max(0, 1 - age_days / validity_days) if validity_days else 0

        return {
            "age_days": age_days,
            "information_type": info_type,
            "validity_period_days": validity_days,
            "is_stale": is_stale,
            "freshness_score": freshness_score
        }

    def _classify_information_type(self, text: str) -> str:
        """åˆ†é¡è³‡è¨Šé¡å‹"""
        text_lower = text.lower()

        if any(w in text_lower for w in ["è‚¡åƒ¹", "stock", "price"]):
            return "stock_price"
        elif any(w in text_lower for w in ["åŒ¯ç‡", "exchange"]):
            return "exchange_rate"
        elif any(w in text_lower for w in ["æ–°è", "news"]):
            return "news"
        elif any(w in text_lower for w in ["å¸‚å ´", "market"]):
            return "market_data"
        elif any(w in text_lower for w in ["å…¬å¸", "company"]):
            return "company_info"
        elif any(w in text_lower for w in ["ç ”ç©¶", "research"]):
            return "research_data"
        else:
            return "general"

    def generate_temporal_disclaimer(self, text: str) -> str:
        """ç”Ÿæˆæ™‚åºå…è²¬è²æ˜"""
        analysis = self.analyze_temporal_sensitivity(text)
        age_info = self.estimate_information_age(text)

        if not age_info["is_stale"] and not analysis["requires_update"]:
            return ""

        disclaimers = []
        if age_info["is_stale"]:
            disclaimers.append(
                f"âš ï¸ æ­¤è³‡è¨Šå·²æœ‰ {age_info['age_days']} å¤©ï¼Œå¯èƒ½å·²éæ™‚"
            )

        for action in analysis["recommended_actions"][:2]:
            disclaimers.append(f"ğŸ“Œ {action}")

        return "\n".join(disclaimers)


# =============================================================================
# å› æœæ¨ç†é©—è­‰å™¨
# =============================================================================

class CausalReasoningValidator:
    """
    å› æœæ¨ç†é©—è­‰å™¨

    â€¹7â€º è­˜åˆ¥å› æœä¸»å¼µ
    â€¹8â€º é©—è­‰å› æœé—œä¿‚åˆç†æ€§
    """

    CAUSAL_INDICATORS = {
        "causes": [
            "å°è‡´", "é€ æˆ", "å¼•èµ·", "ä½¿", "è®“",
            "å› ç‚º", "ç”±æ–¼", "æ‰€ä»¥", "å› æ­¤",
            "causes", "leads to", "results in", "because"
        ],
        "enables": [
            "ä¿ƒé€²", "æ¨å‹•", "æœ‰åŠ©æ–¼",
            "enables", "allows", "facilitates"
        ],
        "prevents": [
            "é˜»æ­¢", "é˜²æ­¢", "é¿å…",
            "prevents", "blocks", "inhibits"
        ],
    }

    FALLACY_PATTERNS = {
        "post_hoc": {
            "description": "å¾Œæ­¤è¬¬èª¤ï¼šåƒ…å› æ™‚åºå…ˆå¾Œæ¨æ–·å› æœ",
            "indicators": ["ä¹‹å¾Œ", "æ¥è‘—", "ç„¶å¾Œ", "after", "then"]
        },
        "correlation_causation": {
            "description": "ç›¸é—œæ€§è¬¬èª¤ï¼šå°‡ç›¸é—œæ€§ç­‰åŒæ–¼å› æœæ€§",
            "indicators": ["ç›¸é—œ", "ä¼´éš¨", "åŒæ™‚", "correlates"]
        },
        "single_cause": {
            "description": "å–®ä¸€åŸå› è¬¬èª¤ï¼šè¤‡é›œç¾è±¡æ­¸å› æ–¼å–®ä¸€åŸå› ",
            "indicators": ["å”¯ä¸€", "åªæ˜¯å› ç‚º", "solely", "only because"]
        }
    }

    def __init__(self, llm_client=None):
        self.llm_client = llm_client

    def extract_causal_claims(self, text: str) -> List[CausalClaim]:
        """æå–å› æœä¸»å¼µ"""
        claims = []
        sentences = self._split_sentences(text)

        for sentence in sentences:
            relation_type = self._identify_causal_relation(sentence)
            if relation_type:
                cause, effect = self._extract_cause_effect(sentence, relation_type)
                if cause and effect:
                    claims.append(CausalClaim(
                        cause=cause,
                        effect=effect,
                        relation_type=relation_type,
                        confidence=0.7,
                        evidence=sentence
                    ))

        return claims

    def _split_sentences(self, text: str) -> List[str]:
        """åˆ†å‰²å¥å­"""
        return [s.strip() for s in re.split(r'[ã€‚ï¼ï¼Ÿ\.!?]', text) if s.strip()]

    def _identify_causal_relation(
        self,
        sentence: str
    ) -> Optional[CausalRelationType]:
        """è­˜åˆ¥å› æœé—œä¿‚é¡å‹"""
        sentence_lower = sentence.lower()

        for relation_type, indicators in self.CAUSAL_INDICATORS.items():
            for indicator in indicators:
                if indicator in sentence_lower:
                    return CausalRelationType(relation_type)

        return None

    def _extract_cause_effect(
        self,
        sentence: str,
        relation_type: CausalRelationType
    ) -> Tuple[Optional[str], Optional[str]]:
        """æå–åŸå› å’Œçµæœ"""
        for indicator in self.CAUSAL_INDICATORS.get(relation_type.value, []):
            if indicator in sentence:
                parts = sentence.split(indicator, 1)
                if len(parts) == 2:
                    return parts[0].strip(), parts[1].strip()
        return None, None

    def validate_causal_claim(self, claim: CausalClaim) -> Dict[str, Any]:
        """é©—è­‰å› æœä¸»å¼µ"""
        issues = []
        suggestions = []

        for fallacy_name, fallacy_info in self.FALLACY_PATTERNS.items():
            if claim.evidence:
                for indicator in fallacy_info.get("indicators", []):
                    if indicator in claim.evidence.lower():
                        issues.append(fallacy_info["description"])
                        break

        is_valid = len(issues) == 0

        return {
            "claim": f"{claim.cause} â†’ {claim.effect}",
            "is_valid": is_valid,
            "issues": issues,
            "suggestions": suggestions
        }


# =============================================================================
# å®Œæ•´äº‹å¯¦æŸ¥æ ¸ç®¡é“
# =============================================================================

class FactCheckPipeline:
    """
    è‡ªå‹•äº‹å¯¦æŸ¥æ ¸ç®¡é“

    æ•´åˆæ‰€æœ‰æŸ¥æ ¸åŠŸèƒ½
    """

    def __init__(
        self,
        llm_client=None,
        search_engine=None,
        model_cutoff: str = "2024-01-01"
    ):
        self.llm_client = llm_client
        self.search_engine = search_engine

        self.hallucination_analyzer = HallucinationAnalyzer(
            llm_client, model_cutoff
        )
        self.fact_checker = FactCheckEngine(llm_client, search_engine)
        self.temporal_processor = TemporalAwareProcessor(model_cutoff)
        self.causal_validator = CausalReasoningValidator(llm_client)

    async def check(self, text: str) -> FactCheckReport:
        """åŸ·è¡Œå®Œæ•´çš„äº‹å¯¦æŸ¥æ ¸"""
        start_time = datetime.now()

        # ä¸¦è¡ŒåŸ·è¡Œå„é …æª¢æŸ¥
        tasks = [
            self._analyze_hallucinations(text),
            self._verify_facts(text),
            self._analyze_temporal(text),
            self._validate_causal(text),
        ]

        results = await asyncio.gather(*tasks)

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        report = FactCheckReport(
            input_text=text[:1000] if len(text) > 1000 else text,
            check_time=start_time,
            duration_seconds=duration,
            hallucination_analysis=results[0],
            fact_verification=results[1],
            temporal_analysis=results[2],
            causal_validation=results[3]
        )

        self._compute_overall_assessment(report)

        return report

    async def _analyze_hallucinations(self, text: str) -> Dict[str, Any]:
        """å¹»è¦ºåˆ†æ"""
        potential = self.hallucination_analyzer.detect_potential_hallucinations(text)
        detailed = await self.hallucination_analyzer.analyze_with_llm(text)

        return {
            "potential_issues": len(potential),
            "detected_hallucinations": len(detailed),
            "details": [h.to_dict() for h in detailed]
        }

    async def _verify_facts(self, text: str) -> Dict[str, Any]:
        """äº‹å¯¦é©—è­‰"""
        return await self.fact_checker.check(text)

    async def _analyze_temporal(self, text: str) -> Dict[str, Any]:
        """æ™‚åºåˆ†æ"""
        sensitivity = self.temporal_processor.analyze_temporal_sensitivity(text)
        age_info = self.temporal_processor.estimate_information_age(text)
        disclaimer = self.temporal_processor.generate_temporal_disclaimer(text)

        return {
            "sensitivity": sensitivity,
            "age_info": age_info,
            "disclaimer": disclaimer
        }

    async def _validate_causal(self, text: str) -> Dict[str, Any]:
        """å› æœé©—è­‰"""
        claims = self.causal_validator.extract_causal_claims(text)
        validations = []

        for claim in claims:
            validation = self.causal_validator.validate_causal_claim(claim)
            validations.append(validation)

        return {
            "claims_found": len(claims),
            "valid_claims": sum(1 for v in validations if v["is_valid"]),
            "validations": validations
        }

    def _compute_overall_assessment(self, report: FactCheckReport):
        """è¨ˆç®—ç¸½é«”è©•ä¼°"""
        scores = []

        # å¹»è¦ºåˆ†æè©•åˆ†
        hallucination_count = report.hallucination_analysis.get(
            "detected_hallucinations", 0
        )
        hallucination_score = max(0, 1 - hallucination_count * 0.2)
        scores.append(hallucination_score)

        # äº‹å¯¦é©—è­‰è©•åˆ†
        fact_credibility = report.fact_verification.get("overall_credibility", 0.5)
        scores.append(fact_credibility)

        # æ™‚åºè©•åˆ†
        freshness = report.temporal_analysis.get("age_info", {}).get(
            "freshness_score", 0.5
        )
        scores.append(freshness)

        # å› æœè©•åˆ†
        causal_data = report.causal_validation
        if causal_data.get("claims_found", 0) > 0:
            causal_score = (
                causal_data.get("valid_claims", 0) /
                causal_data.get("claims_found", 1)
            )
        else:
            causal_score = 1.0
        scores.append(causal_score)

        # åŠ æ¬Šå¹³å‡
        weights = [0.3, 0.4, 0.15, 0.15]
        report.overall_credibility = sum(s * w for s, w in zip(scores, weights))

        # é¢¨éšªç­‰ç´š
        if report.overall_credibility >= 0.8:
            report.risk_level = "low"
        elif report.overall_credibility >= 0.6:
            report.risk_level = "medium"
        else:
            report.risk_level = "high"

        # æ‘˜è¦
        report.summary = (
            f"æ•´é«”å¯ä¿¡åº¦ï¼š{report.overall_credibility:.1%}ï¼Œ"
            f"é¢¨éšªç­‰ç´šï¼š{report.risk_level}"
        )

        # å»ºè­°
        report.recommendations = self._generate_recommendations(report)

    def _generate_recommendations(self, report: FactCheckReport) -> List[str]:
        """ç”Ÿæˆå»ºè­°"""
        recommendations = []

        if report.hallucination_analysis.get("detected_hallucinations", 0) > 0:
            recommendations.append("å»ºè­°å°æ½›åœ¨å¹»è¦ºé€²è¡Œäººå·¥é©—è­‰")

        if report.fact_verification.get("refuted_count", 0) > 0:
            recommendations.append("ç™¼ç¾ä¸æº–ç¢ºçš„è²æ˜ï¼Œè«‹ä¿®æ­£")

        if report.temporal_analysis.get("age_info", {}).get("is_stale", False):
            recommendations.append("éƒ¨åˆ†è³‡è¨Šå¯èƒ½éæ™‚ï¼Œå»ºè­°æ›´æ–°")

        invalid_causal = (
            report.causal_validation.get("claims_found", 0) -
            report.causal_validation.get("valid_claims", 0)
        )
        if invalid_causal > 0:
            recommendations.append(f"{invalid_causal} å€‹å› æœæ¨ç†éœ€è¦å¯©è¦–")

        if not recommendations:
            recommendations.append("æŸ¥æ ¸é€šéï¼Œå…§å®¹å¯ä¿¡åº¦è¼ƒé«˜")

        return recommendations


# =============================================================================
# ç¤ºç¯„
# =============================================================================

async def demo():
    """ç¤ºç¯„äº‹å¯¦æŸ¥æ ¸"""
    text = """
    æ ¹æ“šæœ€æ–°ç ”ç©¶ï¼Œè˜‹æœå…¬å¸åœ¨ 2024 å¹´çš„ç‡Ÿæ”¶é”åˆ° 4000 å„„ç¾å…ƒï¼Œ
    é€™ä¸»è¦æ˜¯å› ç‚º iPhone 15 çš„æˆåŠŸã€‚ç”±æ–¼ AI æŠ€è¡“çš„ç™¼å±•ï¼Œ
    æ™ºæ…§å‹æ‰‹æ©Ÿå¸‚å ´å¢é•·äº† 50%ã€‚å°ˆå®¶é æ¸¬ï¼Œåˆ° 2025 å¹´ï¼Œ
    å…¨çƒ AI æ™¶ç‰‡å¸‚å ´å°‡é”åˆ° 1000 å„„ç¾å…ƒè¦æ¨¡ã€‚
    """

    print("=" * 60)
    print("  äº‹å¯¦æŸ¥æ ¸ç®¡é“ç¤ºç¯„")
    print("=" * 60)

    pipeline = FactCheckPipeline(
        llm_client=None,
        search_engine=None,
        model_cutoff="2024-01-01"
    )

    report = await pipeline.check(text)

    print(f"\nè¼¸å…¥æ–‡æœ¬é•·åº¦ï¼š{len(text)} å­—ç¬¦")
    print(f"æŸ¥æ ¸è€—æ™‚ï¼š{report.duration_seconds:.2f} ç§’")
    print(f"\n{report.summary}")
    print(f"\nå¯ä¿¡åº¦åˆ†æ•¸ï¼š{report.overall_credibility:.2%}")
    print(f"é¢¨éšªç­‰ç´šï¼š{report.risk_level}")

    print("\nå¹»è¦ºåˆ†æï¼š")
    print(f"  - æ½›åœ¨å•é¡Œï¼š{report.hallucination_analysis.get('potential_issues', 0)}")
    print(f"  - æª¢æ¸¬åˆ°çš„å¹»è¦ºï¼š{report.hallucination_analysis.get('detected_hallucinations', 0)}")

    print("\näº‹å¯¦é©—è­‰ï¼š")
    print(f"  - è²æ˜æ•¸é‡ï¼š{report.fact_verification.get('claims_count', 0)}")
    print(f"  - å¾…é©—è­‰ï¼š{report.fact_verification.get('uncertain_count', 0)}")

    print("\næ™‚åºåˆ†æï¼š")
    sensitivity = report.temporal_analysis.get("sensitivity", {})
    print(f"  - æ™‚é–“æ•æ„Ÿï¼š{sensitivity.get('has_temporal_references', False)}")
    print(f"  - éœ€è¦æ›´æ–°ï¼š{sensitivity.get('requires_update', False)}")

    print("\nå› æœé©—è­‰ï¼š")
    print(f"  - å› æœä¸»å¼µæ•¸ï¼š{report.causal_validation.get('claims_found', 0)}")
    print(f"  - æœ‰æ•ˆä¸»å¼µæ•¸ï¼š{report.causal_validation.get('valid_claims', 0)}")

    print("\nå»ºè­°ï¼š")
    for rec in report.recommendations:
        print(f"  - {rec}")


if __name__ == "__main__":
    asyncio.run(demo())
