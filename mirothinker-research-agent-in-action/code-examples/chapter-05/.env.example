# 深度研究代理人實戰 - 第 5 章：工具調用與軌跡收集
# 複製此檔案為 .env 並填入你的 API Key

# ===========================================
# OpenAI API 設定（必要）
# ===========================================
# 從 https://platform.openai.com/api-keys 獲取
OPENAI_API_KEY=your-openai-api-key-here

# ===========================================
# 模型配置
# ===========================================

# 預設模型
DEFAULT_MODEL=gpt-4o-mini

# 工具調用模型（可使用更小的模型以節省成本）
TOOL_CALLING_MODEL=gpt-4o-mini

# ===========================================
# 工具配置
# ===========================================

# 工具執行超時時間（秒）
TOOL_TIMEOUT=30

# 最大並發工具調用數
MAX_CONCURRENT_TOOLS=5

# Python 執行器超時時間（秒）
PYTHON_EXECUTOR_TIMEOUT=30

# 網頁瀏覽器超時時間（秒）
WEB_BROWSER_TIMEOUT=30

# ===========================================
# 軌跡收集配置
# ===========================================

# 軌跡存儲路徑
TRAJECTORY_STORAGE_PATH=./trajectories

# 是否自動保存軌跡
AUTO_SAVE_TRAJECTORIES=true

# 訓練資料匯出路徑
TRAINING_DATA_PATH=./training_data

# 最小獎勵閾值（用於過濾低品質軌跡）
MIN_REWARD_THRESHOLD=0.3

# ===========================================
# 獎勵計算權重
# ===========================================

# 任務完成度權重
REWARD_WEIGHT_TASK_COMPLETION=0.30

# 工具效率權重
REWARD_WEIGHT_TOOL_EFFICIENCY=0.20

# 答案品質權重
REWARD_WEIGHT_ANSWER_QUALITY=0.25

# 事實準確度權重
REWARD_WEIGHT_FACTUAL_ACCURACY=0.15

# Token 效率權重
REWARD_WEIGHT_TOKEN_EFFICIENCY=0.10

# ===========================================
# 搜尋工具配置（可選）
# ===========================================

# Serper API Key（用於真實網頁搜尋）
# SERPER_API_KEY=your-serper-api-key-here

# Tavily API Key（用於真實網頁搜尋）
# TAVILY_API_KEY=your-tavily-api-key-here

# ===========================================
# 日誌配置
# ===========================================

# 日誌級別（DEBUG, INFO, WARNING, ERROR）
LOG_LEVEL=INFO

# 是否顯示詳細輸出
VERBOSE=true

# ===========================================
# 進階設定（可選）
# ===========================================

# 啟用軌跡壓縮
ENABLE_TRAJECTORY_COMPRESSION=false

# 軌跡保留天數（超過則自動清理）
TRAJECTORY_RETENTION_DAYS=30

# 最大軌跡存儲數量
MAX_TRAJECTORIES=10000
