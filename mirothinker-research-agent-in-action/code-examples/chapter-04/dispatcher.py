"""
dispatcher.py

æ·±åº¦ç ”ç©¶ä»£ç†äººçš„æ ¸å¿ƒèª¿åº¦å™¨å¯¦ç¾
æ”¯æ´ä»»å‹™åˆ†è§£ã€ä¾è³´ç®¡ç†ã€ä¸¦è¡ŒåŸ·è¡Œå’ŒéŒ¯èª¤æ¢å¾©

ä½¿ç”¨æ–¹å¼ï¼š
    dispatcher = Dispatcher()
    result = await dispatcher.run("åˆ†æ AI æ™¶ç‰‡å¸‚å ´æ ¼å±€")
"""

import os
import json
import asyncio
import uuid
from enum import Enum, auto
from dataclasses import dataclass, field
from datetime import datetime
from typing import Optional, Callable, Any
from collections import defaultdict
from dotenv import load_dotenv
from openai import AsyncOpenAI

load_dotenv()


# =============================================================================
# ç‹€æ…‹èˆ‡äº‹ä»¶å®šç¾©
# =============================================================================

class TaskState(Enum):
    """ä»»å‹™ç‹€æ…‹"""
    PENDING = auto()
    PLANNING = auto()
    READY = auto()
    RUNNING = auto()
    WAITING = auto()  # ç­‰å¾…ä¾è³´
    COMPLETED = auto()
    FAILED = auto()
    CANCELLED = auto()


class TaskEvent(Enum):
    """ä»»å‹™äº‹ä»¶"""
    CREATED = "created"
    STARTED = "started"
    PROGRESS = "progress"
    COMPLETED = "completed"
    FAILED = "failed"
    RETRYING = "retrying"


# =============================================================================
# è³‡æ–™çµæ§‹
# =============================================================================

@dataclass
class Task:
    """ä»»å‹™è³‡æ–™çµæ§‹"""
    id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    query: str = ""
    state: TaskState = TaskState.PENDING
    priority: int = 5
    parent_id: Optional[str] = None
    children: list = field(default_factory=list)
    dependencies: list = field(default_factory=list)
    result: Optional[dict] = None
    error: Optional[str] = None
    retry_count: int = 0
    max_retries: int = 3
    created_at: datetime = field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    metadata: dict = field(default_factory=dict)

    def to_dict(self) -> dict:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            "id": self.id,
            "query": self.query,
            "state": self.state.name,
            "priority": self.priority,
            "parent_id": self.parent_id,
            "children": self.children,
            "dependencies": self.dependencies,
            "retry_count": self.retry_count,
            "result": self.result,
            "error": self.error
        }


@dataclass
class ExecutionPlan:
    """åŸ·è¡Œè¨ˆç•«"""
    root_task_id: str
    tasks: dict[str, Task] = field(default_factory=dict)
    execution_order: list[str] = field(default_factory=list)
    dependency_graph: dict = field(default_factory=dict)


# =============================================================================
# äº‹ä»¶ç¸½ç·š
# =============================================================================

class EventBus:
    """äº‹ä»¶ç¸½ç·š"""

    def __init__(self):
        self._handlers: dict[TaskEvent, list[Callable]] = defaultdict(list)

    def subscribe(self, event: TaskEvent, handler: Callable):
        """è¨‚é–±äº‹ä»¶"""
        self._handlers[event].append(handler)

    def publish(self, event: TaskEvent, data: Any):
        """ç™¼å¸ƒäº‹ä»¶"""
        for handler in self._handlers[event]:
            try:
                handler(data)
            except Exception as e:
                print(f"Event handler error: {e}")

    def clear(self):
        """æ¸…é™¤æ‰€æœ‰è¨‚é–±"""
        self._handlers.clear()


# =============================================================================
# ä¾è³´åœ–
# =============================================================================

class DependencyGraph:
    """ä»»å‹™ä¾è³´åœ–"""

    def __init__(self):
        self.nodes: dict[str, set] = {}  # task_id -> set of dependencies
        self.reverse: dict[str, set] = defaultdict(set)  # task_id -> set of dependents

    def add_task(self, task_id: str, dependencies: list[str] = None):
        """æ·»åŠ ä»»å‹™"""
        deps = set(dependencies or [])
        self.nodes[task_id] = deps

        for dep_id in deps:
            self.reverse[dep_id].add(task_id)

    def remove_task(self, task_id: str):
        """ç§»é™¤ä»»å‹™"""
        if task_id in self.nodes:
            for dep_id in self.nodes[task_id]:
                self.reverse[dep_id].discard(task_id)
            del self.nodes[task_id]

        if task_id in self.reverse:
            for dependent_id in self.reverse[task_id]:
                if dependent_id in self.nodes:
                    self.nodes[dependent_id].discard(task_id)
            del self.reverse[task_id]

    def get_ready_tasks(self, completed: set[str]) -> list[str]:
        """ç²å–å¯åŸ·è¡Œçš„ä»»å‹™"""
        ready = []
        for task_id, deps in self.nodes.items():
            if task_id not in completed and deps.issubset(completed):
                ready.append(task_id)
        return ready

    def get_execution_order(self) -> list[str]:
        """ç²å–åŸ·è¡Œé †åºï¼ˆæ‹“æ’²æ’åºï¼‰"""
        in_degree = {tid: len(deps) for tid, deps in self.nodes.items()}
        queue = [tid for tid, deg in in_degree.items() if deg == 0]
        result = []

        while queue:
            current = queue.pop(0)
            result.append(current)

            for dependent in self.reverse.get(current, []):
                in_degree[dependent] -= 1
                if in_degree[dependent] == 0:
                    queue.append(dependent)

        if len(result) != len(self.nodes):
            raise ValueError("Circular dependency detected!")

        return result


# =============================================================================
# ä»»å‹™åŸ·è¡Œå™¨
# =============================================================================

class TaskExecutor:
    """ä»»å‹™åŸ·è¡Œå™¨"""

    def __init__(self, client: AsyncOpenAI, model: str = "gpt-4o-mini"):
        self.client = client
        self.model = model

    async def execute(self, task: Task) -> dict:
        """åŸ·è¡Œä»»å‹™"""
        # æ ¹æ“šä»»å‹™é¡å‹é¸æ“‡åŸ·è¡Œç­–ç•¥
        task_type = task.metadata.get("type", "research")

        if task_type == "search":
            return await self._execute_search(task)
        elif task_type == "analyze":
            return await self._execute_analyze(task)
        elif task_type == "synthesize":
            return await self._execute_synthesize(task)
        else:
            return await self._execute_research(task)

    async def _execute_research(self, task: Task) -> dict:
        """åŸ·è¡Œç ”ç©¶ä»»å‹™"""
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[{
                "role": "user",
                "content": f"è«‹ç ”ç©¶ä»¥ä¸‹å•é¡Œä¸¦æä¾›è©³ç´°åˆ†æï¼š\n\n{task.query}"
            }],
            temperature=0.3
        )

        return {
            "type": "research",
            "content": response.choices[0].message.content,
            "tokens_used": response.usage.total_tokens if response.usage else 0
        }

    async def _execute_search(self, task: Task) -> dict:
        """åŸ·è¡Œæœå°‹ä»»å‹™ï¼ˆæ¨¡æ“¬ï¼‰"""
        # åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒèª¿ç”¨æœå°‹ API
        await asyncio.sleep(0.5)  # æ¨¡æ“¬ç¶²è·¯å»¶é²

        return {
            "type": "search",
            "content": f"æœå°‹çµæœï¼š{task.query}",
            "sources": ["https://example.com/1", "https://example.com/2"]
        }

    async def _execute_analyze(self, task: Task) -> dict:
        """åŸ·è¡Œåˆ†æä»»å‹™"""
        # ç²å–ä¾è³´ä»»å‹™çš„çµæœ
        parent_results = task.metadata.get("parent_results", [])

        context = "\n".join([
            f"è³‡æ–™ {i+1}ï¼š{r.get('content', '')[:500]}"
            for i, r in enumerate(parent_results)
        ])

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[{
                "role": "user",
                "content": f"""åŸºæ–¼ä»¥ä¸‹è³‡æ–™é€²è¡Œåˆ†æï¼š

{context}

åˆ†æä»»å‹™ï¼š{task.query}

è«‹æä¾›çµæ§‹åŒ–çš„åˆ†æçµæœã€‚"""
            }],
            temperature=0.3
        )

        return {
            "type": "analyze",
            "content": response.choices[0].message.content
        }

    async def _execute_synthesize(self, task: Task) -> dict:
        """åŸ·è¡Œç¶œåˆä»»å‹™"""
        parent_results = task.metadata.get("parent_results", [])

        context = "\n\n".join([
            f"## è³‡æ–™ {i+1}\n{r.get('content', '')}"
            for i, r in enumerate(parent_results)
        ])

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[{
                "role": "user",
                "content": f"""è«‹ç¶œåˆä»¥ä¸‹ç ”ç©¶çµæœï¼Œç”Ÿæˆä¸€ä»½å®Œæ•´çš„å ±å‘Šï¼š

{context}

å ±å‘Šä¸»é¡Œï¼š{task.query}

è«‹ç”Ÿæˆä¸€ä»½çµæ§‹åŒ–çš„ç ”ç©¶å ±å‘Šï¼ŒåŒ…å«ï¼š
1. æ‘˜è¦
2. ä¸»è¦ç™¼ç¾
3. åˆ†æ
4. çµè«–èˆ‡å»ºè­°"""
            }],
            temperature=0.3
        )

        return {
            "type": "synthesize",
            "content": response.choices[0].message.content
        }


# =============================================================================
# ä»»å‹™åˆ†è§£å™¨
# =============================================================================

class TaskDecomposer:
    """ä»»å‹™åˆ†è§£å™¨"""

    def __init__(self, client: AsyncOpenAI, model: str = "gpt-4o-mini"):
        self.client = client
        self.model = model

    async def decompose(self, task: Task) -> list[Task]:
        """åˆ†è§£ä»»å‹™ç‚ºå­ä»»å‹™"""

        prompt = f"""ä½ æ˜¯ä¸€ä½ä»»å‹™è¦åŠƒå°ˆå®¶ã€‚è«‹å°‡ä»¥ä¸‹ç ”ç©¶ä»»å‹™åˆ†è§£ç‚ºå¯åŸ·è¡Œçš„å­ä»»å‹™ã€‚

ç ”ç©¶ä»»å‹™ï¼š{task.query}

è«‹åˆ†è§£ç‚º 3-6 å€‹å­ä»»å‹™ï¼Œæ¯å€‹å­ä»»å‹™æ‡‰è©²ï¼š
1. å…·é«”ä¸”å¯ç¨ç«‹åŸ·è¡Œ
2. æ¶µè“‹å•é¡Œçš„ä¸åŒé¢å‘
3. æœ‰æ˜ç¢ºçš„ç”¢å‡ºç‰©

è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºï¼š
```json
{{
  "subtasks": [
    {{
      "id": "1",
      "query": "å­ä»»å‹™æè¿°",
      "type": "search|analyze|synthesize",
      "priority": 1-10,
      "dependencies": []
    }}
  ],
  "final_task": {{
    "query": "æ•´åˆæ‰€æœ‰çµæœçš„æœ€çµ‚ä»»å‹™æè¿°",
    "dependencies": ["æ‰€æœ‰å­ä»»å‹™çš„ id"]
  }}
}}
```"""

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        content = response.choices[0].message.content

        # è§£æ JSON
        import re
        json_match = re.search(r'```json\s*([\s\S]*?)\s*```', content)
        if json_match:
            data = json.loads(json_match.group(1))
        else:
            try:
                data = json.loads(content)
            except:
                # é™ç´šï¼šä¸åˆ†è§£ï¼Œç›´æ¥åŸ·è¡Œ
                return []

        subtasks = []

        for st in data.get("subtasks", []):
            subtask = Task(
                id=f"{task.id}-{st['id']}",
                query=st["query"],
                priority=st.get("priority", 5),
                parent_id=task.id,
                dependencies=[f"{task.id}-{d}" for d in st.get("dependencies", [])],
                metadata={"type": st.get("type", "research")}
            )
            subtasks.append(subtask)

        # æ·»åŠ æœ€çµ‚æ•´åˆä»»å‹™
        final = data.get("final_task", {})
        if final:
            final_task = Task(
                id=f"{task.id}-final",
                query=final.get("query", f"æ•´åˆ {task.query} çš„ç ”ç©¶çµæœ"),
                priority=1,  # æœ€é«˜å„ªå…ˆç´š
                parent_id=task.id,
                dependencies=[f"{task.id}-{d}" for d in final.get("dependencies", [])],
                metadata={"type": "synthesize"}
            )
            subtasks.append(final_task)

        return subtasks


# =============================================================================
# æ ¸å¿ƒèª¿åº¦å™¨
# =============================================================================

class Dispatcher:
    """
    æ ¸å¿ƒèª¿åº¦å™¨

    è² è²¬ä»»å‹™çš„æ¥æ”¶ã€åˆ†è§£ã€èª¿åº¦å’Œç›£æ§
    """

    def __init__(
        self,
        model: str = "gpt-4o-mini",
        max_concurrent: int = 5,
        task_timeout: float = 300.0,
        verbose: bool = True
    ):
        self.client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = model
        self.max_concurrent = max_concurrent
        self.task_timeout = task_timeout
        self.verbose = verbose

        # çµ„ä»¶
        self.executor = TaskExecutor(self.client, model)
        self.decomposer = TaskDecomposer(self.client, model)
        self.event_bus = EventBus()

        # ç‹€æ…‹
        self.tasks: dict[str, Task] = {}
        self.dependency_graph = DependencyGraph()
        self.completed_tasks: set[str] = set()
        self.failed_tasks: set[str] = set()

        # ä¸¦ç™¼æ§åˆ¶
        self.semaphore = asyncio.Semaphore(max_concurrent)

        # çµ±è¨ˆ
        self.stats = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "total_retries": 0,
            "start_time": None,
            "end_time": None
        }

        # è¨­ç½®äº‹ä»¶è™•ç†
        self._setup_event_handlers()

    def _setup_event_handlers(self):
        """è¨­ç½®äº‹ä»¶è™•ç†å™¨"""
        self.event_bus.subscribe(
            TaskEvent.COMPLETED,
            lambda data: self._log(f"âœ… ä»»å‹™å®Œæˆï¼š{data['task_id']}")
        )
        self.event_bus.subscribe(
            TaskEvent.FAILED,
            lambda data: self._log(f"âŒ ä»»å‹™å¤±æ•—ï¼š{data['task_id']} - {data.get('error', 'Unknown')}")
        )
        self.event_bus.subscribe(
            TaskEvent.RETRYING,
            lambda data: self._log(f"ğŸ”„ é‡è©¦ä»»å‹™ï¼š{data['task_id']} (ç¬¬ {data['retry_count']} æ¬¡)")
        )

    async def run(self, query: str) -> dict:
        """
        åŸ·è¡Œç ”ç©¶ä»»å‹™

        Args:
            query: ç ”ç©¶å•é¡Œ

        Returns:
            ç ”ç©¶çµæœå­—å…¸
        """
        self.stats["start_time"] = datetime.now()

        self._log(f"\n{'='*60}")
        self._log(f"ğŸš€ é–‹å§‹èª¿åº¦ï¼š{query}")
        self._log(f"{'='*60}\n")

        try:
            # 1. å‰µå»ºæ ¹ä»»å‹™
            root_task = Task(query=query)
            self.tasks[root_task.id] = root_task
            self.stats["total_tasks"] += 1

            # 2. ä»»å‹™åˆ†è§£
            await self._plan_task(root_task)

            # 3. åŸ·è¡Œä»»å‹™
            await self._execute_all()

            # 4. æ”¶é›†çµæœ
            result = self._collect_results(root_task.id)

            self.stats["end_time"] = datetime.now()

            self._log(f"\n{'='*60}")
            self._log(f"âœ… èª¿åº¦å®Œæˆ")
            self._log(self._format_stats())
            self._log(f"{'='*60}\n")

            return result

        except Exception as e:
            self._log(f"âŒ èª¿åº¦å¤±æ•—ï¼š{e}")
            raise

    async def _plan_task(self, task: Task):
        """è¦åŠƒä»»å‹™"""
        task.state = TaskState.PLANNING
        self._log(f"ğŸ“‹ è¦åŠƒä»»å‹™ï¼š{task.query[:50]}...")

        # åˆ†è§£ä»»å‹™
        subtasks = await self.decomposer.decompose(task)

        if not subtasks:
            # ä¸éœ€è¦åˆ†è§£ï¼Œç›´æ¥åŸ·è¡Œ
            self.dependency_graph.add_task(task.id, [])
            task.state = TaskState.READY
            return

        # æ·»åŠ å­ä»»å‹™
        for subtask in subtasks:
            self.tasks[subtask.id] = subtask
            self.stats["total_tasks"] += 1
            self.dependency_graph.add_task(subtask.id, subtask.dependencies)
            task.children.append(subtask.id)

        self._log(f"   ğŸ“Š åˆ†è§£ç‚º {len(subtasks)} å€‹å­ä»»å‹™")

        # æ‰“å°åŸ·è¡Œé †åº
        order = self.dependency_graph.get_execution_order()
        self._log(f"   ğŸ“ åŸ·è¡Œé †åºï¼š{' â†’ '.join(order)}")

        task.state = TaskState.WAITING

    async def _execute_all(self):
        """åŸ·è¡Œæ‰€æœ‰ä»»å‹™"""
        self._log("\nğŸ“ é–‹å§‹åŸ·è¡Œä»»å‹™")

        while True:
            # ç²å–å¯åŸ·è¡Œçš„ä»»å‹™
            ready = self.dependency_graph.get_ready_tasks(self.completed_tasks)
            ready = [tid for tid in ready if tid not in self.failed_tasks]

            if not ready:
                # æª¢æŸ¥æ˜¯å¦é‚„æœ‰æœªå®Œæˆçš„ä»»å‹™
                pending = set(self.dependency_graph.nodes.keys()) - self.completed_tasks - self.failed_tasks
                if not pending:
                    break
                # æœ‰ä»»å‹™ä½†ç„¡æ³•åŸ·è¡Œï¼ˆå¯èƒ½æ˜¯ä¾è³´å¤±æ•—ï¼‰
                self._log("âš ï¸ éƒ¨åˆ†ä»»å‹™å› ä¾è³´å¤±æ•—è€Œç„¡æ³•åŸ·è¡Œ")
                break

            # ä¸¦è¡ŒåŸ·è¡Œ
            await self._execute_batch(ready)

    async def _execute_batch(self, task_ids: list[str]):
        """æ‰¹æ¬¡åŸ·è¡Œä»»å‹™"""
        self._log(f"\n   ğŸ”„ ä¸¦è¡ŒåŸ·è¡Œ {len(task_ids)} å€‹ä»»å‹™")

        async def execute_single(task_id: str):
            async with self.semaphore:
                return await self._execute_task(task_id)

        results = await asyncio.gather(
            *[execute_single(tid) for tid in task_ids],
            return_exceptions=True
        )

        for task_id, result in zip(task_ids, results):
            if isinstance(result, Exception):
                self._log(f"      âŒ {task_id}: {result}")
            else:
                self._log(f"      âœ… {task_id}: å®Œæˆ")

    async def _execute_task(self, task_id: str) -> dict:
        """åŸ·è¡Œå–®å€‹ä»»å‹™"""
        task = self.tasks[task_id]
        task.state = TaskState.RUNNING
        task.started_at = datetime.now()

        # æ”¶é›†ä¾è³´ä»»å‹™çš„çµæœ
        if task.dependencies:
            parent_results = []
            for dep_id in task.dependencies:
                if dep_id in self.tasks:
                    dep_result = self.tasks[dep_id].result
                    if dep_result:
                        parent_results.append(dep_result)
            task.metadata["parent_results"] = parent_results

        try:
            # åŸ·è¡Œä»»å‹™
            result = await asyncio.wait_for(
                self.executor.execute(task),
                timeout=self.task_timeout
            )

            task.result = result
            task.state = TaskState.COMPLETED
            task.completed_at = datetime.now()
            self.completed_tasks.add(task_id)
            self.stats["completed_tasks"] += 1

            self.event_bus.publish(TaskEvent.COMPLETED, {"task_id": task_id})

            return result

        except asyncio.TimeoutError:
            return await self._handle_task_failure(task, "Task timeout")

        except Exception as e:
            return await self._handle_task_failure(task, str(e))

    async def _handle_task_failure(self, task: Task, error: str) -> dict:
        """è™•ç†ä»»å‹™å¤±æ•—"""
        task.error = error
        task.retry_count += 1
        self.stats["total_retries"] += 1

        if task.retry_count <= task.max_retries:
            # é‡è©¦
            self.event_bus.publish(TaskEvent.RETRYING, {
                "task_id": task.id,
                "retry_count": task.retry_count,
                "error": error
            })

            # æŒ‡æ•¸é€€é¿
            await asyncio.sleep(2 ** task.retry_count)

            return await self._execute_task(task.id)

        else:
            # æ¨™è¨˜å¤±æ•—
            task.state = TaskState.FAILED
            self.failed_tasks.add(task.id)
            self.stats["failed_tasks"] += 1

            self.event_bus.publish(TaskEvent.FAILED, {
                "task_id": task.id,
                "error": error
            })

            return {"error": error}

    def _collect_results(self, root_task_id: str) -> dict:
        """æ”¶é›†çµæœ"""
        root_task = self.tasks[root_task_id]

        # æ‰¾åˆ°æœ€çµ‚ä»»å‹™
        final_task_id = f"{root_task_id}-final"
        if final_task_id in self.tasks:
            final_task = self.tasks[final_task_id]
            if final_task.result:
                return {
                    "success": True,
                    "content": final_task.result.get("content", ""),
                    "subtask_count": len(root_task.children),
                    "stats": self.stats
                }

        # å¦‚æœæ²’æœ‰æœ€çµ‚ä»»å‹™ï¼Œæ”¶é›†æ‰€æœ‰å­ä»»å‹™çµæœ
        contents = []
        for child_id in root_task.children:
            if child_id in self.tasks:
                child = self.tasks[child_id]
                if child.result:
                    contents.append(child.result.get("content", ""))

        return {
            "success": len(self.failed_tasks) == 0,
            "content": "\n\n---\n\n".join(contents) if contents else "No results",
            "subtask_count": len(root_task.children),
            "stats": self.stats
        }

    def _format_stats(self) -> str:
        """æ ¼å¼åŒ–çµ±è¨ˆè³‡è¨Š"""
        duration = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()

        return f"""
   ğŸ“Š åŸ·è¡Œçµ±è¨ˆ
   â”œâ”€â”€ ç¸½ä»»å‹™æ•¸ï¼š{self.stats['total_tasks']}
   â”œâ”€â”€ å®Œæˆä»»å‹™ï¼š{self.stats['completed_tasks']}
   â”œâ”€â”€ å¤±æ•—ä»»å‹™ï¼š{self.stats['failed_tasks']}
   â”œâ”€â”€ ç¸½é‡è©¦æ¬¡æ•¸ï¼š{self.stats['total_retries']}
   â””â”€â”€ ç¸½è€—æ™‚ï¼š{duration:.1f} ç§’"""

    def _log(self, message: str):
        """è¼¸å‡ºæ—¥èªŒ"""
        if self.verbose:
            print(message)

    def get_task_tree(self, task_id: str = None) -> dict:
        """ç²å–ä»»å‹™æ¨¹ï¼ˆç”¨æ–¼å¯è¦–åŒ–ï¼‰"""
        if task_id is None:
            # æ‰¾åˆ°æ ¹ä»»å‹™
            root_tasks = [t for t in self.tasks.values() if t.parent_id is None]
            if not root_tasks:
                return {}
            task_id = root_tasks[0].id

        task = self.tasks.get(task_id)
        if not task:
            return {}

        return {
            "id": task.id,
            "query": task.query[:50] + "..." if len(task.query) > 50 else task.query,
            "state": task.state.name,
            "children": [self.get_task_tree(cid) for cid in task.children]
        }


# =============================================================================
# ä¸»ç¨‹å¼
# =============================================================================

async def main():
    """ä¸»ç¨‹å¼"""
    import argparse

    parser = argparse.ArgumentParser(description="æ·±åº¦ç ”ç©¶èª¿åº¦å™¨")
    parser.add_argument("-q", "--query", type=str, help="ç ”ç©¶å•é¡Œ")
    parser.add_argument("--model", default="gpt-4o-mini", help="ä½¿ç”¨çš„æ¨¡å‹")
    parser.add_argument("--max-concurrent", type=int, default=5, help="æœ€å¤§ä¸¦ç™¼æ•¸")
    parser.add_argument("-o", "--output", type=str, help="è¼¸å‡ºæª”æ¡ˆ")

    args = parser.parse_args()

    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ è«‹è¨­å®š OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")
        return

    dispatcher = Dispatcher(
        model=args.model,
        max_concurrent=args.max_concurrent,
        verbose=True
    )

    query = args.query or "åˆ†æ 2024 å¹´å…¨çƒ AI æ™¶ç‰‡å¸‚å ´æ ¼å±€ï¼ŒåŒ…æ‹¬ä¸»è¦ç©å®¶å’ŒæŠ€è¡“è¶¨å‹¢"

    result = await dispatcher.run(query)

    print("\n" + "="*60)
    print("ğŸ“„ ç ”ç©¶å ±å‘Š")
    print("="*60)
    print(result.get("content", "No content"))

    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(result.get("content", ""))
        print(f"\nğŸ“„ å ±å‘Šå·²ä¿å­˜è‡³ï¼š{args.output}")


if __name__ == "__main__":
    asyncio.run(main())
