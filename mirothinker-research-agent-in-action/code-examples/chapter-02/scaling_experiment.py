"""
scaling_experiment.py

æ¸¬é‡ä»£ç†äººäº¤äº’ç¸®æ”¾æ•ˆç›Šçš„å¯¦é©—æ¡†æ¶

ä¾†æºï¼šã€Šæ·±åº¦ç ”ç©¶ä»£ç†äººå¯¦æˆ°ã€‹ç¬¬ 2 ç« 
æˆæ¬Šï¼šMIT License

åŠŸèƒ½ï¼š
- æ¯”è¼ƒä¸åŒæ¨¡å‹å¤§å°å’Œäº¤äº’æ¬¡æ•¸é…ç½®çš„æ•ˆèƒ½
- è‡ªå‹•è¿½è¹¤ Token æ¶ˆè€—å’Œæ™‚é–“æˆæœ¬
- ç”Ÿæˆæ¯”è¼ƒå ±å‘Š
"""

import os
import json
import time
import re
from dataclasses import dataclass, field
from typing import Optional, Callable, Any
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv
import httpx

load_dotenv()


# ============================================================
# è³‡æ–™çµæ§‹
# ============================================================

@dataclass
class ExperimentConfig:
    """å¯¦é©—é…ç½®"""
    name: str
    model: str
    max_interactions: int
    temperature: float = 0.1
    description: str = ""

    def __str__(self):
        return f"{self.name} ({self.model}, max={self.max_interactions})"


@dataclass
class TaskResult:
    """å–®ä¸€ä»»å‹™çš„åŸ·è¡Œçµæœ"""
    task_id: str
    question: str
    answer: str
    interactions_used: int
    tokens_consumed: int
    time_seconds: float
    sources_cited: int
    search_queries: list[str] = field(default_factory=list)
    config_name: str = ""

    def to_dict(self) -> dict:
        return {
            "task_id": self.task_id,
            "question": self.question,
            "answer": self.answer[:200] + "..." if len(self.answer) > 200 else self.answer,
            "interactions_used": self.interactions_used,
            "tokens_consumed": self.tokens_consumed,
            "time_seconds": round(self.time_seconds, 2),
            "sources_cited": self.sources_cited,
            "search_queries": self.search_queries,
            "config_name": self.config_name
        }


@dataclass
class ExperimentResult:
    """å¯¦é©—ç¸½çµæœ"""
    config: ExperimentConfig
    task_results: list[TaskResult] = field(default_factory=list)
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None

    @property
    def avg_interactions(self) -> float:
        if not self.task_results:
            return 0
        return sum(r.interactions_used for r in self.task_results) / len(self.task_results)

    @property
    def avg_time(self) -> float:
        if not self.task_results:
            return 0
        return sum(r.time_seconds for r in self.task_results) / len(self.task_results)

    @property
    def total_tokens(self) -> int:
        return sum(r.tokens_consumed for r in self.task_results)

    @property
    def avg_sources(self) -> float:
        if not self.task_results:
            return 0
        return sum(r.sources_cited for r in self.task_results) / len(self.task_results)

    @property
    def total_time(self) -> float:
        return sum(r.time_seconds for r in self.task_results)

    def to_dict(self) -> dict:
        return {
            "config": str(self.config),
            "task_count": len(self.task_results),
            "avg_interactions": round(self.avg_interactions, 2),
            "avg_time": round(self.avg_time, 2),
            "total_tokens": self.total_tokens,
            "avg_sources": round(self.avg_sources, 2),
            "total_time": round(self.total_time, 2)
        }


# ============================================================
# æœå°‹å·¥å…·
# ============================================================

class SearchTool:
    """æœå°‹å·¥å…·ï¼ˆæ”¯æ´çœŸå¯¦ API å’Œæ¨¡æ“¬æ¨¡å¼ï¼‰"""

    def __init__(self, use_mock: bool = False):
        self.api_key = os.getenv("SERPER_API_KEY")
        self.use_mock = use_mock or not self.api_key
        self.base_url = "https://google.serper.dev/search"

        if self.use_mock:
            print("âš ï¸ æœå°‹å·¥å…·ä½¿ç”¨æ¨¡æ“¬æ¨¡å¼")

    def search(self, query: str, num_results: int = 3) -> str:
        if self.use_mock:
            return self._mock_search(query)

        headers = {
            "X-API-KEY": self.api_key,
            "Content-Type": "application/json"
        }
        payload = {"q": query, "num": num_results}

        try:
            response = httpx.post(
                self.base_url,
                headers=headers,
                json=payload,
                timeout=30.0
            )
            response.raise_for_status()
            data = response.json()

            results = []
            for item in data.get("organic", [])[:num_results]:
                results.append(
                    f"æ¨™é¡Œ: {item.get('title', 'N/A')}\n"
                    f"æ‘˜è¦: {item.get('snippet', 'N/A')}"
                )

            return "\n---\n".join(results) if results else "æœªæ‰¾åˆ°ç›¸é—œçµæœ"

        except Exception as e:
            return f"æœå°‹éŒ¯èª¤: {str(e)}"

    def _mock_search(self, query: str) -> str:
        """æ¨¡æ“¬æœå°‹çµæœ"""
        return f"""æ¨™é¡Œ: é—œæ–¼ã€Œ{query}ã€çš„æœå°‹çµæœ
æ‘˜è¦: é€™æ˜¯æ¨¡æ“¬çš„æœå°‹çµæœã€‚åŒ…å«èˆ‡ã€Œ{query}ã€ç›¸é—œçš„è³‡è¨Šã€‚åœ¨å¯¦éš›ä½¿ç”¨ä¸­ï¼Œé€™è£¡æœƒé¡¯ç¤ºçœŸå¯¦çš„ç¶²è·¯æœå°‹çµæœã€‚

---

æ¨™é¡Œ: {query} - ç›¸é—œè³‡æ–™
æ‘˜è¦: æ›´å¤šé—œæ–¼æ­¤ä¸»é¡Œçš„è©³ç´°è³‡è¨Šã€‚æ¨¡æ“¬æ¨¡å¼ä¸‹ç„¡æ³•ç²å–çœŸå¯¦æ•¸æ“šï¼Œä½†å¯ä»¥æ¸¬è©¦ä»£ç†äººçš„åŸºæœ¬æµç¨‹ã€‚"""


# ============================================================
# å¯é…ç½®çš„ä»£ç†äºº
# ============================================================

class ConfigurableAgent:
    """
    å¯é…ç½®çš„ä»£ç†äººï¼Œç”¨æ–¼ç¸®æ”¾å¯¦é©—

    ç‰¹é»ï¼š
    - å¯é…ç½®æœ€å¤§äº¤äº’æ¬¡æ•¸
    - è¿½è¹¤ Token æ¶ˆè€—
    - è¨˜éŒ„æœå°‹æŸ¥è©¢
    """

    def __init__(self, config: ExperimentConfig, search_tool: SearchTool):
        self.config = config
        self.client = OpenAI()
        self.search_tool = search_tool
        self.interaction_count = 0
        self.token_count = 0
        self.search_queries: list[str] = []

    def reset_counters(self):
        """é‡ç½®è¨ˆæ•¸å™¨"""
        self.interaction_count = 0
        self.token_count = 0
        self.search_queries = []

    def _build_system_prompt(self) -> str:
        """æ§‹å»ºç³»çµ±æç¤ºè©"""
        return f"""ä½ æ˜¯ä¸€å€‹ç ”ç©¶åŠ©ç†ä»£ç†äººï¼Œä½¿ç”¨ ReAct æ¨¡å¼å·¥ä½œã€‚

## äº¤äº’é™åˆ¶
- ä½ æœ€å¤šå¯ä»¥é€²è¡Œ {self.config.max_interactions} æ¬¡æœå°‹
- è«‹é«˜æ•ˆä½¿ç”¨æœå°‹æ¬¡æ•¸ï¼Œé¿å…é‡è¤‡æŸ¥è©¢
- å¦‚æœè³‡è¨Šè¶³å¤ ï¼Œå„˜æ—©çµ¦å‡ºç­”æ¡ˆ

## å¯ç”¨å·¥å…·

### search
æœå°‹ç¶²è·¯ç²å–è³‡è¨Š
æ ¼å¼ï¼šAction: search[æœå°‹é—œéµå­—]

## å›æ‡‰æ ¼å¼

æœå°‹æ™‚ï¼š
```
Thought: [åˆ†æç•¶å‰ç‹€æ…‹ï¼Œèªªæ˜ç‚ºä½•éœ€è¦æœå°‹]
Action: search[ç²¾ç¢ºçš„æœå°‹é—œéµå­—]
```

å›ç­”æ™‚ï¼š
```
Thought: [ç¸½çµå·²ç²å¾—çš„è³‡è¨Š]
Answer: [å®Œæ•´çš„ç­”æ¡ˆ]
å¼•ç”¨ä¾†æºæ•¸ï¼š[æ•¸å­—]
```

## é‡è¦åŸå‰‡
1. æ¯æ¬¡åªåŸ·è¡Œä¸€å€‹æœå°‹
2. æœå°‹é—œéµå­—è¦ç²¾ç¢ºï¼Œé¿å…éæ–¼å¯¬æ³›
3. ç­”æ¡ˆè¦åŸºæ–¼æœå°‹çµæœ
4. å¦‚æœè³‡è¨Šä¸è¶³ä½†å·²é”åˆ°æœå°‹ä¸Šé™ï¼Œèª å¯¦èªªæ˜
5. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”
"""

    def run(self, question: str) -> tuple[str, int]:
        """
        åŸ·è¡Œä»£ç†äºº

        Returns:
            (ç­”æ¡ˆ, å¼•ç”¨ä¾†æºæ•¸é‡)
        """
        self.reset_counters()

        messages = [
            {"role": "system", "content": self._build_system_prompt()},
            {"role": "user", "content": f"è«‹ç ”ç©¶ä¸¦å›ç­”ä»¥ä¸‹å•é¡Œï¼š\n\n{question}"}
        ]

        while self.interaction_count < self.config.max_interactions + 10:  # +10 for non-search iterations
            try:
                response = self.client.chat.completions.create(
                    model=self.config.model,
                    messages=messages,
                    temperature=self.config.temperature,
                    max_tokens=1500
                )
            except Exception as e:
                return f"API éŒ¯èª¤: {str(e)}", 0

            self.token_count += response.usage.total_tokens
            content = response.choices[0].message.content
            messages.append({"role": "assistant", "content": content})

            # è§£æå›æ‡‰
            if "Answer:" in content:
                # æå–ç­”æ¡ˆ
                answer_match = re.search(r'Answer:\s*(.+?)(?=å¼•ç”¨ä¾†æºæ•¸|$)', content, re.DOTALL)
                answer = answer_match.group(1).strip() if answer_match else content

                # æå–å¼•ç”¨æ•¸é‡
                source_match = re.search(r'å¼•ç”¨ä¾†æºæ•¸[ï¼š:]\s*(\d+)', content)
                sources = int(source_match.group(1)) if source_match else len(self.search_queries)

                return answer, sources

            elif "Action: search[" in content:
                # æª¢æŸ¥æ˜¯å¦é”åˆ°æœå°‹ä¸Šé™
                if self.interaction_count >= self.config.max_interactions:
                    messages.append({
                        "role": "user",
                        "content": f"å·²é”åˆ°æœå°‹ä¸Šé™ï¼ˆ{self.config.max_interactions} æ¬¡ï¼‰ã€‚è«‹æ ¹æ“šç¾æœ‰è³‡è¨Šçµ¦å‡ºç­”æ¡ˆï¼Œæ ¼å¼ï¼šAnswer: [ç­”æ¡ˆ]\nå¼•ç”¨ä¾†æºæ•¸ï¼š[æ•¸å­—]"
                    })
                    continue

                # æå–æœå°‹æŸ¥è©¢
                match = re.search(r'Action: search\[(.+?)\]', content)
                if match:
                    query = match.group(1)
                    self.search_queries.append(query)
                    self.interaction_count += 1

                    # åŸ·è¡Œæœå°‹
                    result = self.search_tool.search(query)
                    messages.append({
                        "role": "user",
                        "content": f"Observation:\n{result}\n\nï¼ˆå·²ä½¿ç”¨ {self.interaction_count}/{self.config.max_interactions} æ¬¡æœå°‹ï¼‰"
                    })
                else:
                    messages.append({
                        "role": "user",
                        "content": "ç„¡æ³•è§£ææœå°‹æ ¼å¼ï¼Œè«‹ä½¿ç”¨ï¼šAction: search[é—œéµå­—]"
                    })

            else:
                # æç¤ºæ ¼å¼
                messages.append({
                    "role": "user",
                    "content": "è«‹ä½¿ç”¨æ­£ç¢ºæ ¼å¼ï¼š\n- æœå°‹ï¼šAction: search[é—œéµå­—]\n- å›ç­”ï¼šAnswer: [ç­”æ¡ˆ]"
                })

        return "é”åˆ°è¿­ä»£ä¸Šé™", len(self.search_queries)


# ============================================================
# å¯¦é©—åŸ·è¡Œå™¨
# ============================================================

class ScalingExperiment:
    """
    ç¸®æ”¾å¯¦é©—åŸ·è¡Œå™¨

    ç”¨æ–¼æ¯”è¼ƒä¸åŒé…ç½®ä¸‹ä»£ç†äººçš„è¡¨ç¾
    """

    def __init__(self, tasks: list[str], use_mock_search: bool = False):
        self.tasks = tasks
        self.search_tool = SearchTool(use_mock=use_mock_search)
        self.results: list[ExperimentResult] = []

    def run_config(self, config: ExperimentConfig, verbose: bool = True) -> ExperimentResult:
        """åŸ·è¡Œå–®ä¸€é…ç½®çš„å¯¦é©—"""
        if verbose:
            print(f"\n{'='*60}")
            print(f"ğŸ”¬ åŸ·è¡Œé…ç½®: {config.name}")
            print(f"   æ¨¡å‹: {config.model}")
            print(f"   æœ€å¤§äº¤äº’: {config.max_interactions}")
            print(f"{'='*60}")

        agent = ConfigurableAgent(config, self.search_tool)
        experiment_result = ExperimentResult(config=config)

        for i, task in enumerate(self.tasks, 1):
            if verbose:
                print(f"\nğŸ“ ä»»å‹™ {i}/{len(self.tasks)}: {task[:50]}...")

            start_time = time.time()
            answer, sources = agent.run(task)
            elapsed = time.time() - start_time

            result = TaskResult(
                task_id=f"task_{i}",
                question=task,
                answer=answer,
                interactions_used=agent.interaction_count,
                tokens_consumed=agent.token_count,
                time_seconds=elapsed,
                sources_cited=sources,
                search_queries=agent.search_queries.copy(),
                config_name=config.name
            )

            experiment_result.task_results.append(result)

            if verbose:
                print(f"   â±ï¸  è€—æ™‚: {elapsed:.2f}s")
                print(f"   ğŸ”„ æœå°‹æ¬¡æ•¸: {agent.interaction_count}")
                print(f"   ğŸ“š å¼•ç”¨ä¾†æº: {sources}")
                print(f"   ğŸ’° Token: {agent.token_count}")

        experiment_result.end_time = datetime.now()
        self.results.append(experiment_result)
        return experiment_result

    def run_all(self, configs: list[ExperimentConfig], verbose: bool = True) -> list[ExperimentResult]:
        """åŸ·è¡Œæ‰€æœ‰é…ç½®çš„å¯¦é©—"""
        print(f"\nğŸš€ é–‹å§‹ç¸®æ”¾å¯¦é©—")
        print(f"   é…ç½®æ•¸é‡: {len(configs)}")
        print(f"   ä»»å‹™æ•¸é‡: {len(self.tasks)}")

        for config in configs:
            self.run_config(config, verbose)

        return self.results

    def generate_report(self) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼çš„æ¯”è¼ƒå ±å‘Š"""
        lines = []
        lines.append("# ç¸®æ”¾å¯¦é©—çµæœå ±å‘Š")
        lines.append(f"\nç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # å¯¦é©—æ¦‚è¦½
        lines.append("\n## å¯¦é©—æ¦‚è¦½")
        lines.append(f"- æ¸¬è©¦ä»»å‹™æ•¸é‡: {len(self.tasks)}")
        lines.append(f"- é…ç½®æ•¸é‡: {len(self.results)}")

        # é…ç½®æ¯”è¼ƒè¡¨
        lines.append("\n## é…ç½®æ¯”è¼ƒ")
        lines.append("\n| é…ç½® | æ¨¡å‹ | æœ€å¤§äº¤äº’ | å¹³å‡äº¤äº’ | å¹³å‡è€—æ™‚ | ç¸½ Token | å¹³å‡å¼•ç”¨ |")
        lines.append("|------|------|----------|----------|----------|----------|----------|")

        for result in self.results:
            lines.append(
                f"| {result.config.name} | {result.config.model} | "
                f"{result.config.max_interactions} | {result.avg_interactions:.1f} | "
                f"{result.avg_time:.1f}s | {result.total_tokens:,} | {result.avg_sources:.1f} |"
            )

        # æˆæœ¬æ•ˆç›Šåˆ†æ
        lines.append("\n## æˆæœ¬æ•ˆç›Šåˆ†æ")

        # æ¨¡å‹åƒ¹æ ¼ï¼ˆæ¯ 1K tokensï¼Œè¼¸å…¥+è¼¸å‡ºå¹³å‡ï¼‰
        cost_per_1k = {
            "gpt-4o-mini": 0.0003,
            "gpt-4o": 0.0075,
            "gpt-4-turbo": 0.015,
            "gpt-3.5-turbo": 0.001,
        }

        lines.append("\n| é…ç½® | ç¸½ Token | ä¼°ç®—æˆæœ¬ | æˆæœ¬/ä»»å‹™ |")
        lines.append("|------|----------|----------|-----------|")

        for result in self.results:
            model = result.config.model
            rate = cost_per_1k.get(model, 0.001)
            total_cost = result.total_tokens / 1000 * rate
            cost_per_task = total_cost / len(self.tasks) if self.tasks else 0

            lines.append(
                f"| {result.config.name} | {result.total_tokens:,} | "
                f"${total_cost:.4f} | ${cost_per_task:.4f} |"
            )

        # è©³ç´°çµæœ
        lines.append("\n## è©³ç´°çµæœ")

        for result in self.results:
            lines.append(f"\n### {result.config.name}")
            lines.append(f"\n| ä»»å‹™ | æœå°‹æ¬¡æ•¸ | è€—æ™‚ | Token | å¼•ç”¨ |")
            lines.append("|------|----------|------|-------|------|")

            for tr in result.task_results:
                lines.append(
                    f"| {tr.task_id} | {tr.interactions_used} | "
                    f"{tr.time_seconds:.1f}s | {tr.tokens_consumed:,} | {tr.sources_cited} |"
                )

        # çµè«–
        lines.append("\n## çµè«–")

        if len(self.results) >= 2:
            # æ‰¾å‡ºæœ€æœ‰æ•ˆç‡çš„é…ç½®
            sorted_results = sorted(self.results, key=lambda r: r.avg_sources / max(r.avg_time, 0.1), reverse=True)
            best = sorted_results[0]
            lines.append(f"\n- **æœ€ä½³æ•ˆç‡é…ç½®**: {best.config.name}")
            lines.append(f"  - å¹³å‡å¼•ç”¨: {best.avg_sources:.1f} ä¾†æº/ä»»å‹™")
            lines.append(f"  - å¹³å‡è€—æ™‚: {best.avg_time:.1f} ç§’/ä»»å‹™")

            # æ‰¾å‡ºæˆæœ¬æœ€ä½çš„é…ç½®
            sorted_by_cost = sorted(self.results, key=lambda r: r.total_tokens)
            cheapest = sorted_by_cost[0]
            lines.append(f"\n- **æœ€ä½æˆæœ¬é…ç½®**: {cheapest.config.name}")
            lines.append(f"  - ç¸½ Token: {cheapest.total_tokens:,}")

        return "\n".join(lines)

    def save_results(self, filepath: str):
        """å„²å­˜çµæœç‚º JSON"""
        data = {
            "tasks": self.tasks,
            "results": [
                {
                    "config": str(r.config),
                    "summary": r.to_dict(),
                    "task_results": [tr.to_dict() for tr in r.task_results]
                }
                for r in self.results
            ]
        }

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"âœ… çµæœå·²å„²å­˜è‡³ {filepath}")


# ============================================================
# é è¨­æ¸¬è©¦ä»»å‹™
# ============================================================

DEFAULT_TASKS = [
    "2024 å¹´å…¨çƒé›»å‹•è»ŠéŠ·é‡æ’åå‰äº”çš„å“ç‰Œæ˜¯å“ªäº›ï¼Ÿè«‹æä¾›å…·é«”æ•¸æ“šã€‚",
    "æ¯”è¼ƒ OpenAI GPT-4o å’Œ Anthropic Claude 3.5 Sonnet çš„ä¸»è¦å·®ç•°",
    "å°ç©é›» 2024 å¹´ç¬¬ä¸‰å­£çš„ç‡Ÿæ”¶å’Œç²åˆ©è¡¨ç¾å¦‚ä½•ï¼Ÿ",
    "è§£é‡‹ MiroThinker çš„ Interactive Scaling æ¦‚å¿µ",
    "æœ€è¿‘ä¸€å€‹æœˆå…§ï¼Œç¾åœ‹è¯æº–æœƒåšå‡ºäº†å“ªäº›é‡è¦æ±ºç­–ï¼Ÿ"
]


# ============================================================
# ä¸»ç¨‹å¼
# ============================================================

def main():
    """åŸ·è¡Œç¸®æ”¾å¯¦é©—ç¤ºç¯„"""

    print("\n" + "="*60)
    print("ğŸ“Š ä»£ç†äººç¸®æ”¾æ•ˆç›Šå¯¦é©—")
    print("="*60)

    # æª¢æŸ¥ API Key
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ éŒ¯èª¤ï¼šè«‹è¨­å®š OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")
        return

    # ä½¿ç”¨è¼ƒå°‘çš„ä»»å‹™é€²è¡Œç¤ºç¯„
    demo_tasks = DEFAULT_TASKS[:3]

    # å¯¦é©—é…ç½®
    configs = [
        ExperimentConfig(
            name="å°‘äº¤äº’",
            model="gpt-4o-mini",
            max_interactions=3,
            description="æ¨¡æ“¬å¤§æ¨¡å‹å°‘äº¤äº’å ´æ™¯"
        ),
        ExperimentConfig(
            name="ä¸­äº¤äº’",
            model="gpt-4o-mini",
            max_interactions=10,
            description="å¹³è¡¡çš„äº¤äº’æ¬¡æ•¸"
        ),
        ExperimentConfig(
            name="å¤šäº¤äº’",
            model="gpt-4o-mini",
            max_interactions=25,
            description="å……åˆ†åˆ©ç”¨äº¤äº’èƒ½åŠ›"
        ),
    ]

    # åŸ·è¡Œå¯¦é©—ï¼ˆä½¿ç”¨æ¨¡æ“¬æœå°‹ä»¥é¿å… API æˆæœ¬ï¼‰
    use_mock = not os.getenv("SERPER_API_KEY")
    if use_mock:
        print("\nâš ï¸ æœªè¨­å®š SERPER_API_KEYï¼Œä½¿ç”¨æ¨¡æ“¬æœå°‹æ¨¡å¼")

    experiment = ScalingExperiment(demo_tasks, use_mock_search=use_mock)
    experiment.run_all(configs)

    # ç”Ÿæˆå ±å‘Š
    report = experiment.generate_report()
    print("\n" + report)

    # å„²å­˜çµæœ
    report_path = "scaling_experiment_report.md"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report)
    print(f"\nğŸ“„ å ±å‘Šå·²å„²å­˜è‡³ {report_path}")

    # å„²å­˜ JSON çµæœ
    experiment.save_results("scaling_experiment_results.json")


if __name__ == "__main__":
    main()
