# ç¬¬ 5 ç« 
> ğŸ“š **ç« ç¯€å®šä½**ï¼šæœ¬ç« èšç„¦æ•¸æ“šèˆ‡æ–‡ä»¶è™•ç†è‡ªå‹•åŒ–ã€‚çµåˆ **Chapter 4** çš„ç€è¦½å™¨æ¸¬è©¦å’Œæœ¬ç« çš„æ•¸æ“šè™•ç†ï¼Œä½ å°‡å…·å‚™ç«¯åˆ°ç«¯æ¸¬è©¦èƒ½åŠ›ã€‚
ï¼šæ•¸æ“šèˆ‡æ–‡ä»¶è™•ç†è‡ªå‹•åŒ–

åœ¨ç¾ä»£è»Ÿä»¶æ¸¬è©¦èˆ‡è‡ªå‹•åŒ–å·¥ä½œæµä¸­ï¼Œæ•¸æ“šè™•ç†æ˜¯ä¸å¯æˆ–ç¼ºçš„ä¸€ç’°ã€‚æ¸¬è©¦æ•¸æ“šå¯èƒ½ä¾†è‡ª Excel è©¦ç®—è¡¨ã€CSV æª”æ¡ˆã€PDF å ±å‘Šç­‰å¤šç¨®æ ¼å¼ï¼Œè€Œæ¸¬è©¦çµæœä¹Ÿéœ€è¦ä»¥çµæ§‹åŒ–æ–¹å¼è¨˜éŒ„å’Œåˆ†æã€‚æœ¬ç« å°‡æ¢è¨å¦‚ä½•ä½¿ç”¨ Claude Code Skills è‡ªå‹•åŒ–è™•ç†å„ç¨®æ•¸æ“šèˆ‡æ–‡ä»¶æ ¼å¼ï¼Œå¾ Excel/CSV çš„è®€å¯«é©—è­‰ï¼Œåˆ° PDF å…§å®¹æå–èˆ‡é©—è­‰ï¼Œå†åˆ°æ•¸æ“šé©…å‹•æ¸¬è©¦çš„å¯¦è¸ã€‚

## 5.1 Excel/CSV æ•¸æ“šè™•ç† Skills

### 5.1.1 ç‚ºä»€éº¼éœ€è¦è‡ªå‹•åŒ– Excel è™•ç†ï¼Ÿ

Excel åœ¨ä¼æ¥­ç’°å¢ƒä¸­ç„¡è™•ä¸åœ¨ï¼šæ¸¬è©¦æ•¸æ“šå­˜å„²æ–¼ Excel è¡¨æ ¼ã€æ¸¬è©¦çµæœåŒ¯å‡ºç‚º Excel å ±å‘Šã€æ¥­å‹™é‚è¼¯ä¾è³´ Excel è¨ˆç®—ã€‚æ‰‹å‹•è™•ç†é€™äº›æª”æ¡ˆæ—¢è€—æ™‚åˆå®¹æ˜“å‡ºéŒ¯ã€‚é€é Claude Code Skills æ•´åˆ Python çš„æ•¸æ“šè™•ç†èƒ½åŠ›ï¼Œæˆ‘å€‘å¯ä»¥ï¼š

- **æ‰¹é‡è®€å–æ¸¬è©¦æ•¸æ“š**ï¼šå¾ Excel æª”æ¡ˆè®€å–æ•¸ç™¾ç­†æ¸¬è©¦æ¡ˆä¾‹ï¼Œè‡ªå‹•åŸ·è¡Œæ¸¬è©¦
- **é©—è­‰æ•¸æ“šæ ¼å¼**ï¼šç¢ºä¿ä¸Šå‚³çš„ Excel æª”æ¡ˆç¬¦åˆé æœŸçµæ§‹ï¼ˆæ¬„ä½åç¨±ã€æ•¸æ“šé¡å‹ã€å¿…å¡«é …ï¼‰
- **ç”Ÿæˆæ¸¬è©¦å ±å‘Š**ï¼šå°‡æ¸¬è©¦çµæœå¯«å…¥ Excelï¼Œé…åˆåœ–è¡¨å’Œæ ¼å¼åŒ–ï¼Œä¾¿æ–¼åˆ†äº«
- **æ•¸æ“šæ¸…æ´—èˆ‡è½‰æ›**ï¼šè™•ç†ç¼ºå¤±å€¼ã€æ ¼å¼è½‰æ›ã€æ•¸æ“šæ¨™æº–åŒ–

### 5.1.2 æŠ€è¡“é¸å‹ï¼šPandas + openpyxl

Python ç”Ÿæ…‹ç³»çµ±æä¾›äº†å¼·å¤§çš„æ•¸æ“šè™•ç†å·¥å…·ï¼š

- **Pandas**ï¼šæ•¸æ“šåˆ†æåº«ï¼Œæä¾› DataFrame çµæ§‹ï¼Œæ”¯æŒ Excel/CSV è®€å¯«ã€æ•¸æ“šæ¸…æ´—ã€çµ±è¨ˆåˆ†æ
- **openpyxl**ï¼šè®€å¯« Excel 2010+ (.xlsx) æª”æ¡ˆï¼Œæ”¯æŒæ¨£å¼ã€å…¬å¼ã€åœ–è¡¨
- **xlrd/xlwt**ï¼šè™•ç†èˆŠç‰ˆ Excel (.xls)ï¼Œä½†å·²é€æ¼¸è¢« openpyxl å–ä»£

æˆ‘å€‘å°‡ä½¿ç”¨ **Pandas + openpyxl** çµ„åˆï¼Œæ—¢èƒ½é«˜æ•ˆè™•ç†æ•¸æ“šï¼Œåˆèƒ½æ§åˆ¶ Excel æª”æ¡ˆçš„ç´°ç¯€ã€‚

### 5.1.3 å¯¦ä½œï¼šExcelProcessor é¡åˆ¥

ä»¥ä¸‹æ˜¯ç”Ÿç”¢ç´šçš„ Excel è™•ç†å™¨ï¼Œæ¶µè“‹è®€å–ã€å¯«å…¥ã€é©—è­‰ä¸‰å¤§åŠŸèƒ½ï¼š

```python
import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import Font, PatternFill, Alignment
from typing import Dict, List, Any, Optional
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


class ExcelProcessor:
    """
    Excel è™•ç†å™¨ï¼Œæä¾›è®€å¯«ã€é©—è­‰ã€æ ¼å¼åŒ–åŠŸèƒ½

    é©ç”¨æ–¼æ¸¬è©¦æ•¸æ“šç®¡ç†ã€çµæœå ±å‘Šç”Ÿæˆç­‰å ´æ™¯
    """

    def __init__(self, default_sheet: str = "Sheet1"):
        """
        åˆå§‹åŒ– Excel è™•ç†å™¨

        Args:
            default_sheet: é è¨­å·¥ä½œè¡¨åç¨±
        """
        self.default_sheet = default_sheet

    def read_test_data(
        self,
        file_path: str,
        sheet_name: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        è®€å–æ¸¬è©¦æ•¸æ“šï¼Œè½‰æ›ç‚ºå­—å…¸åˆ—è¡¨

        Args:
            file_path: Excel æª”æ¡ˆè·¯å¾‘
            sheet_name: å·¥ä½œè¡¨åç¨±ï¼Œé è¨­ä½¿ç”¨ç¬¬ä¸€å€‹å·¥ä½œè¡¨

        Returns:
            æ¯ç­†è³‡æ–™ç‚ºä¸€å€‹å­—å…¸çš„åˆ—è¡¨

        Example:
            >>> processor = ExcelProcessor()
            >>> data = processor.read_test_data("test_cases.xlsx")
            >>> print(data[0])
            {'username': 'user1', 'password': 'pass123', 'expected': 'success'}
        """
        try:
            df = pd.read_excel(
                file_path,
                sheet_name=sheet_name or 0,
                engine='openpyxl'
            )

            # ç§»é™¤å®Œå…¨ç©ºç™½çš„è¡Œ
            df = df.dropna(how='all')

            # è½‰æ›ç‚ºå­—å…¸åˆ—è¡¨
            records = df.to_dict('records')

            logger.info(
                f"æˆåŠŸè®€å– {len(records)} ç­†æ¸¬è©¦æ•¸æ“š "
                f"å¾ {file_path}"
            )

            return records

        except FileNotFoundError:
            logger.error(f"æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
            raise
        except Exception as e:
            logger.error(f"è®€å– Excel å¤±æ•—: {e}")
            raise

    def write_results(
        self,
        results: List[Dict[str, Any]],
        output_path: str,
        sheet_name: str = "Test Results",
        apply_formatting: bool = True
    ) -> None:
        """
        å¯«å…¥æ¸¬è©¦çµæœåˆ° Excelï¼Œæ”¯æŒè‡ªå‹•æ ¼å¼åŒ–

        Args:
            results: æ¸¬è©¦çµæœåˆ—è¡¨
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
            sheet_name: å·¥ä½œè¡¨åç¨±
            apply_formatting: æ˜¯å¦å¥—ç”¨æ ¼å¼åŒ–ï¼ˆæ¨™é¡Œè¡Œã€æ¢ä»¶æ ¼å¼ï¼‰

        Example:
            >>> results = [
            ...     {'test_name': 'Login Test', 'status': 'PASSED', 'duration_ms': 1234},
            ...     {'test_name': 'Checkout Test', 'status': 'FAILED', 'duration_ms': 5678}
            ... ]
            >>> processor.write_results(results, "test_results.xlsx")
        """
        # å‰µå»º DataFrame
        df = pd.DataFrame(results)

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)

        # å¯«å…¥ Excel
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            df.to_excel(
                writer,
                sheet_name=sheet_name,
                index=False
            )

            # å¥—ç”¨æ ¼å¼åŒ–
            if apply_formatting:
                workbook = writer.book
                worksheet = writer.sheets[sheet_name]

                self._apply_header_formatting(worksheet)
                self._apply_status_formatting(worksheet, df)
                self._auto_adjust_column_width(worksheet, df)

        logger.info(f"æ¸¬è©¦çµæœå·²å¯«å…¥: {output_path}")

    def validate_data(
        self,
        file_path: str,
        schema: Dict[str, Any],
        sheet_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        é©—è­‰ Excel æ•¸æ“šæ ¼å¼æ˜¯å¦ç¬¦åˆé æœŸ

        Args:
            file_path: Excel æª”æ¡ˆè·¯å¾‘
            schema: é©—è­‰è¦å‰‡
                - required_columns: å¿…è¦æ¬„ä½åˆ—è¡¨
                - column_types: æ¬„ä½é¡å‹æ˜ å°„ {'column': dtype}
                - value_ranges: å€¼ç¯„åœé©—è­‰ {'column': {'min': 0, 'max': 100}}
            sheet_name: å·¥ä½œè¡¨åç¨±

        Returns:
            é©—è­‰çµæœå­—å…¸

        Example:
            >>> schema = {
            ...     'required_columns': ['username', 'password'],
            ...     'column_types': {'age': 'int64'},
            ...     'value_ranges': {'age': {'min': 0, 'max': 120}}
            ... }
            >>> result = processor.validate_data("users.xlsx", schema)
            >>> print(result['valid'])  # True/False
        """
        df = pd.read_excel(
            file_path,
            sheet_name=sheet_name or 0,
            engine='openpyxl'
        )

        errors = []
        warnings = []

        # 1. æª¢æŸ¥å¿…è¦æ¬„ä½
        required_columns = schema.get('required_columns', [])
        for col in required_columns:
            if col not in df.columns:
                errors.append(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {col}")

        # 2. æª¢æŸ¥æ•¸æ“šé¡å‹
        column_types = schema.get('column_types', {})
        for col, expected_dtype in column_types.items():
            if col in df.columns:
                actual_dtype = str(df[col].dtype)
                if actual_dtype != expected_dtype:
                    # å˜—è©¦è½‰æ›
                    try:
                        df[col] = df[col].astype(expected_dtype)
                        warnings.append(
                            f"æ¬„ä½ {col} å·²è‡ªå‹•è½‰æ›ç‚º {expected_dtype}"
                        )
                    except (ValueError, TypeError):
                        errors.append(
                            f"æ¬„ä½ {col} é¡å‹éŒ¯èª¤: "
                            f"æœŸæœ› {expected_dtype}, å¯¦éš› {actual_dtype}"
                        )

        # 3. æª¢æŸ¥å€¼ç¯„åœ
        value_ranges = schema.get('value_ranges', {})
        for col, range_spec in value_ranges.items():
            if col in df.columns:
                if 'min' in range_spec:
                    invalid_rows = df[df[col] < range_spec['min']]
                    if not invalid_rows.empty:
                        errors.append(
                            f"æ¬„ä½ {col} æœ‰ {len(invalid_rows)} ç­†è³‡æ–™ "
                            f"å°æ–¼æœ€å°å€¼ {range_spec['min']}"
                        )

                if 'max' in range_spec:
                    invalid_rows = df[df[col] > range_spec['max']]
                    if not invalid_rows.empty:
                        errors.append(
                            f"æ¬„ä½ {col} æœ‰ {len(invalid_rows)} ç­†è³‡æ–™ "
                            f"å¤§æ–¼æœ€å¤§å€¼ {range_spec['max']}"
                        )

        # 4. æª¢æŸ¥ç©ºå€¼
        null_counts = df.isnull().sum()
        columns_with_nulls = null_counts[null_counts > 0]
        if not columns_with_nulls.empty:
            for col, count in columns_with_nulls.items():
                warnings.append(
                    f"æ¬„ä½ {col} æœ‰ {count} ç­†ç©ºå€¼"
                )

        return {
            "valid": len(errors) == 0,
            "errors": errors,
            "warnings": warnings,
            "row_count": len(df),
            "column_count": len(df.columns),
            "columns": list(df.columns)
        }

    def _apply_header_formatting(self, worksheet):
        """å¥—ç”¨æ¨™é¡Œåˆ—æ ¼å¼"""
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_alignment = Alignment(horizontal="center", vertical="center")

        for cell in worksheet[1]:
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = header_alignment

    def _apply_status_formatting(self, worksheet, df):
        """æ ¹æ“šç‹€æ…‹å¥—ç”¨æ¢ä»¶æ ¼å¼"""
        if 'status' not in df.columns:
            return

        status_col_idx = df.columns.get_loc('status') + 1  # openpyxl å¾ 1 é–‹å§‹

        for row_idx in range(2, len(df) + 2):  # å¾ç¬¬ 2 è¡Œé–‹å§‹ï¼ˆç¬¬ 1 è¡Œæ˜¯æ¨™é¡Œï¼‰
            cell = worksheet.cell(row_idx, status_col_idx)
            status = cell.value

            if status == 'PASSED':
                cell.fill = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
                cell.font = Font(color="006100")
            elif status == 'FAILED':
                cell.fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
                cell.font = Font(color="9C0006")
            elif status == 'SKIPPED':
                cell.fill = PatternFill(start_color="FFEB9C", end_color="FFEB9C", fill_type="solid")
                cell.font = Font(color="9C6500")

    def _auto_adjust_column_width(self, worksheet, df):
        """è‡ªå‹•èª¿æ•´æ¬„å¯¬"""
        for column in worksheet.columns:
            max_length = 0
            column_letter = column[0].column_letter

            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass

            adjusted_width = min(max_length + 2, 50)  # æœ€å¤§ 50
            worksheet.column_dimensions[column_letter].width = adjusted_width
```

### 5.1.4 æ•´åˆåˆ° Claude Code Skill

ç¾åœ¨å°‡ ExcelProcessor æ•´åˆåˆ° Skill ä¸­ï¼Œå¯¦ç¾ã€Œè®€å–æ¸¬è©¦æ•¸æ“šä¸¦åŸ·è¡Œæ¸¬è©¦ã€çš„è‡ªå‹•åŒ–æµç¨‹ï¼š

**SKILL.md:**

```markdown
---
name: run-data-driven-tests
description: Execute data-driven tests using test cases from Excel file
parameters:
  - name: excel_file
    description: Path to Excel file containing test cases
    type: string
    required: true
  - name: test_function
    description: Test function name to execute for each case
    type: string
    required: true
---

# Data-Driven Test Execution

This Skill reads test cases from an Excel file and executes the specified test function for each case.

## Expected Excel Format

| username | password | expected_result |
|----------|----------|-----------------|
| user1    | pass123  | success         |
| user2    | wrong    | failure         |

## Execution

The Skill will:
1. Read test cases from Excel
2. Validate data format
3. Execute test function for each case
4. Generate results Excel report
```

**skill.py:**

```python
import sys
import json
from pathlib import Path
from typing import Dict, Any
from excel_processor import ExcelProcessor


def run_data_driven_tests(excel_file: str, test_function: str) -> Dict[str, Any]:
    """
    åŸ·è¡Œæ•¸æ“šé©…å‹•æ¸¬è©¦

    Args:
        excel_file: Excel æ¸¬è©¦æ•¸æ“šæª”æ¡ˆè·¯å¾‘
        test_function: æ¸¬è©¦å‡½æ•¸åç¨±

    Returns:
        æ¸¬è©¦çµæœæ‘˜è¦
    """
    processor = ExcelProcessor()

    # 1. è®€å–æ¸¬è©¦æ•¸æ“š
    try:
        test_cases = processor.read_test_data(excel_file)
    except Exception as e:
        return {
            "success": False,
            "error": f"è®€å–æ¸¬è©¦æ•¸æ“šå¤±æ•—: {str(e)}"
        }

    # 2. é©—è­‰æ•¸æ“šæ ¼å¼
    schema = {
        'required_columns': ['username', 'password', 'expected_result']
    }

    validation = processor.validate_data(excel_file, schema)
    if not validation['valid']:
        return {
            "success": False,
            "error": "æ•¸æ“šé©—è­‰å¤±æ•—",
            "validation_errors": validation['errors']
        }

    # 3. åŸ·è¡Œæ¸¬è©¦ï¼ˆå‹•æ…‹å°å…¥æ¸¬è©¦å‡½æ•¸ï¼‰
    results = []
    test_module = __import__('tests.login_tests', fromlist=[test_function])
    test_func = getattr(test_module, test_function)

    for idx, test_case in enumerate(test_cases, 1):
        try:
            result = test_func(
                username=test_case['username'],
                password=test_case['password']
            )

            status = 'PASSED' if result == test_case['expected_result'] else 'FAILED'

            results.append({
                'case_id': idx,
                'username': test_case['username'],
                'expected': test_case['expected_result'],
                'actual': result,
                'status': status
            })
        except Exception as e:
            results.append({
                'case_id': idx,
                'username': test_case['username'],
                'status': 'ERROR',
                'error': str(e)
            })

    # 4. å¯«å…¥çµæœå ±å‘Š
    output_file = Path(excel_file).stem + "_results.xlsx"
    processor.write_results(results, output_file)

    # 5. çµ±è¨ˆ
    passed = sum(1 for r in results if r['status'] == 'PASSED')
    failed = sum(1 for r in results if r['status'] == 'FAILED')
    errors = sum(1 for r in results if r['status'] == 'ERROR')

    return {
        "success": True,
        "total_cases": len(results),
        "passed": passed,
        "failed": failed,
        "errors": errors,
        "pass_rate": f"{passed / len(results) * 100:.2f}%",
        "report_file": output_file
    }


if __name__ == "__main__":
    params = json.loads(sys.argv[1])
    result = run_data_driven_tests(**params)
    print(json.dumps(result, ensure_ascii=False, indent=2))
```

### 5.1.5 CSV è™•ç†ï¼šè¼•é‡ç´šæ›¿ä»£æ–¹æ¡ˆ

å°æ–¼ä¸éœ€è¦è¤‡é›œæ ¼å¼çš„å ´æ™¯ï¼ŒCSV æ˜¯æ›´è¼•é‡çš„é¸æ“‡ã€‚Pandas åŒæ¨£æ”¯æŒ CSVï¼š

```python
# è®€å– CSV
df = pd.read_csv('test_data.csv', encoding='utf-8')

# å¯«å…¥ CSV
df.to_csv('results.csv', index=False, encoding='utf-8-sig')  # BOM for Excel ç›¸å®¹

# è™•ç†å¤§å‹ CSVï¼ˆåˆ†å¡Šè®€å–ï¼‰
chunk_size = 10000
for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    process_chunk(chunk)
```

**æœ€ä½³å¯¦è¸ï¼š**

- å°æ–¼ 1MB ä¸”ç„¡æ ¼å¼éœ€æ±‚ï¼šä½¿ç”¨ CSV
- éœ€è¦æ ¼å¼åŒ–ã€å¤šå·¥ä½œè¡¨ã€å…¬å¼ï¼šä½¿ç”¨ Excel
- è¶…å¤§æ•¸æ“šï¼ˆç™¾è¬è¡Œï¼‰ï¼šè€ƒæ…®è³‡æ–™åº«æˆ– Parquet æ ¼å¼


## 5.2 PDF æ–‡ä»¶è™•ç†èˆ‡é©—è­‰

### 5.2.1 PDF è™•ç†çš„æ‡‰ç”¨å ´æ™¯

åœ¨æ¸¬è©¦è‡ªå‹•åŒ–ä¸­ï¼ŒPDF è™•ç†å¸¸è¦‹æ–¼ï¼š

- **å ±å‘Šé©—è­‰**ï¼šæ¸¬è©¦ç³»çµ±ç”Ÿæˆçš„ PDF å ±å‘Šæ˜¯å¦åŒ…å«æ­£ç¢ºå…§å®¹
- **æ–‡ä»¶ä¸‹è¼‰æ¸¬è©¦**ï¼šé©—è­‰ä¸‹è¼‰çš„ PDF æª”æ¡ˆå®Œæ•´æ€§å’Œå…§å®¹
- **åˆè¦æª¢æŸ¥**ï¼šç¢ºä¿ PDF åŒ…å«å¿…è¦çš„æ³•å¾‹è²æ˜ã€æ¢æ¬¾
- **æ•¸æ“šæå–**ï¼šå¾ PDF ç™¼ç¥¨ã€å ±è¡¨ä¸­æå–çµæ§‹åŒ–æ•¸æ“šé€²è¡Œé©—è­‰

### 5.2.2 æŠ€è¡“é¸å‹ï¼šPyPDF2 vs pdfplumber vs pdfminer

Python æœ‰å¤šå€‹ PDF è™•ç†åº«ï¼Œå„æœ‰å„ªåŠ£ï¼š

| å·¥å…· | å„ªé» | ç¼ºé» | é©ç”¨å ´æ™¯ |
|------|------|------|----------|
| **PyPDF2** | è¼•é‡ã€æ˜“ç”¨ã€æ”¯æŒåˆä½µåˆ†å‰² | æ–‡æœ¬æå–ä¸ç©©å®š | åŸºæœ¬æ“ä½œã€åˆä½µ PDF |
| **pdfplumber** | è¡¨æ ¼æå–å„ªç§€ã€å¸ƒå±€ä¿ç•™å¥½ | è¼ƒé‡ã€ä¾è³´è¼ƒå¤š | æå–è¡¨æ ¼æ•¸æ“š |
| **pdfminer.six** | æ–‡æœ¬æå–æœ€æº–ç¢ºã€æ”¯æŒä½ˆå±€åˆ†æ | API è¤‡é›œ | ç²¾ç¢ºæ–‡æœ¬æå– |
| **PyMuPDF (fitz)** | é€Ÿåº¦å¿«ã€åŠŸèƒ½å…¨é¢ | C ä¾è³´ã€å®‰è£è¤‡é›œ | é«˜æ€§èƒ½éœ€æ±‚ |

æˆ‘å€‘é¸ç”¨ **pdfminer.six**ï¼ˆæ–‡æœ¬æå–ï¼‰+ **PyPDF2**ï¼ˆåŸºæœ¬æ“ä½œï¼‰çš„çµ„åˆã€‚

### 5.2.3 å¯¦ä½œï¼šPDFValidator é¡åˆ¥

```python
import PyPDF2
from pdfminer.high_level import extract_text, extract_pages
from pdfminer.layout import LTTextContainer, LAParams
from typing import Dict, Any, List, Optional
from pathlib import Path
import re
import logging

logger = logging.getLogger(__name__)


class PDFValidator:
    """
    PDF é©—è­‰å™¨ï¼Œæä¾›å…§å®¹æå–ã€é©—è­‰ã€å…ƒæ•¸æ“šæª¢æŸ¥åŠŸèƒ½

    é©ç”¨æ–¼æ¸¬è©¦å ±å‘Šé©—è­‰ã€æ–‡ä»¶ä¸‹è¼‰æ¸¬è©¦ç­‰å ´æ™¯
    """

    def __init__(self):
        """åˆå§‹åŒ– PDF é©—è­‰å™¨"""
        self.la_params = LAParams(
            line_margin=0.5,
            word_margin=0.1,
            char_margin=2.0,
            boxes_flow=0.5
        )

    def extract_text(self, pdf_path: str, page_numbers: Optional[List[int]] = None) -> str:
        """
        æå– PDF æ–‡æœ¬å…§å®¹

        Args:
            pdf_path: PDF æª”æ¡ˆè·¯å¾‘
            page_numbers: è¦æå–çš„é ç¢¼åˆ—è¡¨ï¼ˆå¾ 1 é–‹å§‹ï¼‰ï¼ŒNone è¡¨ç¤ºå…¨éƒ¨

        Returns:
            æå–çš„æ–‡æœ¬å…§å®¹

        Example:
            >>> validator = PDFValidator()
            >>> text = validator.extract_text("report.pdf", page_numbers=[1, 2])
            >>> print(text[:100])
        """
        try:
            if page_numbers:
                # æå–ç‰¹å®šé é¢ï¼ˆpdfminer é ç¢¼å¾ 1 é–‹å§‹ï¼‰
                text = extract_text(
                    pdf_path,
                    page_numbers=set(page_numbers),
                    laparams=self.la_params
                )
            else:
                # æå–å…¨éƒ¨
                text = extract_text(pdf_path, laparams=self.la_params)

            logger.info(f"æˆåŠŸå¾ {pdf_path} æå– {len(text)} å­—å…ƒ")
            return text

        except Exception as e:
            logger.error(f"PDF æ–‡æœ¬æå–å¤±æ•—: {e}")
            raise

    def validate_content(
        self,
        pdf_path: str,
        expected_content: List[str],
        case_sensitive: bool = True,
        use_regex: bool = False
    ) -> Dict[str, Any]:
        """
        é©—è­‰ PDF æ˜¯å¦åŒ…å«é æœŸå…§å®¹

        Args:
            pdf_path: PDF æª”æ¡ˆè·¯å¾‘
            expected_content: é æœŸå…§å®¹åˆ—è¡¨
            case_sensitive: æ˜¯å¦å€åˆ†å¤§å°å¯«
            use_regex: æ˜¯å¦ä½¿ç”¨æ­£å‰‡è¡¨é”å¼åŒ¹é…

        Returns:
            é©—è­‰çµæœå­—å…¸

        Example:
            >>> result = validator.validate_content(
            ...     "invoice.pdf",
            ...     ["Invoice #12345", "Total: \\$\\d+\\.\\d{2}"],
            ...     use_regex=True
            ... )
            >>> print(result['all_found'])  # True/False
        """
        text = self.extract_text(pdf_path)

        if not case_sensitive and not use_regex:
            text = text.lower()

        results = {
            "all_found": True,
            "missing": [],
            "found": [],
            "matches": {}
        }

        for content in expected_content:
            search_content = content if case_sensitive else content.lower()

            if use_regex:
                # æ­£å‰‡è¡¨é”å¼åŒ¹é…
                pattern = re.compile(search_content, re.IGNORECASE if not case_sensitive else 0)
                matches = pattern.findall(text)

                if matches:
                    results["found"].append(content)
                    results["matches"][content] = matches
                else:
                    results["missing"].append(content)
                    results["all_found"] = False
            else:
                # æ™®é€šå­—ä¸²åŒ¹é…
                if search_content in text:
                    results["found"].append(content)
                else:
                    results["missing"].append(content)
                    results["all_found"] = False

        logger.info(
            f"å…§å®¹é©—è­‰å®Œæˆ: {len(results['found'])}/{len(expected_content)} æ‰¾åˆ°"
        )

        return results

    def get_metadata(self, pdf_path: str) -> Dict[str, Any]:
        """
        æå– PDF å…ƒæ•¸æ“šï¼ˆä½œè€…ã€æ¨™é¡Œã€å‰µå»ºæ—¥æœŸç­‰ï¼‰

        Args:
            pdf_path: PDF æª”æ¡ˆè·¯å¾‘

        Returns:
            å…ƒæ•¸æ“šå­—å…¸

        Example:
            >>> metadata = validator.get_metadata("document.pdf")
            >>> print(metadata['title'])
        """
        try:
            with open(pdf_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                metadata = reader.metadata

                return {
                    "title": metadata.get('/Title', ''),
                    "author": metadata.get('/Author', ''),
                    "subject": metadata.get('/Subject', ''),
                    "creator": metadata.get('/Creator', ''),
                    "producer": metadata.get('/Producer', ''),
                    "creation_date": metadata.get('/CreationDate', ''),
                    "modification_date": metadata.get('/ModDate', ''),
                    "page_count": len(reader.pages),
                    "is_encrypted": reader.is_encrypted
                }
        except Exception as e:
            logger.error(f"å…ƒæ•¸æ“šæå–å¤±æ•—: {e}")
            raise

    def validate_structure(
        self,
        pdf_path: str,
        expected_pages: Optional[int] = None,
        max_file_size_mb: Optional[float] = None
    ) -> Dict[str, Any]:
        """
        é©—è­‰ PDF çµæ§‹ï¼ˆé æ•¸ã€æª”æ¡ˆå¤§å°ç­‰ï¼‰

        Args:
            pdf_path: PDF æª”æ¡ˆè·¯å¾‘
            expected_pages: é æœŸé æ•¸
            max_file_size_mb: æœ€å¤§æª”æ¡ˆå¤§å°ï¼ˆMBï¼‰

        Returns:
            é©—è­‰çµæœ

        Example:
            >>> result = validator.validate_structure(
            ...     "report.pdf",
            ...     expected_pages=10,
            ...     max_file_size_mb=5.0
            ... )
        """
        path = Path(pdf_path)

        if not path.exists():
            return {
                "valid": False,
                "errors": [f"æª”æ¡ˆä¸å­˜åœ¨: {pdf_path}"]
            }

        errors = []
        metadata = self.get_metadata(pdf_path)

        # æª¢æŸ¥é æ•¸
        actual_pages = metadata['page_count']
        if expected_pages and actual_pages != expected_pages:
            errors.append(
                f"é æ•¸ä¸ç¬¦: æœŸæœ› {expected_pages}, å¯¦éš› {actual_pages}"
            )

        # æª¢æŸ¥æª”æ¡ˆå¤§å°
        file_size_mb = path.stat().st_size / (1024 * 1024)
        if max_file_size_mb and file_size_mb > max_file_size_mb:
            errors.append(
                f"æª”æ¡ˆéå¤§: {file_size_mb:.2f} MB > {max_file_size_mb} MB"
            )

        # æª¢æŸ¥æ˜¯å¦åŠ å¯†
        if metadata['is_encrypted']:
            errors.append("PDF å·²åŠ å¯†ï¼Œç„¡æ³•è®€å–")

        return {
            "valid": len(errors) == 0,
            "errors": errors,
            "page_count": actual_pages,
            "file_size_mb": round(file_size_mb, 2),
            "metadata": metadata
        }

    def extract_tables(self, pdf_path: str, page_numbers: Optional[List[int]] = None) -> List[List[List[str]]]:
        """
        æå– PDF ä¸­çš„è¡¨æ ¼ï¼ˆéœ€è¦ pdfplumberï¼‰

        Args:
            pdf_path: PDF æª”æ¡ˆè·¯å¾‘
            page_numbers: è¦æå–çš„é ç¢¼åˆ—è¡¨

        Returns:
            è¡¨æ ¼åˆ—è¡¨ï¼Œæ¯å€‹è¡¨æ ¼æ˜¯äºŒç¶­åˆ—è¡¨
        """
        try:
            import pdfplumber
        except ImportError:
            raise ImportError("è«‹å®‰è£ pdfplumber: pip install pdfplumber")

        tables = []

        with pdfplumber.open(pdf_path) as pdf:
            pages_to_process = page_numbers if page_numbers else range(len(pdf.pages))

            for page_num in pages_to_process:
                page = pdf.pages[page_num]
                page_tables = page.extract_tables()

                if page_tables:
                    tables.extend(page_tables)

        logger.info(f"å¾ {pdf_path} æå– {len(tables)} å€‹è¡¨æ ¼")
        return tables
```

### 5.2.4 æ•´åˆåˆ° Claude Code Skillï¼šå ±å‘Šé©—è­‰

**SKILL.md:**

```markdown
---
name: validate-test-report
description: Validate generated PDF test report contains required content
parameters:
  - name: pdf_path
    description: Path to PDF test report
    type: string
    required: true
  - name: test_run_id
    description: Test run ID that should appear in report
    type: string
    required: true
---

# Test Report Validation

Validates that the generated PDF test report:
- Contains the correct test run ID
- Includes all required sections (Summary, Failures, Metrics)
- Has the expected number of pages
- File size is reasonable (<10MB)
```

**skill.py:**

```python
import sys
import json
from pdf_validator import PDFValidator


def validate_test_report(pdf_path: str, test_run_id: str) -> dict:
    """é©—è­‰æ¸¬è©¦å ±å‘Š PDF"""
    validator = PDFValidator()

    # 1. çµæ§‹é©—è­‰
    structure = validator.validate_structure(
        pdf_path,
        expected_pages=None,  # é æ•¸å¯èƒ½è®Šå‹•
        max_file_size_mb=10.0
    )

    if not structure['valid']:
        return {
            "success": False,
            "errors": structure['errors']
        }

    # 2. å…§å®¹é©—è­‰ï¼ˆåŒ…å«å¿…è¦ç« ç¯€ï¼‰
    required_content = [
        f"Test Run: {test_run_id}",
        "Executive Summary",
        "Test Results",
        "Failed Tests",
        r"Pass Rate: \d+\.\d+%"  # æ­£å‰‡ï¼šPass Rate: 85.5%
    ]

    content_result = validator.validate_content(
        pdf_path,
        required_content,
        use_regex=True
    )

    if not content_result['all_found']:
        return {
            "success": False,
            "error": "å ±å‘Šå…§å®¹ä¸å®Œæ•´",
            "missing_sections": content_result['missing']
        }

    # 3. æå–çµ±è¨ˆæ•¸æ“šï¼ˆå¾æ–‡æœ¬ä¸­è§£æï¼‰
    text = validator.extract_text(pdf_path)

    import re
    pass_rate_match = re.search(r'Pass Rate: (\d+\.\d+)%', text)
    total_tests_match = re.search(r'Total Tests: (\d+)', text)

    return {
        "success": True,
        "report_metadata": structure['metadata'],
        "page_count": structure['page_count'],
        "file_size_mb": structure['file_size_mb'],
        "pass_rate": pass_rate_match.group(1) if pass_rate_match else None,
        "total_tests": int(total_tests_match.group(1)) if total_tests_match else None
    }


if __name__ == "__main__":
    params = json.loads(sys.argv[1])
    result = validate_test_report(**params)
    print(json.dumps(result, ensure_ascii=False, indent=2))
```


## 5.3 æ•¸æ“šé©…å‹•æ¸¬è©¦å¯¦è¸

### 5.3.1 ä»€éº¼æ˜¯æ•¸æ“šé©…å‹•æ¸¬è©¦ï¼Ÿ

**æ•¸æ“šé©…å‹•æ¸¬è©¦ï¼ˆData-Driven Testing, DDTï¼‰** æ˜¯æŒ‡æ¸¬è©¦é‚è¼¯èˆ‡æ¸¬è©¦æ•¸æ“šåˆ†é›¢ï¼ŒåŒä¸€æ¸¬è©¦å‡½æ•¸ä½¿ç”¨ä¸åŒæ•¸æ“šé›†é‡è¤‡åŸ·è¡Œã€‚å„ªé»ï¼š

- **æ¸›å°‘ä»£ç¢¼é‡è¤‡**ï¼šä¸€å€‹æ¸¬è©¦å‡½æ•¸ï¼Œæ•¸ç™¾å€‹æ¸¬è©¦æ¡ˆä¾‹
- **æå‡è¦†è“‹ç‡**ï¼šè¼•é¬†å¢åŠ é‚Šç•Œå€¼ã€ç•°å¸¸å€¼æ¸¬è©¦
- **ä¾¿æ–¼ç¶­è­·**ï¼šæ¥­å‹™äººå“¡å¯ç›´æ¥ç·¨è¼¯ Excel æ¸¬è©¦æ•¸æ“šï¼Œç„¡éœ€æ”¹ä»£ç¢¼

### 5.3.2 å¯¦ä½œï¼šPytest + Excel DDT

ä½¿ç”¨ pytest çš„åƒæ•¸åŒ–åŠŸèƒ½çµåˆ Excelï¼š

```python
import pytest
import pandas as pd
from excel_processor import ExcelProcessor


def load_test_data(excel_file: str, sheet_name: str = "TestCases"):
    """å¾ Excel è¼‰å…¥æ¸¬è©¦æ•¸æ“šï¼Œè½‰ç‚º pytest åƒæ•¸"""
    processor = ExcelProcessor()
    data = processor.read_test_data(excel_file, sheet_name)

    # è½‰æ›ç‚º pytest.param æ ¼å¼
    test_params = []
    for row in data:
        test_params.append(
            pytest.param(
                row['username'],
                row['password'],
                row['expected_result'],
                id=f"case_{row.get('case_id', len(test_params) + 1)}"
            )
        )

    return test_params


# æ¸¬è©¦æ•¸æ“šä¾†è‡ª Excel
test_cases = load_test_data("tests/data/login_tests.xlsx")


@pytest.mark.parametrize("username,password,expected", test_cases)
def test_login(username, password, expected):
    """æ•¸æ“šé©…å‹•ç™»å…¥æ¸¬è©¦"""
    from app.auth import login

    result = login(username, password)

    if expected == "success":
        assert result.success is True
        assert result.user is not None
    elif expected == "invalid_password":
        assert result.success is False
        assert result.error == "Invalid password"
    elif expected == "user_not_found":
        assert result.success is False
        assert result.error == "User not found"
```

**Excel æ¸¬è©¦æ•¸æ“šæ ¼å¼ï¼š**

| case_id | username | password | expected_result |
|---------|----------|----------|-----------------|
| 1 | admin | admin123 | success |
| 2 | admin | wrong | invalid_password |
| 3 | nonexist | any | user_not_found |
| 4 | user1 | pass1 | success |

### 5.3.3 é«˜ç´šæŠ€å·§ï¼šå‹•æ…‹ç”Ÿæˆæ¸¬è©¦æ•¸æ“š

å°æ–¼å¤§è¦æ¨¡æ¸¬è©¦ï¼ˆå¦‚å£“åŠ›æ¸¬è©¦ï¼‰ï¼Œå¯çµåˆ Faker ç”Ÿæˆæ•¸æ“šï¼š

```python
from faker import Faker
import pandas as pd

fake = Faker('zh_TW')

# ç”Ÿæˆ 1000 ç­†æ¸¬è©¦ç”¨æˆ¶
users = []
for i in range(1000):
    users.append({
        'user_id': i + 1,
        'name': fake.name(),
        'email': fake.email(),
        'phone': fake.phone_number(),
        'address': fake.address()
    })

# å¯«å…¥ Excel
df = pd.DataFrame(users)
df.to_excel('test_users_1000.xlsx', index=False)
```


## 5.4 æ•¸æ“šæ¸…æ´—èˆ‡è½‰æ›

### 5.4.1 å¸¸è¦‹æ•¸æ“šå•é¡Œ

å¯¦éš›æ¸¬è©¦ä¸­ï¼Œæ•¸æ“šå¸¸æœ‰å•é¡Œï¼š

- **ç¼ºå¤±å€¼**ï¼šæŸäº›æ¬„ä½ç‚ºç©º
- **æ ¼å¼ä¸ä¸€è‡´**ï¼šæ—¥æœŸæ ¼å¼æ··äº‚ï¼ˆ2024-01-01 vs 01/01/2024ï¼‰
- **æ•¸æ“šé¡å‹éŒ¯èª¤**ï¼šæ•¸å­—å­˜ç‚ºæ–‡æœ¬
- **é‡è¤‡æ•¸æ“š**ï¼šåŒä¸€ç”¨æˆ¶å¤šæ¬¡å‡ºç¾

### 5.4.2 Pandas æ•¸æ“šæ¸…æ´—æŠ€å·§

```python
import pandas as pd
import numpy as np

# è®€å–æ•¸æ“š
df = pd.read_excel('messy_data.xlsx')

# 1. è™•ç†ç¼ºå¤±å€¼
df['email'].fillna('unknown@example.com', inplace=True)  # å¡«å……é è¨­å€¼
df.dropna(subset=['username'], inplace=True)  # åˆªé™¤é—œéµæ¬„ä½ç‚ºç©ºçš„è¡Œ

# 2. æ•¸æ“šé¡å‹è½‰æ›
df['age'] = pd.to_numeric(df['age'], errors='coerce')  # ç„¡æ³•è½‰æ›çš„è®Šç‚º NaN
df['signup_date'] = pd.to_datetime(df['signup_date'], format='%Y-%m-%d', errors='coerce')

# 3. å»é™¤é‡è¤‡
df.drop_duplicates(subset=['username'], keep='first', inplace=True)

# 4. å­—ä¸²æ¸…ç†
df['phone'] = df['phone'].str.replace(r'\D', '', regex=True)  # åªä¿ç•™æ•¸å­—

# 5. æ•¸æ“šæ¨™æº–åŒ–
df['name'] = df['name'].str.strip().str.title()  # å»ç©ºæ ¼ï¼Œé¦–å­—æ¯å¤§å¯«

# 6. æ¢ä»¶è½‰æ›
df['status'] = df['age'].apply(lambda x: 'adult' if x >= 18 else 'minor')

# ä¿å­˜æ¸…æ´—å¾Œçš„æ•¸æ“š
df.to_excel('cleaned_data.xlsx', index=False)
```


## 5.5 èˆ‡ WebGuard æ¸¬è©¦ç³»çµ±æ•´åˆ

å°‡æ•¸æ“šè™•ç†èƒ½åŠ›æ•´åˆåˆ° WebGuard æ¶æ§‹ï¼š

```python
# webguard/data/excel_test_suite.py
from typing import List, Dict, Any
from pathlib import Path
from excel_processor import ExcelProcessor
from webguard.core.test_base import TestBase
import logging

logger = logging.getLogger(__name__)


class ExcelTestSuite(TestBase):
    """
    åŸºæ–¼ Excel çš„æ¸¬è©¦å¥—ä»¶

    å¾ Excel è®€å–æ¸¬è©¦æ¡ˆä¾‹ï¼ŒåŸ·è¡Œä¸¦å›å¯«çµæœ
    """

    def __init__(
        self,
        excel_path: str,
        sheet_name: str = "TestCases",
        result_sheet: str = "Results"
    ):
        super().__init__()
        self.excel_path = Path(excel_path)
        self.sheet_name = sheet_name
        self.result_sheet = result_sheet
        self.processor = ExcelProcessor()

    def load_test_cases(self) -> List[Dict[str, Any]]:
        """è¼‰å…¥æ¸¬è©¦æ¡ˆä¾‹"""
        # é©—è­‰æ•¸æ“šæ ¼å¼
        schema = {
            'required_columns': ['test_name', 'test_type'],
            'column_types': {
                'timeout': 'int64',
                'retry': 'int64'
            }
        }

        validation = self.processor.validate_data(
            str(self.excel_path),
            schema,
            self.sheet_name
        )

        if not validation['valid']:
            raise ValueError(f"æ¸¬è©¦æ•¸æ“šé©—è­‰å¤±æ•—: {validation['errors']}")

        return self.processor.read_test_data(
            str(self.excel_path),
            self.sheet_name
        )

    async def run(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ¸¬è©¦å¥—ä»¶"""
        test_cases = self.load_test_cases()
        results = []

        for case in test_cases:
            test_name = case['test_name']
            test_type = case['test_type']

            logger.info(f"åŸ·è¡Œæ¸¬è©¦: {test_name} ({test_type})")

            try:
                # æ ¹æ“šé¡å‹é¸æ“‡æ¸¬è©¦æ–¹æ³•
                if test_type == 'browser':
                    result = await self._run_browser_test(case)
                elif test_type == 'api':
                    result = await self._run_api_test(case)
                else:
                    raise ValueError(f"æœªçŸ¥æ¸¬è©¦é¡å‹: {test_type}")

                results.append({
                    'test_name': test_name,
                    'status': 'PASSED' if result['success'] else 'FAILED',
                    'duration_ms': result.get('duration_ms'),
                    'error': result.get('error')
                })

            except Exception as e:
                logger.error(f"æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
                results.append({
                    'test_name': test_name,
                    'status': 'ERROR',
                    'error': str(e)
                })

        # å¯«å…¥çµæœ
        self._write_results(results)

        return {
            "success": True,
            "total": len(results),
            "passed": sum(1 for r in results if r['status'] == 'PASSED'),
            "failed": sum(1 for r in results if r['status'] == 'FAILED'),
            "errors": sum(1 for r in results if r['status'] == 'ERROR')
        }

    def _write_results(self, results: List[Dict[str, Any]]):
        """å¯«å…¥æ¸¬è©¦çµæœåˆ° Excel"""
        output_path = self.excel_path.parent / f"{self.excel_path.stem}_results.xlsx"
        self.processor.write_results(results, str(output_path), self.result_sheet)
        logger.info(f"æ¸¬è©¦çµæœå·²å¯«å…¥: {output_path}")
```


## 5.6 æœ€ä½³å¯¦è¸èˆ‡å®‰å…¨è€ƒé‡

### 5.6.1 æ•¸æ“šè™•ç†æœ€ä½³å¯¦è¸

1. **å§‹çµ‚é©—è­‰è¼¸å…¥æ•¸æ“š**ï¼šä¸ä¿¡ä»»ä»»ä½•å¤–éƒ¨æ•¸æ“šæº
2. **å„ªé›…è™•ç†éŒ¯èª¤**ï¼šè®€å–å¤±æ•—æ™‚æä¾›æ¸…æ™°éŒ¯èª¤è¨Šæ¯
3. **åˆ†é›¢æ•¸æ“šèˆ‡é‚è¼¯**ï¼šæ¸¬è©¦ä»£ç¢¼èˆ‡æ¸¬è©¦æ•¸æ“šåˆ†é–‹å­˜æ”¾
4. **ç‰ˆæœ¬æ§åˆ¶æ•¸æ“šæ¨¡æ¿**ï¼šå°‡ Excel æ¨¡æ¿ç´å…¥ Gitï¼Œæ•¸æ“šæª”æ¡ˆå‰‡ç”¨ .gitignore æ’é™¤
5. **è¨˜éŒ„æ•¸æ“šè¡€çµ±**ï¼šè¨˜éŒ„æ•¸æ“šä¾†æºã€è½‰æ›æ­·å²

### 5.6.2 å®‰å…¨è€ƒé‡

**Excel å…¬å¼æ³¨å…¥ï¼ˆFormula Injectionï¼‰ï¼š**

å¦‚æœ Excel å–®å…ƒæ ¼å…§å®¹ä¾†è‡ªä¸å¯ä¿¡ä¾†æºï¼ˆå¦‚ç”¨æˆ¶è¼¸å…¥ï¼‰ï¼Œæƒ¡æ„ç”¨æˆ¶å¯èƒ½æ³¨å…¥å…¬å¼ï¼š

```
=cmd|'/c calc.exe'!A1  # åŸ·è¡Œè¨ˆç®—æ©Ÿï¼ˆWindowsï¼‰
```

**é˜²è­·æªæ–½ï¼š**

```python
def sanitize_cell_value(value: str) -> str:
    """æ¸…ç†å–®å…ƒæ ¼å€¼ï¼Œé˜²æ­¢å…¬å¼æ³¨å…¥"""
    if isinstance(value, str) and value.startswith(('=', '+', '-', '@')):
        return f"'{value}"  # åŠ ä¸Šå–®å¼•è™Ÿå¼·åˆ¶ç‚ºæ–‡æœ¬
    return value

# å¯«å…¥æ™‚æ¸…ç†
safe_results = [
    {k: sanitize_cell_value(v) for k, v in row.items()}
    for row in results
]
processor.write_results(safe_results, output_path)
```

**PDF å®‰å…¨ï¼š**

- ä¸åŸ·è¡Œ PDF ä¸­çš„ JavaScriptï¼ˆä½¿ç”¨ `strict=True` åƒæ•¸ï¼‰
- é™åˆ¶æª”æ¡ˆå¤§å°é˜²æ­¢ DoS
- æƒæå¯ç–‘å…§å®¹ï¼ˆå¦‚åµŒå…¥çš„å¯åŸ·è¡Œæª”ï¼‰


## 5.7 æœ¬ç« ç¸½çµ

æœ¬ç« æ·±å…¥æ¢è¨äº†æ•¸æ“šèˆ‡æ–‡ä»¶è™•ç†è‡ªå‹•åŒ–ï¼Œç‚ºæ§‹å»ºå®Œæ•´çš„æ¸¬è©¦ç³»çµ±å¥ å®šåŸºç¤ï¼š

**æ ¸å¿ƒæŠ€èƒ½ï¼š**

- **Excel/CSV è™•ç†**ï¼šä½¿ç”¨ Pandas + openpyxl å¯¦ç¾æ•¸æ“šè®€å¯«ã€é©—è­‰ã€æ ¼å¼åŒ–
- **PDF é©—è­‰**ï¼šä½¿ç”¨ pdfminer + PyPDF2 é€²è¡Œå…§å®¹æå–ã€çµæ§‹é©—è­‰ã€å…ƒæ•¸æ“šæª¢æŸ¥
- **æ•¸æ“šé©…å‹•æ¸¬è©¦**ï¼šå°‡æ¸¬è©¦é‚è¼¯èˆ‡æ•¸æ“šåˆ†é›¢ï¼Œæå‡å¯ç¶­è­·æ€§
- **æ•¸æ“šæ¸…æ´—**ï¼šè™•ç†ç¼ºå¤±å€¼ã€æ ¼å¼ä¸ä¸€è‡´ã€é‡è¤‡æ•¸æ“šç­‰å¯¦éš›å•é¡Œ

**æ•´åˆæ€ç¶­ï¼š**

é€™äº›æ•¸æ“šè™•ç†èƒ½åŠ›ä¸¦éå­¤ç«‹å­˜åœ¨ï¼Œè€Œæ˜¯èˆ‡å‰å¹¾ç« çš„ Skills ç³»çµ±ã€Stagehand ç€è¦½å™¨è‡ªå‹•åŒ–ç·Šå¯†æ•´åˆï¼š

- å¾ Excel è®€å–æ¸¬è©¦æ¡ˆä¾‹ â†’ ç”¨ Stagehand åŸ·è¡Œç€è¦½å™¨æ¸¬è©¦ â†’ çµæœå¯«å› Excel
- PDF å ±å‘Šé©—è­‰ Skill â†’ ç¢ºä¿æ¸¬è©¦å ±å‘Šç¬¦åˆä¼æ¥­è¦ç¯„

**ä¸‹ä¸€ç« é å‘Šï¼š**

æŒæ¡æ•¸æ“šè™•ç†å¾Œï¼Œæˆ‘å€‘å°‡é€²å…¥ **API æ¸¬è©¦èˆ‡æ•´åˆé©—è­‰**ï¼ˆç¬¬ 6 ç« ï¼‰ï¼Œæ¢è¨å¦‚ä½•æ¸¬è©¦ REST/GraphQL APIã€è™•ç†èªè­‰ã€æ¨¡æ“¬ç¬¬ä¸‰æ–¹æœå‹™ï¼Œä¸¦å°‡ API æ¸¬è©¦æ•´åˆåˆ° WebGuard ç³»çµ±ä¸­ã€‚é€™å°‡å®Œå–„æˆ‘å€‘çš„æ¸¬è©¦èƒ½åŠ›çŸ©é™£ï¼šç€è¦½å™¨æ¸¬è©¦ï¼ˆChapter 4ï¼‰+ æ•¸æ“šè™•ç†ï¼ˆChapter 5ï¼‰+ API æ¸¬è©¦ï¼ˆChapter 6ï¼‰= å…¨æ£§æ¸¬è©¦è‡ªå‹•åŒ–ã€‚
