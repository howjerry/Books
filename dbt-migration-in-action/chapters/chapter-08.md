# ç¬¬ 8 ç« ï¼šSchemaã€ç´„æŸèˆ‡ UDF è™•ç†

> åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘å€‘å°‡æ·±å…¥é·ç§»ä¸­çš„ç´°ç¯€å•é¡Œï¼š**Schema å®šç¾©ã€ç´„æŸæ¢ä»¶å’Œ User-Defined Functionsï¼ˆUDFï¼‰**ã€‚é€™äº›çœ‹ä¼¼å°çš„ç´°ç¯€ï¼Œå¯¦éš›ä¸Šå°æ•¸æ“šå“è³ªã€æŸ¥è©¢æ€§èƒ½å’Œåœ˜éšŠå”ä½œéƒ½æœ‰é‡å¤§å½±éŸ¿ã€‚åˆ°æœ¬ç« çµæŸæ™‚ï¼Œä½ å°‡æŒæ¡å®Œæ•´çš„ Schema é·ç§»ç­–ç•¥ï¼Œå»ºç«‹è‡ªå‹•åŒ–æå–å·¥å…·ï¼Œä¸¦å­¸æœƒå°‡ BigQuery UDF è½‰æ›ç‚º dbt macrosã€‚

åœ¨å‰é¢çš„ç« ç¯€ä¸­ï¼Œæˆ‘å€‘æŒæ¡äº†ä¸‰ç¨®ä¸»è¦çš„é·ç§»æ¨¡å¼ï¼šå®Œå…¨æ›´æ–°è¡¨ã€åˆ†å€è¡¨ã€åˆ†ç‰‡è¡¨ã€‚ä½†æˆ‘å€‘éƒ½ä½¿ç”¨äº†ç›¸å°ç°¡å–®çš„ Schema å®šç¾©ã€‚åœ¨å¯¦éš›å°ˆæ¡ˆä¸­ï¼ŒSchema å¯èƒ½éå¸¸è¤‡é›œï¼šä¸Šç™¾å€‹æ¬„ä½ã€å¤šå±¤å·¢ç‹€çµæ§‹ã€è¤‡é›œçš„ç´„æŸæ¢ä»¶ã€è‡ªå®šç¾©å‡½æ•¸ã€‚

M3 çš„ 50 å€‹ SQL ä¸­ï¼Œæœ‰äº›è¡¨æœ‰ 100+ æ¬„ä½ï¼Œæ¯å€‹æ¬„ä½éƒ½æœ‰è©³ç´°çš„æè¿°å’Œç´„æŸã€‚æ‰‹å‹•é·ç§»é€™äº› Schema æœƒéå¸¸è€—æ™‚ä¸”å®¹æ˜“å‡ºéŒ¯ã€‚æˆ‘å€‘éœ€è¦è‡ªå‹•åŒ–ã€‚

## 8.1 Schema æè¿°å®Œæ•´é·ç§»

### 8.1.1 ç‚ºä½• Schema æè¿°å¦‚æ­¤é‡è¦ï¼Ÿ

**Schema æè¿°**ä¸åƒ…åƒ…æ˜¯è¨»è§£ï¼Œå®ƒæ˜¯**æ•¸æ“šæ–‡æª”**ã€**åœ˜éšŠçŸ¥è­˜**å’Œ**æ•¸æ“šæ²»ç†**çš„åŸºç¤ã€‚

**æ²’æœ‰æè¿°çš„å¾Œæœ**ï¼š

```yaml
# æ²’æœ‰æè¿°çš„ schema
columns:
  - name: amt
  - name: dt
  - name: usr_id
  - name: sts
```

6 å€‹æœˆå¾Œï¼Œæ–°åœ˜éšŠæˆå“¡çœ‹åˆ°é€™å€‹ schemaï¼š
- â“ `amt` æ˜¯ä»€éº¼é‡‘é¡ï¼Ÿç¸½é¡ï¼Ÿç¨…é¡ï¼Ÿ
- â“ `dt` æ˜¯å“ªå€‹æ—¥æœŸï¼Ÿäº¤æ˜“æ—¥ï¼Ÿå…¥å¸³æ—¥ï¼Ÿ
- â“ `usr_id` æ˜¯è²·å®¶é‚„æ˜¯è³£å®¶ï¼Ÿ
- â“ `sts` æœ‰å“ªäº›å¯èƒ½çš„å€¼ï¼Ÿ

çµæœï¼šæµªè²»å¤§é‡æ™‚é–“æŸ¥è©¢ä»£ç¢¼ã€è©¢å•åŒäº‹ã€çŒœæ¸¬æ¬„ä½æ„ç¾©ã€‚

**å®Œæ•´æè¿°çš„åƒ¹å€¼**ï¼š

```yaml
# å®Œæ•´æè¿°çš„ schema
columns:
  - name: amt
    description: "äº¤æ˜“ç¸½é‡‘é¡ï¼ˆå«ç¨…ï¼Œå–®ä½ï¼šæ–°å°å¹£å…ƒï¼‰"
  - name: dt
    description: "äº¤æ˜“ç™¼ç”Ÿæ—¥æœŸï¼ˆå°åŒ—æ™‚å€ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼‰"
  - name: usr_id
    description: "è²·å®¶ç”¨æˆ¶ IDï¼ˆåƒç…§ users.user_idï¼‰"
  - name: sts
    description: "äº¤æ˜“ç‹€æ…‹ï¼ˆpending:å¾…ä»˜æ¬¾, completed:å·²å®Œæˆ, cancelled:å·²å–æ¶ˆï¼‰"
```

æ–°åœ˜éšŠæˆå“¡ç«‹å³ç†è§£æ¯å€‹æ¬„ä½çš„æ„ç¾©ã€å–®ä½ã€å¯èƒ½çš„å€¼ã€‚

ğŸ’¡ **é—œéµæ´å¯Ÿ**ï¼šå®Œæ•´çš„ Schema æè¿°èƒ½å°‡åœ˜éšŠçš„ onboarding æ™‚é–“æ¸›å°‘ 50%+ã€‚

### 8.1.2 å¾ BigQuery æå– Schema

BigQuery è¡¨å¯èƒ½å·²ç¶“æœ‰è©³ç´°çš„ Schema å®šç¾©ã€‚æˆ‘å€‘éœ€è¦æå–é€™äº›è³‡è¨Šã€‚

**æ–¹æ³• 1ï¼šä½¿ç”¨ INFORMATION_SCHEMA**

```sql
-- æå–è¡¨çš„æ‰€æœ‰æ¬„ä½è³‡è¨Š
SELECT
    column_name,
    data_type,
    is_nullable,
    description
FROM `m3-project.analytics.INFORMATION_SCHEMA.COLUMNS`
WHERE table_name = 'user_daily_transactions'
ORDER BY ordinal_position;
```

çµæœï¼š

```
column_name         data_type   is_nullable  description
user_id             INT64       NO           ç”¨æˆ¶å”¯ä¸€è­˜åˆ¥ç¢¼
transaction_id      STRING      NO           äº¤æ˜“ ID
transaction_date    DATE        NO           äº¤æ˜“æ—¥æœŸ
amount              FLOAT64     NO           äº¤æ˜“é‡‘é¡ï¼ˆå–®ä½ï¼šå…ƒï¼‰
payment_method      STRING      YES          æ”¯ä»˜æ–¹å¼
status              STRING      NO           äº¤æ˜“ç‹€æ…‹
```

**æ–¹æ³• 2ï¼šä½¿ç”¨ bq å‘½ä»¤åˆ—å·¥å…·**

```bash
bq show --schema --format=prettyjson \
  m3-project:analytics.user_daily_transactions > schema.json
```

ç”Ÿæˆçš„ `schema.json`ï¼š

```json
[
  {
    "name": "user_id",
    "type": "INTEGER",
    "mode": "REQUIRED",
    "description": "ç”¨æˆ¶å”¯ä¸€è­˜åˆ¥ç¢¼"
  },
  {
    "name": "transaction_id",
    "type": "STRING",
    "mode": "REQUIRED",
    "description": "äº¤æ˜“ ID"
  },
  {
    "name": "amount",
    "type": "FLOAT",
    "mode": "REQUIRED",
    "description": "äº¤æ˜“é‡‘é¡ï¼ˆå–®ä½ï¼šå…ƒï¼‰"
  },
  ...
]
```

**æ–¹æ³• 3ï¼šä½¿ç”¨ Python BigQuery Client**

```python
from google.cloud import bigquery

client = bigquery.Client(project='m3-project')
table = client.get_table('m3-project.analytics.user_daily_transactions')

for field in table.schema:
    print(f"{field.name}: {field.field_type} - {field.description or 'No description'}")
```

### 8.1.3 è‡ªå‹•åŒ– Schema ç”Ÿæˆè…³æœ¬

æ‰‹å‹•è¤‡è£½è²¼ä¸Šå®¹æ˜“å‡ºéŒ¯ã€‚è®“æˆ‘å€‘å»ºç«‹è‡ªå‹•åŒ–è…³æœ¬ã€‚

å‰µå»º `scripts/generate_schema_yml.py`ï¼š

```python
# scripts/generate_schema_yml.py
"""
å¾ BigQuery è¡¨è‡ªå‹•ç”Ÿæˆ dbt schema.yml

ç”¨é€”ï¼š
1. æå– BigQuery è¡¨çš„ schema
2. ç”Ÿæˆ dbt schema.yml æ ¼å¼
3. åŒ…å«æ¬„ä½æè¿°ã€é¡å‹ã€ç´„æŸ
"""

from google.cloud import bigquery
import yaml
from typing import Dict, List


def extract_schema_from_bigquery(project_id: str, dataset_id: str,
                                 table_id: str) -> Dict:
    """
    å¾ BigQuery æå–è¡¨çš„ schema

    Returns:
        dict: dbt schema.yml æ ¼å¼çš„å­—å…¸
    """
    client = bigquery.Client(project=project_id)
    table = client.get_table(f"{project_id}.{dataset_id}.{table_id}")

    # å»ºç«‹ schema çµæ§‹
    model_schema = {
        'name': table_id,
        'description': table.description or f'TODO: ç‚º {table_id} åŠ å…¥æè¿°',
        'columns': []
    }

    # éæ­·æ‰€æœ‰æ¬„ä½
    for field in table.schema:
        column = {
            'name': field.name,
            'description': field.description or f'TODO: ç‚º {field.name} åŠ å…¥æè¿°',
            'tests': []
        }

        # æ ¹æ“š mode åŠ å…¥ not_null test
        if field.mode == 'REQUIRED':
            column['tests'].append('not_null')

        # æ¨è–¦åŠ å…¥çš„å…¶ä»– testsï¼ˆéœ€æ‰‹å‹•ç¢ºèªï¼‰
        # å¦‚æœæ¬„ä½ååŒ…å« 'id' ä¸”ä¸æ˜¯å¤–éµï¼Œå¯èƒ½æ˜¯ unique
        if 'id' in field.name.lower() and field.name.lower().endswith('id'):
            # åŠ å…¥è¨»è§£æç¤ºï¼Œéœ€æ‰‹å‹•ç¢ºèª
            if not column['tests']:
                column['tests'] = []
            # column['tests'].append('unique')  # å–æ¶ˆè¨»è§£ä»¥å•Ÿç”¨

        model_schema['columns'].append(column)

    return model_schema


def extract_schema_with_info(project_id: str, dataset_id: str,
                             table_id: str) -> Dict:
    """
    å¾ BigQuery æå– schema ä¸¦åŠ å…¥é¡å¤–è³‡è¨Š

    åŒ…å«ï¼š
    - åˆ†å€é…ç½®
    - Clustering é…ç½®
    - è¡Œæ•¸çµ±è¨ˆ
    """
    client = bigquery.Client(project=project_id)
    table = client.get_table(f"{project_id}.{dataset_id}.{table_id}")

    model_schema = extract_schema_from_bigquery(project_id, dataset_id, table_id)

    # åŠ å…¥è¡¨ç´šåˆ¥çš„å…ƒæ•¸æ“š
    metadata_lines = []

    if table.description:
        metadata_lines.append(table.description)
        metadata_lines.append("")

    metadata_lines.append("**è¡¨è³‡è¨Š**:")
    metadata_lines.append(f"- è¡Œæ•¸ï¼š{table.num_rows:,}")
    metadata_lines.append(f"- å¤§å°ï¼š{table.num_bytes / (1024**3):.2f} GB")

    # åˆ†å€è³‡è¨Š
    if table.time_partitioning:
        metadata_lines.append("")
        metadata_lines.append("**åˆ†å€é…ç½®**:")
        metadata_lines.append(f"- åˆ†å€æ¬„ä½ï¼š{table.time_partitioning.field or '_PARTITIONDATE'}")
        metadata_lines.append(f"- åˆ†å€é¡å‹ï¼š{table.time_partitioning.type_}")
        if table.time_partitioning.expiration_ms:
            days = table.time_partitioning.expiration_ms / (1000 * 60 * 60 * 24)
            metadata_lines.append(f"- éæœŸæ™‚é–“ï¼š{days:.0f} å¤©")

    # Clustering è³‡è¨Š
    if table.clustering_fields:
        metadata_lines.append("")
        metadata_lines.append("**Clustering**:")
        metadata_lines.append(f"- æ¬„ä½ï¼š{', '.join(table.clustering_fields)}")

    # æ›´æ–°æè¿°
    model_schema['description'] = '\n'.join(metadata_lines)

    return model_schema


def generate_schema_yml(models: List[Dict], output_file: str = None):
    """
    ç”Ÿæˆ schema.yml æª”æ¡ˆ

    Args:
        models: æ¨¡å‹åˆ—è¡¨ï¼ˆæ¯å€‹æ˜¯ dictï¼‰
        output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆNone å‰‡è¼¸å‡ºåˆ° stdoutï¼‰
    """
    schema_yml = {
        'version': 2,
        'models': models
    }

    # ä½¿ç”¨ | ç¬¦è™Ÿæ”¯æ´å¤šè¡Œæè¿°
    def str_presenter(dumper, data):
        if '\n' in data:
            return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='|')
        return dumper.represent_scalar('tag:yaml.org,2002:str', data)

    yaml.add_representer(str, str_presenter)

    # ç”Ÿæˆ YAML
    yml_content = yaml.dump(
        schema_yml,
        allow_unicode=True,
        default_flow_style=False,
        sort_keys=False
    )

    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(yml_content)
        print(f"âœ“ Schema å·²ç”Ÿæˆï¼š{output_file}")
    else:
        print(yml_content)


def generate_schema_for_multiple_tables(project_id: str, dataset_id: str,
                                        table_ids: List[str],
                                        output_file: str):
    """
    ç‚ºå¤šå€‹è¡¨ç”Ÿæˆçµ±ä¸€çš„ schema.yml

    Args:
        table_ids: è¡¨ååˆ—è¡¨
        output_file: è¼¸å‡ºæª”æ¡ˆï¼ˆå¦‚ models/marts/schema.ymlï¼‰
    """
    models = []
    for table_id in table_ids:
        print(f"æå– schemaï¼š{table_id}")
        try:
            model = extract_schema_with_info(project_id, dataset_id, table_id)
            models.append(model)
        except Exception as e:
            print(f"  âœ— éŒ¯èª¤ï¼š{e}")
            continue

    generate_schema_yml(models, output_file)


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == '__main__':
    # ç¯„ä¾‹ 1ï¼šå–®ä¸€è¡¨
    print("=== å–®ä¸€è¡¨ schema ===")
    schema = extract_schema_with_info(
        'm3-project',
        'analytics',
        'user_daily_transactions'
    )
    generate_schema_yml([schema])

    print("\n" + "=" * 60 + "\n")

    # ç¯„ä¾‹ 2ï¼šå¤šå€‹è¡¨
    print("=== å¤šå€‹è¡¨ schema ===")
    generate_schema_for_multiple_tables(
        'm3-project',
        'analytics',
        ['user_daily_transactions', 'product_sales', 'daily_sales_summary'],
        'models/marts/schema.yml'
    )
```

### 8.1.4 åŸ·è¡Œ Schema ç”Ÿæˆ

**å–®ä¸€è¡¨**ï¼š

```bash
python scripts/generate_schema_yml.py
```

é æœŸè¼¸å‡ºï¼š

```yaml
version: 2
models:
- name: user_daily_transactions
  description: |
    ç”¨æˆ¶æ¯æ—¥äº¤æ˜“è¨˜éŒ„

    **è¡¨è³‡è¨Š**:
    - è¡Œæ•¸ï¼š1,234,567
    - å¤§å°ï¼š0.45 GB

    **åˆ†å€é…ç½®**:
    - åˆ†å€æ¬„ä½ï¼štransaction_date
    - åˆ†å€é¡å‹ï¼šDAY
    - éæœŸæ™‚é–“ï¼š365 å¤©

    **Clustering**:
    - æ¬„ä½ï¼šuser_id, payment_method
  columns:
  - name: user_id
    description: ç”¨æˆ¶å”¯ä¸€è­˜åˆ¥ç¢¼
    tests:
    - not_null
  - name: transaction_id
    description: äº¤æ˜“ ID
    tests:
    - not_null
  - name: transaction_date
    description: äº¤æ˜“æ—¥æœŸ
    tests:
    - not_null
  - name: amount
    description: äº¤æ˜“é‡‘é¡ï¼ˆå–®ä½ï¼šå…ƒï¼‰
    tests:
    - not_null
  ...
```

**æ‰¹é‡ç”Ÿæˆ**ï¼š

```python
# ç‚ºæ•´å€‹è³‡æ–™å¤¾çš„è¡¨ç”Ÿæˆ schema
generate_schema_for_multiple_tables(
    'm3-project',
    'analytics',
    [
        'user_daily_transactions',
        'product_sales',
        'daily_sales_summary',
        'user_activity_daily',
        'product_inventory_daily'
    ],
    'models/marts/schema.yml'
)
```

### 8.1.5 æ‰‹å‹•å„ªåŒ–ç”Ÿæˆçš„ Schema

è‡ªå‹•ç”Ÿæˆçš„ schema æ˜¯éª¨æ¶ï¼Œéœ€è¦æ‰‹å‹•å„ªåŒ–ï¼š

**å„ªåŒ– 1ï¼šæ“´å……æè¿°**

```yaml
# è‡ªå‹•ç”Ÿæˆ
- name: amount
  description: äº¤æ˜“é‡‘é¡ï¼ˆå–®ä½ï¼šå…ƒï¼‰

# æ‰‹å‹•å„ªåŒ–
- name: amount
  description: |
    äº¤æ˜“ç¸½é‡‘é¡ï¼ˆå«ç¨…ï¼Œå–®ä½ï¼šæ–°å°å¹£å…ƒï¼‰

    **è¨ˆç®—æ–¹å¼**ï¼šquantity Ã— unit_price
    **ç¯„åœ**ï¼š> 0
    **ç²¾åº¦**ï¼šå°æ•¸é»å¾Œå…©ä½
```

**å„ªåŒ– 2ï¼šåŠ å…¥æ¥­å‹™è¦å‰‡**

```yaml
- name: status
  description: |
    äº¤æ˜“ç‹€æ…‹

    **å¯èƒ½çš„å€¼**ï¼š
    - pendingï¼šç­‰å¾…ä»˜æ¬¾
    - processingï¼šè™•ç†ä¸­
    - completedï¼šå·²å®Œæˆ
    - cancelledï¼šå·²å–æ¶ˆ
    - refundedï¼šå·²é€€æ¬¾

    **ç‹€æ…‹è½‰æ›**ï¼š
    pending â†’ processing â†’ completed
    pending â†’ cancelled
    completed â†’ refunded
  tests:
  - not_null
  - accepted_values:
      values: ['pending', 'processing', 'completed', 'cancelled', 'refunded']
```

**å„ªåŒ– 3ï¼šåŠ å…¥åƒç…§é—œä¿‚**

```yaml
- name: user_id
  description: |
    ç”¨æˆ¶å”¯ä¸€è­˜åˆ¥ç¢¼

    **åƒç…§**ï¼šusers.user_id
  tests:
  - not_null
  - relationships:
      to: source('raw_data', 'users')
      field: user_id
```

### 8.1.6 ç¶­è­· Schema çš„æœ€ä½³å¯¦è¸

**åŸå‰‡ 1ï¼šSingle Source of Truth**

Schema å®šç¾©æ‡‰è©²åœ¨ä¸€å€‹åœ°æ–¹ï¼šdbt çš„ schema.ymlã€‚

âŒ ä¸è¦åœ¨å¤šå€‹åœ°æ–¹ç¶­è­·ï¼š
- BigQuery è¡¨æè¿°
- dbt schema.yml
- å…§éƒ¨ Wiki
- Confluence æ–‡æª”

âœ… æ‡‰è©²åªåœ¨ dbt schema.yml ç¶­è­·ï¼Œç„¶å¾Œï¼š
- ä½¿ç”¨ `dbt docs generate` ç”Ÿæˆæ–‡æª”
- ä½¿ç”¨ dbt çš„ `persist_docs` é…ç½®åŒæ­¥åˆ° BigQuery

**é…ç½® persist_docs**ï¼š

```yaml
# dbt_project.yml
models:
  m3_analytics:
    marts:
      +persist_docs:
        relation: true  # åŒæ­¥è¡¨æè¿°åˆ° BigQuery
        columns: true   # åŒæ­¥æ¬„ä½æè¿°åˆ° BigQuery
```

åŸ·è¡Œå¾Œï¼Œdbt æœƒå°‡ schema.yml çš„æè¿°å¯«å…¥ BigQuery è¡¨çš„ metadataã€‚

**åŸå‰‡ 2ï¼šå®šæœŸå¯©æŸ¥**

å»ºç«‹å­£åº¦ Schema å¯©æŸ¥æµç¨‹ï¼š
1. æª¢æŸ¥æ˜¯å¦æœ‰ "TODO" æè¿°
2. é©—è­‰æè¿°æ˜¯å¦ä»ç„¶æº–ç¢º
3. æ›´æ–°æ¥­å‹™è¦å‰‡è®Šæ›´

**åŸå‰‡ 3ï¼šCode Review å¿…æŸ¥**

åœ¨ Pull Request ä¸­ï¼Œæª¢æŸ¥ï¼š
- [ ] æ–°æ¬„ä½æ˜¯å¦æœ‰æè¿°
- [ ] æè¿°æ˜¯å¦æ¸…æ¥šå®Œæ•´
- [ ] æ˜¯å¦åŠ å…¥é©ç•¶çš„ tests

## 8.2 ç´„æŸæ¢ä»¶è™•ç†

### 8.2.1 BigQuery çš„ç´„æŸé¡å‹

BigQuery æ”¯æ´ä»¥ä¸‹ç´„æŸï¼ˆå¤§éƒ¨åˆ†æ˜¯ metadataï¼Œä¸å¼·åˆ¶åŸ·è¡Œï¼‰ï¼š

| ç´„æŸé¡å‹ | BigQuery æ”¯æ´ | å¼·åˆ¶åŸ·è¡Œ | dbt å°æ‡‰ |
|---------|--------------|---------|---------|
| NOT NULL | âœ… Yes | âŒ No* | `not_null` test |
| PRIMARY KEY | âœ… Yes (metadata) | âŒ No | `unique` + `not_null` |
| FOREIGN KEY | âœ… Yes (metadata) | âŒ No | `relationships` test |
| UNIQUE | âœ… Yes (metadata) | âŒ No | `unique` test |
| CHECK | âŒ No | âŒ No | custom tests |

*BigQuery ä¸å¼·åˆ¶åŸ·è¡Œ NOT NULLï¼Œä½†æœƒåœ¨ schema ä¸­æ¨™è¨˜ã€‚

### 8.2.2 NOT NULL ç´„æŸé·ç§»

**è­˜åˆ¥ BigQuery ä¸­çš„ NOT NULL æ¬„ä½**ï¼š

```sql
SELECT
    column_name,
    is_nullable
FROM `m3-project.analytics.INFORMATION_SCHEMA.COLUMNS`
WHERE table_name = 'user_daily_transactions'
  AND is_nullable = 'NO';
```

çµæœï¼š

```
column_name
user_id
transaction_id
transaction_date
amount
status
```

**åœ¨ dbt ä¸­åŠ å…¥ not_null tests**ï¼š

```yaml
columns:
  - name: user_id
    tests:
      - not_null
  - name: transaction_id
    tests:
      - not_null
  - name: transaction_date
    tests:
      - not_null
  - name: amount
    tests:
      - not_null
  - name: status
    tests:
      - not_null
```

**åŸ·è¡Œæ¸¬è©¦**ï¼š

```bash
dbt test -s user_daily_transactions
```

å¦‚æœæœ‰ NULL å€¼ï¼Œæ¸¬è©¦æœƒå¤±æ•—ï¼š

```
Failure in test not_null_user_daily_transactions_user_id
  Got 5 results, configured to fail if != 0

  compiled SQL at target/compiled/.../not_null_user_daily_transactions_user_id.sql
```

é€™æ˜¯å¥½äº‹ï¼åœ¨é·ç§»éšæ®µç™¼ç¾æ•¸æ“šå“è³ªå•é¡Œã€‚

### 8.2.3 PRIMARY KEY å’Œ UNIQUE ç´„æŸ

BigQuery çš„ PRIMARY KEY åªæ˜¯ metadataï¼Œä¸ä¿è­‰å”¯ä¸€æ€§ã€‚åœ¨ dbt ä¸­ç”¨ tests é©—è­‰ã€‚

**é·ç§»ç­–ç•¥**ï¼š

```sql
-- BigQuery è¡¨å®šç¾©ï¼ˆå¯èƒ½æœ‰ï¼‰
CREATE TABLE users (
    user_id INT64 PRIMARY KEY,  -- è²æ˜ä½†ä¸å¼·åˆ¶
    email STRING UNIQUE,        -- è²æ˜ä½†ä¸å¼·åˆ¶
    ...
)
```

**dbt schema.yml**ï¼š

```yaml
columns:
  - name: user_id
    description: "ç”¨æˆ¶å”¯ä¸€è­˜åˆ¥ç¢¼ï¼ˆPRIMARY KEYï¼‰"
    tests:
      - unique      # é©—è­‰å”¯ä¸€æ€§
      - not_null    # é©—è­‰éç©º

  - name: email
    description: "ç”¨æˆ¶é›»å­éƒµä»¶ï¼ˆUNIQUEï¼‰"
    tests:
      - unique
```

**çµ„åˆä¸»éµï¼ˆComposite Keyï¼‰**ï¼š

```yaml
# å°æ–¼çµ„åˆä¸»éµï¼ˆuser_id + transaction_dateï¼‰
models:
  - name: user_daily_summary
    tests:
      - dbt_utils.unique_combination_of_columns:  # éœ€å®‰è£ dbt_utils
          combination_of_columns:
            - user_id
            - transaction_date
```

### 8.2.4 FOREIGN KEY ç´„æŸï¼ˆRelationshipsï¼‰

FOREIGN KEY åœ¨ dbt ä¸­ç”¨ `relationships` test è¡¨é”ã€‚

**ç¯„ä¾‹**ï¼š

```yaml
# transactions è¡¨åƒç…§ users è¡¨
models:
  - name: transactions
    columns:
      - name: user_id
        description: "è²·å®¶ç”¨æˆ¶ IDï¼ˆåƒç…§ users.user_idï¼‰"
        tests:
          - relationships:
              to: source('raw_data', 'users')  # åƒç…§ä¾†æº
              field: user_id                    # åƒç…§æ¬„ä½
```

**åŸ·è¡Œæ¸¬è©¦**ï¼š

```bash
dbt test -s transactions
```

å¦‚æœæœ‰ orphan recordsï¼ˆå¤–éµä¸å­˜åœ¨ï¼‰ï¼Œæ¸¬è©¦æœƒå¤±æ•—ï¼š

```
Failure in test relationships_transactions_user_id__user_id__source_raw_data_users
  Got 12 results, configured to fail if != 0

  These 12 user_id values in transactions do not exist in users:
  - 10023
  - 10045
  ...
```

é€™å¹«åŠ©æˆ‘å€‘ç™¼ç¾æ•¸æ“šå®Œæ•´æ€§å•é¡Œã€‚

### 8.2.5 è‡ªå®šç¾©ç´„æŸï¼ˆCustom Testsï¼‰

å°æ–¼æ›´è¤‡é›œçš„æ¥­å‹™è¦å‰‡ï¼Œå»ºç«‹è‡ªå®šç¾© testsã€‚

**ç¯„ä¾‹ 1ï¼šé‡‘é¡å¿…é ˆå¤§æ–¼ 0**

å‰µå»º `tests/assert_amount_positive.sql`ï¼š

```sql
-- tests/assert_amount_positive.sql
-- é©—è­‰ amount æ¬„ä½å¿…é ˆ > 0

SELECT
    transaction_id,
    amount
FROM {{ ref('user_daily_transactions') }}
WHERE amount <= 0
```

å¦‚æœæŸ¥è©¢æœ‰çµæœï¼Œæ¸¬è©¦å¤±æ•—ã€‚

**ç¯„ä¾‹ 2ï¼šæ—¥æœŸç¯„åœé©—è­‰**

```sql
-- tests/assert_valid_date_range.sql
-- é©—è­‰ transaction_date åœ¨åˆç†ç¯„åœå…§

SELECT
    transaction_id,
    transaction_date
FROM {{ ref('user_daily_transactions') }}
WHERE transaction_date < '2020-01-01'  -- æ¥­å‹™é–‹å§‹æ—¥æœŸ
   OR transaction_date > CURRENT_DATE() + 1  -- ä¸æ‡‰è©²æœ‰æœªä¾†æ—¥æœŸ
```

**ç¯„ä¾‹ 3ï¼šç‹€æ…‹è½‰æ›é©—è­‰**

```sql
-- tests/assert_status_transition_valid.sql
-- é©—è­‰ç‹€æ…‹è½‰æ›çš„åˆç†æ€§

WITH status_changes AS (
    SELECT
        user_id,
        transaction_id,
        status AS current_status,
        LAG(status) OVER (PARTITION BY user_id ORDER BY transaction_date) AS previous_status
    FROM {{ ref('user_transactions_history') }}
)
SELECT *
FROM status_changes
WHERE
    -- ä¸å…è¨±å¾ completed å›åˆ° pending
    (previous_status = 'completed' AND current_status = 'pending')
    OR
    -- ä¸å…è¨±å¾ cancelled åˆ°ä»»ä½•å…¶ä»–ç‹€æ…‹
    (previous_status = 'cancelled' AND current_status != 'cancelled')
```

### 8.2.6 ç´„æŸé·ç§»çš„å®Œæ•´æµç¨‹

**Step 1ï¼šè­˜åˆ¥åŸå§‹ç´„æŸ**

```python
# scripts/extract_constraints.py
from google.cloud import bigquery

def extract_constraints(project_id, dataset_id, table_id):
    client = bigquery.Client(project=project_id)
    table = client.get_table(f"{project_id}.{dataset_id}.{table_id}")

    constraints = {
        'not_null': [],
        'unique': [],
        'primary_key': [],
        'foreign_keys': []
    }

    for field in table.schema:
        if field.mode == 'REQUIRED':
            constraints['not_null'].append(field.name)

    # BigQuery API ç›®å‰ä¸ç›´æ¥æš´éœ² PRIMARY KEY/FOREIGN KEY metadata
    # éœ€è¦æŸ¥è©¢ INFORMATION_SCHEMA æˆ–å¾åŸå§‹ DDL è§£æ

    return constraints
```

**Step 2ï¼šç”Ÿæˆ dbt tests**

```python
def generate_tests_from_constraints(constraints):
    tests = []

    for column in constraints['not_null']:
        tests.append({
            'column': column,
            'test': 'not_null'
        })

    for column in constraints['unique']:
        tests.append({
            'column': column,
            'test': 'unique'
        })

    # ... ç”Ÿæˆå…¶ä»– tests

    return tests
```

**Step 3ï¼šæ•´åˆåˆ° schema.yml**

è‡ªå‹•å°‡æå–çš„ç´„æŸåŠ å…¥åˆ° schema.yml çš„ tests å€å¡Šã€‚

## 8.3 UDF é·ç§»ç­–ç•¥

### 8.3.1 BigQuery UDF æ¦‚è¿°

**User-Defined Functions (UDF)** å…è¨±åœ¨ SQL ä¸­ä½¿ç”¨è‡ªå®šç¾©é‚è¼¯ã€‚

**ç¯„ä¾‹**ï¼š

```sql
-- å®šç¾© UDF
CREATE TEMP FUNCTION calculate_discount(amount FLOAT64, user_type STRING)
RETURNS FLOAT64
LANGUAGE js AS """
  if (user_type === 'premium') {
    return amount * 0.9;  // 10% æŠ˜æ‰£
  } else {
    return amount;
  }
""";

-- ä½¿ç”¨ UDF
SELECT
    transaction_id,
    amount,
    calculate_discount(amount, user_type) as discounted_amount
FROM transactions;
```

**UDF çš„é¡å‹**ï¼š

1. **SQL UDF**ï¼šç”¨ SQL èªæ³•å®šç¾©
2. **JavaScript UDF**ï¼šç”¨ JavaScript å®šç¾©ï¼ˆæ›´éˆæ´»ï¼‰
3. **Persistent UDF**ï¼šä¿å­˜åœ¨ dataset ä¸­ï¼Œå¯é‡è¤‡ä½¿ç”¨
4. **Temporary UDF**ï¼šåªåœ¨å–®ä¸€æŸ¥è©¢ä¸­æœ‰æ•ˆ

### 8.3.2 ä½•æ™‚ä¿ç•™ UDF vs è½‰ç‚º Macro

**æ±ºç­–æ¨¹**ï¼š

```mermaid
graph TD
    A[é‡åˆ° UDF] --> B{UDF è¤‡é›œåº¦?}
    B -->|ç°¡å–®é‚è¼¯| C[è½‰ç‚º dbt macro]
    B -->|è¤‡é›œé‚è¼¯| D{ä½¿ç”¨é »ç‡?}
    D -->|é«˜é »| E[è½‰ç‚º dbt macro]
    D -->|ä½é »| F{æ˜¯å¦å¿…é ˆç”¨ JavaScript?}
    F -->|æ˜¯| G[ä¿ç•™ç‚º UDF<br/>ç”¨ pre-hook å‰µå»º]
    F -->|å¦| C
```

**ä¿ç•™ UDF çš„æƒ…æ³**ï¼š
- è¤‡é›œçš„ JavaScript é‚è¼¯ï¼Œç”¨ SQL é›£ä»¥è¡¨é”
- éœ€è¦ JavaScript ç‰¹æœ‰çš„å‡½æ•¸æˆ–åº«
- ä½é »ä½¿ç”¨ï¼Œè½‰æ›æˆæœ¬é«˜

**è½‰ç‚º dbt macro çš„æƒ…æ³**ï¼š
- ç°¡å–®çš„é‚è¼¯ï¼ˆå¯ç”¨ SQL è¡¨é”ï¼‰
- é«˜é »ä½¿ç”¨ï¼ˆåœ¨å¤šå€‹æ¨¡å‹ä¸­ï¼‰
- ç‚ºäº†å¯ç§»æ¤æ€§ï¼ˆdbt å¯ä»¥è·¨æ•¸æ“šå€‰åº«ï¼‰

### 8.3.3 UDF åˆ° Macro çš„è½‰æ›

**ç¯„ä¾‹ 1ï¼šç°¡å–®è¨ˆç®— UDF**

**åŸå§‹ BigQuery UDF**ï¼š

```sql
CREATE TEMP FUNCTION calculate_discount(amount FLOAT64, user_type STRING)
RETURNS FLOAT64 AS (
  CASE
    WHEN user_type = 'premium' THEN amount * 0.9
    WHEN user_type = 'gold' THEN amount * 0.85
    ELSE amount
  END
);
```

**dbt Macro** (`macros/calculate_discount.sql`)ï¼š

```sql
-- macros/calculate_discount.sql
{% macro calculate_discount(amount, user_type) %}
  CASE
    WHEN {{ user_type }} = 'premium' THEN {{ amount }} * 0.9
    WHEN {{ user_type }} = 'gold' THEN {{ amount }} * 0.85
    ELSE {{ amount }}
  END
{% endmacro %}
```

**ä½¿ç”¨**ï¼š

```sql
-- models/marts/transactions_with_discount.sql
SELECT
    transaction_id,
    amount,
    {{ calculate_discount('amount', 'user_type') }} as discounted_amount
FROM {{ ref('transactions') }}
```

ç·¨è­¯å¾Œï¼š

```sql
SELECT
    transaction_id,
    amount,
    CASE
      WHEN user_type = 'premium' THEN amount * 0.9
      WHEN user_type = 'gold' THEN amount * 0.85
      ELSE amount
    END as discounted_amount
FROM transactions
```

**ç¯„ä¾‹ 2ï¼šæ—¥æœŸè™•ç† UDF**

**åŸå§‹ UDF**ï¼š

```sql
CREATE TEMP FUNCTION get_fiscal_quarter(date_value DATE)
RETURNS STRING AS (
  CONCAT('FY', FORMAT_DATE('%Y', date_value), '-Q',
    CAST(CEIL(EXTRACT(MONTH FROM date_value) / 3.0) AS STRING))
);

-- ä½¿ç”¨ï¼šget_fiscal_quarter('2024-05-15') â†’ 'FY2024-Q2'
```

**dbt Macro**ï¼š

```sql
-- macros/get_fiscal_quarter.sql
{% macro get_fiscal_quarter(date_field) %}
  CONCAT(
    'FY',
    FORMAT_DATE('%Y', {{ date_field }}),
    '-Q',
    CAST(CEIL(EXTRACT(MONTH FROM {{ date_field }}) / 3.0) AS STRING)
  )
{% endmacro %}
```

**ä½¿ç”¨**ï¼š

```sql
SELECT
    transaction_date,
    {{ get_fiscal_quarter('transaction_date') }} as fiscal_quarter,
    SUM(amount) as total_amount
FROM {{ ref('transactions') }}
GROUP BY 1, 2
```

### 8.3.4 ä¿ç•™ JavaScript UDF

å°æ–¼å¿…é ˆç”¨ JavaScript çš„è¤‡é›œé‚è¼¯ï¼Œåœ¨ dbt ä¸­ç”¨ **pre-hook** å‰µå»º UDFã€‚

**ç¯„ä¾‹ï¼šè¤‡é›œçš„ JSON è§£æ UDF**

**åŸå§‹ UDF**ï¼š

```sql
CREATE TEMP FUNCTION parse_complex_json(json_string STRING)
RETURNS ARRAY<STRUCT<key STRING, value FLOAT64>>
LANGUAGE js AS """
  const obj = JSON.parse(json_string);
  const result = [];
  for (const [key, value] of Object.entries(obj)) {
    if (typeof value === 'number') {
      result.push({key: key, value: value});
    }
  }
  return result;
""";
```

**dbt æ¨¡å‹** (`models/marts/parsed_events.sql`)ï¼š

```sql
-- models/marts/parsed_events.sql

{{ config(
    pre_hook=[
        """
        CREATE TEMP FUNCTION parse_complex_json(json_string STRING)
        RETURNS ARRAY<STRUCT<key STRING, value FLOAT64>>
        LANGUAGE js AS '''
          const obj = JSON.parse(json_string);
          const result = [];
          for (const [key, value] of Object.entries(obj)) {
            if (typeof value === 'number') {
              result.push({key: key, value: value});
            }
          }
          return result;
        ''';
        """
    ]
) }}

SELECT
    event_id,
    event_timestamp,
    parse_complex_json(event_data) as parsed_data
FROM {{ source('raw_data', 'events') }}
```

**pre-hook** æœƒåœ¨æ¨¡å‹åŸ·è¡Œå‰é‹è¡Œï¼Œå‰µå»ºè‡¨æ™‚ UDFã€‚

### 8.3.5 Persistent UDF é·ç§»

å¦‚æœåŸå§‹å°ˆæ¡ˆä½¿ç”¨ Persistent UDFï¼ˆä¿å­˜åœ¨ dataset ä¸­ï¼‰ï¼Œéœ€è¦åœ¨ dbt å°ˆæ¡ˆä¸­é‡æ–°å‰µå»ºã€‚

**ç­–ç•¥**ï¼šä½¿ç”¨ dbt **on-run-start** hooks

```yaml
# dbt_project.yml
on-run-start:
  - |
    CREATE OR REPLACE FUNCTION `{{ target.project }}.{{ target.dataset }}.calculate_discount`(amount FLOAT64, user_type STRING)
    RETURNS FLOAT64 AS (
      CASE
        WHEN user_type = 'premium' THEN amount * 0.9
        WHEN user_type = 'gold' THEN amount * 0.85
        ELSE amount
      END
    );
  - |
    CREATE OR REPLACE FUNCTION `{{ target.project }}.{{ target.dataset }}.get_fiscal_quarter`(date_value DATE)
    RETURNS STRING AS (
      CONCAT('FY', FORMAT_DATE('%Y', date_value), '-Q',
        CAST(CEIL(EXTRACT(MONTH FROM date_value) / 3.0) AS STRING))
    );
```

åŸ·è¡Œ `dbt run` æ™‚ï¼Œé€™äº› UDF æœƒåœ¨ä»»ä½•æ¨¡å‹ä¹‹å‰è¢«å‰µå»ºã€‚

**æ¨¡å‹ä¸­ä½¿ç”¨**ï¼š

```sql
SELECT
    transaction_id,
    amount,
    `{{ target.dataset }}`.calculate_discount(amount, user_type) as discounted_amount
FROM {{ ref('transactions') }}
```

### 8.3.6 UDF é·ç§»çš„æœ€ä½³å¯¦è¸

**åŸå‰‡ 1ï¼šå„ªå…ˆè½‰ç‚º Macro**

Macros çš„å„ªå‹¢ï¼š
- å¯ç§»æ¤æ€§ï¼ˆè·¨æ•¸æ“šå€‰åº«ï¼‰
- æ˜“æ–¼æ¸¬è©¦
- ç‰ˆæœ¬æ§åˆ¶åœ¨ dbt å°ˆæ¡ˆä¸­
- ç·¨è­¯æ™‚å±•é–‹ï¼Œæ€§èƒ½æ›´å¥½

**åŸå‰‡ 2ï¼šæ–‡æª”åŒ– UDF**

ç‚ºæ¯å€‹ UDF/Macro æ’°å¯«æ¸…æ¥šçš„æ–‡æª”ï¼š

```sql
-- macros/calculate_discount.sql
{#
  è¨ˆç®—æŠ˜æ‰£å¾Œçš„é‡‘é¡

  åƒæ•¸ï¼š
    - amount (FLOAT64): åŸå§‹é‡‘é¡
    - user_type (STRING): ç”¨æˆ¶é¡å‹ï¼ˆpremium, gold, regularï¼‰

  è¿”å›ï¼š
    FLOAT64: æŠ˜æ‰£å¾Œé‡‘é¡

  ç¯„ä¾‹ï¼š
    {{ calculate_discount('amount', 'user_type') }}

  æŠ˜æ‰£è¦å‰‡ï¼š
    - premium: 10% æŠ˜æ‰£ï¼ˆ0.9 å€ï¼‰
    - gold: 15% æŠ˜æ‰£ï¼ˆ0.85 å€ï¼‰
    - regular: ç„¡æŠ˜æ‰£
#}
{% macro calculate_discount(amount, user_type) %}
  ...
{% endmacro %}
```

**åŸå‰‡ 3ï¼šé›†ä¸­ç®¡ç†**

å°‡æ‰€æœ‰ UDF/Macros æ”¾åœ¨å°ˆé–€çš„ç›®éŒ„ï¼š

```
macros/
â”œâ”€â”€ business_logic/
â”‚   â”œâ”€â”€ calculate_discount.sql
â”‚   â”œâ”€â”€ get_fiscal_quarter.sql
â”‚   â””â”€â”€ classify_customer.sql
â”œâ”€â”€ date_utils/
â”‚   â”œâ”€â”€ get_week_start.sql
â”‚   â””â”€â”€ is_business_day.sql
â””â”€â”€ string_utils/
    â”œâ”€â”€ clean_email.sql
    â””â”€â”€ normalize_phone.sql
```

## 8.4 è¤‡é›œæ¬„ä½é¡å‹è™•ç†

### 8.4.1 STRUCT é¡å‹

BigQuery çš„ **STRUCT** æ˜¯å·¢ç‹€çµæ§‹ï¼Œé¡ä¼¼ç‰©ä»¶ã€‚

**ç¯„ä¾‹**ï¼š

```sql
CREATE TABLE users (
    user_id INT64,
    profile STRUCT<
        name STRING,
        email STRING,
        age INT64
    >
)
```

æŸ¥è©¢ï¼š

```sql
SELECT
    user_id,
    profile.name,      -- è¨ªå•å·¢ç‹€æ¬„ä½
    profile.email
FROM users
```

**åœ¨ dbt ä¸­è™•ç† STRUCT**ï¼š

é‚è¼¯ä¿æŒä¸è®Šï¼Œä½† schema.yml éœ€è¦è©³ç´°æè¿°ï¼š

```yaml
columns:
  - name: user_id
    description: "ç”¨æˆ¶ ID"

  - name: profile
    description: |
      ç”¨æˆ¶æª”æ¡ˆè³‡è¨Šï¼ˆSTRUCT é¡å‹ï¼‰

      **çµæ§‹**ï¼š
      - name (STRING): ç”¨æˆ¶å§“å
      - email (STRING): é›»å­éƒµä»¶
      - age (INT64): å¹´é½¡
```

å¦‚æœéœ€è¦æ‰å¹³åŒ–ï¼š

```sql
-- models/marts/users_flattened.sql
SELECT
    user_id,
    profile.name as user_name,
    profile.email as user_email,
    profile.age as user_age
FROM {{ source('raw_data', 'users') }}
```

### 8.4.2 ARRAY é¡å‹

**ARRAY** æ˜¯é™£åˆ—ï¼ŒåŒ…å«å¤šå€‹ç›¸åŒé¡å‹çš„å€¼ã€‚

**ç¯„ä¾‹**ï¼š

```sql
CREATE TABLE orders (
    order_id STRING,
    product_ids ARRAY<STRING>  -- å¤šå€‹ç”¢å“ ID
)
```

æŸ¥è©¢ï¼ˆä½¿ç”¨ UNNESTï¼‰ï¼š

```sql
SELECT
    order_id,
    product_id
FROM orders,
UNNEST(product_ids) as product_id  -- å±•é–‹é™£åˆ—
```

**åœ¨ dbt ä¸­è™•ç† ARRAY**ï¼š

```sql
-- models/marts/order_items.sql
SELECT
    order_id,
    product_id,
    ARRAY_LENGTH(product_ids) as product_count
FROM {{ source('raw_data', 'orders') }},
UNNEST(product_ids) as product_id
```

**Schema å®šç¾©**ï¼š

```yaml
# source
sources:
  - name: raw_data
    tables:
      - name: orders
        columns:
          - name: product_ids
            description: "ç”¢å“ ID é™£åˆ—ï¼ˆARRAY<STRING>ï¼‰"

# model
models:
  - name: order_items
    description: "è¨‚å–®é …ç›®ï¼ˆå±•é–‹å¾Œçš„ç”¢å“åˆ—è¡¨ï¼‰"
    columns:
      - name: product_id
        description: "ç”¢å“ IDï¼ˆå¾ product_ids é™£åˆ—å±•é–‹ï¼‰"
```

### 8.4.3 å·¢ç‹€ STRUCT å’Œ ARRAY

æ›´è¤‡é›œçš„æƒ…æ³ï¼šARRAY of STRUCT

```sql
CREATE TABLE transactions (
    transaction_id STRING,
    line_items ARRAY<STRUCT<
        product_id STRING,
        quantity INT64,
        unit_price FLOAT64
    >>
)
```

æŸ¥è©¢ï¼š

```sql
SELECT
    transaction_id,
    item.product_id,
    item.quantity,
    item.unit_price,
    item.quantity * item.unit_price as line_total
FROM transactions,
UNNEST(line_items) as item
```

**dbt æ¨¡å‹**ï¼š

```sql
-- models/marts/transaction_line_items.sql
{{ config(
    description='äº¤æ˜“æ˜ç´°ï¼ˆå±•é–‹ line_itemsï¼‰'
) }}

SELECT
    transaction_id,
    item.product_id,
    item.quantity,
    item.unit_price,
    item.quantity * item.unit_price as line_total
FROM {{ source('raw_data', 'transactions') }},
UNNEST(line_items) as item
```

### 8.4.4 GEOGRAPHY é¡å‹

BigQuery ç‰¹æœ‰çš„åœ°ç†ç©ºé–“é¡å‹ã€‚

**ç¯„ä¾‹**ï¼š

```sql
CREATE TABLE stores (
    store_id STRING,
    location GEOGRAPHY  -- åœ°ç†ä½ç½®
)
```

æŸ¥è©¢ï¼š

```sql
SELECT
    store_id,
    ST_ASTEXT(location) as location_wkt,  -- è½‰ç‚º WKT æ ¼å¼
    ST_X(location) as longitude,
    ST_Y(location) as latitude
FROM stores
```

**åœ¨ dbt ä¸­è™•ç†**ï¼š

ä¿æŒ GEOGRAPHY å‡½æ•¸ä¸è®Šï¼Œåœ¨ schema.yml ä¸­èªªæ˜ï¼š

```yaml
columns:
  - name: location
    description: |
      å•†åº—åœ°ç†ä½ç½®ï¼ˆGEOGRAPHY é¡å‹ï¼‰

      **æ ¼å¼**ï¼šWGS84 åº§æ¨™ç³»
      **ç¯„ä¾‹æŸ¥è©¢**ï¼š
      - ST_ASTEXT(location)ï¼šè½‰ç‚º WKT æ–‡å­—
      - ST_X(location)ï¼šå–å¾—ç¶“åº¦
      - ST_Y(location)ï¼šå–å¾—ç·¯åº¦
```

## æœ¬ç« ç¸½çµ

åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘å€‘æŒæ¡äº†é·ç§»ä¸­çš„æ‰€æœ‰ç´°ç¯€è™•ç†ï¼š

âœ… **å®Œæ•´çš„ Schema é·ç§»æµç¨‹**ï¼ŒåŒ…æ‹¬è‡ªå‹•åŒ–æå–å’Œç”Ÿæˆå·¥å…·
âœ… **ç´„æŸæ¢ä»¶çš„ç³»çµ±åŒ–è™•ç†**ï¼Œå¾ NOT NULL åˆ°è‡ªå®šç¾©æ¥­å‹™è¦å‰‡
âœ… **UDF åˆ° dbt Macros çš„è½‰æ›**ï¼Œä¿ç•™å¿…è¦çš„ JavaScript UDF
âœ… **è¤‡é›œæ¬„ä½é¡å‹çš„è™•ç†**ï¼ŒåŒ…æ‹¬ STRUCTã€ARRAYã€GEOGRAPHY

### æ ¸å¿ƒæ”¶ç©«

**é—œæ–¼ Schema é·ç§»**ï¼š
- è‡ªå‹•åŒ–ç”Ÿæˆæ¸›å°‘ 90% çš„æ‰‹å‹•å·¥ä½œ
- å®Œæ•´çš„æè¿°æ˜¯åœ˜éšŠå”ä½œçš„é—œéµ
- persist_docs ç¢ºä¿å–®ä¸€ä¾†æº

**é—œæ–¼ç´„æŸè™•ç†**ï¼š
- dbt tests å–ä»£ BigQuery constraints
- æ—©æœŸç™¼ç¾æ•¸æ“šå“è³ªå•é¡Œ
- è‡ªå®šç¾© tests è¡¨é”è¤‡é›œæ¥­å‹™è¦å‰‡

**é—œæ–¼ UDF é·ç§»**ï¼š
- å„ªå…ˆè½‰ç‚º dbt macrosï¼ˆå¯ç§»æ¤æ€§ï¼‰
- ä¿ç•™å¿…è¦çš„ JavaScript UDF
- å……åˆ†æ–‡æª”åŒ–æ‰€æœ‰è‡ªå®šç¾©é‚è¼¯

### å¯¦æˆ°çµ±è¨ˆ

æ‰€æœ‰æ ¸å¿ƒæŠ€è¡“æ¨¡å¼å·²å®Œæˆï¼š

| æ¨¡å¼é¡å‹ | æ•¸é‡ | å·²å®Œæˆ | ç‹€æ…‹ |
|---------|------|-------|------|
| å®Œå…¨æ›´æ–°è¡¨ | 30 | âœ… | æŒæ¡ |
| åˆ†å€è¡¨ | 10 | âœ… | æŒæ¡ |
| åˆ†ç‰‡è¡¨ | 10 | âœ… | æŒæ¡ |
| Schema/UDF è™•ç† | - | âœ… | æŒæ¡ |

### ä¸‹ä¸€ç« é å‘Š

åœ¨ç¬¬ 9 ç« ï¼Œæˆ‘å€‘å°‡é€²å…¥**çŸ¥è­˜è¿­ä»£å¾ªç’° - å¾éŒ¯èª¤ä¸­å­¸ç¿’**ã€‚

é€™æ˜¯æœ¬æ›¸æœ€æ ¸å¿ƒçš„ç« ç¯€ä¹‹ä¸€ï¼Œå±•ç¤ºï¼š
- é·ç§»æ‰‹å†Šå¾ v1.0 åˆ° v3.0 çš„å®Œæ•´æ¼”é€²
- å¯¦éš›é‡åˆ°çš„ 10+ ç¨®éŒ¯èª¤æ¡ˆä¾‹
- éŒ¯èª¤ â†’ åˆ†æ â†’ æ‰‹å†Šæ›´æ–° â†’ æ”¹é€²çš„å®Œæ•´å¾ªç’°
- AI èƒ½åŠ›æˆé•·çš„é‡åŒ–æŒ‡æ¨™

é€™å°‡æ˜¯æ•´å€‹é·ç§»å°ˆæ¡ˆçš„ã€ŒçŸ¥è­˜çµæ™¶ã€ã€‚æº–å‚™å¥½äº†å—ï¼Ÿè®“æˆ‘å€‘ç¹¼çºŒï¼

---

**æœ¬ç« ç”¢å‡ºç‰©æ¸…å–®**ï¼š
- âœ… Schema è‡ªå‹•ç”Ÿæˆè…³æœ¬
- âœ… ç´„æŸæå–èˆ‡é·ç§»å·¥å…·
- âœ… UDF åˆ° Macro è½‰æ›ç¯„ä¾‹
- âœ… è¤‡é›œé¡å‹è™•ç†æŒ‡å—

**ä¸‹ä¸€æ­¥è¡Œå‹•**ï¼š
1. ç‚ºæ‰€æœ‰æ¨¡å‹ç”Ÿæˆå®Œæ•´ schema.yml
2. åŸ·è¡Œæ‰€æœ‰ tests ä¸¦ä¿®æ­£å•é¡Œ
3. æº–å‚™é€²å…¥ç¬¬ 9 ç« ï¼šçŸ¥è­˜è¿­ä»£å¾ªç’°
