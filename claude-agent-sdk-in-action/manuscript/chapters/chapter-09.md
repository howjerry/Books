# ç¬¬ 9 ç« ï¼šå¤šå±¤æ¬¡å”èª¿èˆ‡å…ƒ Agent - å®Œæ•´æ‡‰ç”¨ç¨‹å¼é‡å¯«å°ˆæ¡ˆ

## æœ¬ç« å…§å®¹æ¦‚è¦½

- ç†è§£ Meta Agent çš„è¨­è¨ˆæ¨¡å¼èˆ‡æ ¸å¿ƒåƒ¹å€¼
- å¯¦ä½œä¸‰å±¤æ¶æ§‹ï¼šè¦åŠƒå±¤ã€å”èª¿å±¤ã€åŸ·è¡Œå±¤
- å»ºæ§‹å®Œæ•´çš„ä»»å‹™åˆ†è§£èˆ‡ä¾è³´ç®¡ç†ç³»çµ±
- å¯¦ç¾è‡ªé©æ‡‰æ±ºç­–èˆ‡éŒ¯èª¤æ¢å¾©æ©Ÿåˆ¶
- å®Œæˆä¸€å€‹çœŸå¯¦çš„å–®é«”æ‡‰ç”¨é‡å¯«å°ˆæ¡ˆ

---

## 9.1 å ´æ™¯ï¼šä¸€å€‹åƒ¹å€¼åƒè¬çš„æŠ€è¡“å‚µ

### çœŸå¯¦æŒ‘æˆ°

ä½ æ˜¯ TechCorp çš„æŠ€è¡“ç¸½ç›£ï¼Œå…¬å¸çš„æ ¸å¿ƒæ¥­å‹™ç³»çµ±æ˜¯ä¸€å€‹é‹è¡Œäº† 8 å¹´çš„ PHP å–®é«”æ‡‰ç”¨ï¼š

```
legacy_erp/
â”œâ”€â”€ index.php (12,000 è¡Œ)
â”œâ”€â”€ config.php (800 è¡Œ)
â”œâ”€â”€ functions.php (5,000 è¡Œ)
â””â”€â”€ modules/
    â”œâ”€â”€ customer.php (3,500 è¡Œ)
    â”œâ”€â”€ order.php (4,200 è¡Œ)
    â”œâ”€â”€ inventory.php (2,800 è¡Œ)
    â””â”€â”€ billing.php (3,100 è¡Œ)
```

**ç—›é»**ï¼š
- ğŸŒ **æ•ˆèƒ½ç“¶é ¸**ï¼šé«˜å³°æœŸéŸ¿æ‡‰æ™‚é–“ > 5 ç§’
- ğŸ”¥ **éƒ¨ç½²é¢¨éšª**ï¼šæ¯æ¬¡æ›´æ–°éœ€è¦åœæ©Ÿ 2 å°æ™‚
- ğŸ’° **ç¶­è­·æˆæœ¬**ï¼šæ–°åŠŸèƒ½é–‹ç™¼é€±æœŸå¾ 2 é€±å¢åŠ åˆ° 2 å€‹æœˆ
- ğŸ‘¥ **äººæ‰æµå¤±**ï¼šè³‡æ·±é–‹ç™¼è€…ä¸é¡˜æ„ç¶­è­·è€èˆŠç¨‹å¼ç¢¼

**ç›®æ¨™**ï¼šé‡å¯«ç‚ºå¾®æœå‹™æ¶æ§‹ï¼ˆPython FastAPI + PostgreSQL + Redisï¼‰

**å‚³çµ±æ–¹å¼çš„å›°å¢ƒ**ï¼š

```python
# âŒ å‚³çµ±æ–¹å¼ï¼šäººå·¥é‡å¯«
# æ™‚é–“ï¼š6-12 å€‹æœˆ
# æˆæœ¬ï¼š6 åé–‹ç™¼è€… Ã— 10 å€‹æœˆ = NT$ 3,600,000
# é¢¨éšªï¼šåŠŸèƒ½éºæ¼ã€é‚è¼¯éŒ¯èª¤ã€æ¥­å‹™ä¸­æ–·
```

**Meta Agent æ–¹å¼**ï¼š

```python
# âœ… Meta Agent è‡ªå‹•åŒ–é‡å¯«
# æ™‚é–“ï¼š2-3 é€±ï¼ˆè¦åŠƒ 3 å¤© + åŸ·è¡Œ 10 å¤© + é©—è­‰ 5 å¤©ï¼‰
# æˆæœ¬ï¼š1 åé–‹ç™¼è€…ç›£ç£ + AI æˆæœ¬ = NT$ 150,000
# å„ªå‹¢ï¼šå®Œæ•´æ–‡ä»¶ã€æ¸¬è©¦è¦†è“‹ç‡ 95%+ã€é›¶åŠŸèƒ½éºæ¼
```

---

## 9.2 ç†è§£ Meta Agentï¼šAgent çš„æŒ‡æ®å®˜

### 9.2.1 ä»€éº¼æ˜¯ Meta Agentï¼Ÿ

**Meta Agent** æ˜¯ä¸€å€‹ã€Œç®¡ç†å…¶ä»– Agent çš„ Agentã€ï¼Œå…·å‚™ä¸‰å€‹æ ¸å¿ƒèƒ½åŠ›ï¼š

1. **è¦åŠƒèƒ½åŠ›**ï¼ˆPlanningï¼‰
   - åˆ†æè¤‡é›œä»»å‹™
   - åˆ¶å®šåŸ·è¡Œè¨ˆç•«
   - è­˜åˆ¥ä»»å‹™ä¾è³´é—œä¿‚

2. **å”èª¿èƒ½åŠ›**ï¼ˆCoordinationï¼‰
   - å‰µå»ºä¸¦ç®¡ç† Subagents
   - åˆ†é…ä»»å‹™èˆ‡è³‡æº
   - ç›£æ§åŸ·è¡Œé€²åº¦

3. **æ±ºç­–èƒ½åŠ›**ï¼ˆDecision Makingï¼‰
   - è©•ä¼°åŸ·è¡Œçµæœ
   - å‹•æ…‹èª¿æ•´è¨ˆç•«
   - è™•ç†ç•°å¸¸èˆ‡éŒ¯èª¤

### 9.2.2 ä¸‰å±¤æ¶æ§‹è¨­è¨ˆ

```mermaid
graph TB
    subgraph "è¦åŠƒå±¤ (Planning Layer)"
        MetaAgent[Meta Agent<br/>ä»»å‹™åˆ†æèˆ‡è¦åŠƒ]
    end

    subgraph "å”èª¿å±¤ (Coordination Layer)"
        Coordinator[ä»»å‹™å”èª¿å™¨<br/>ä¾è³´ç®¡ç†èˆ‡èª¿åº¦]
    end

    subgraph "åŸ·è¡Œå±¤ (Execution Layer)"
        A1[Architecture<br/>Analyzer]
        A2[Code<br/>Analyzer]
        A3[API<br/>Generator]
        A4[Database<br/>Designer]
        A5[Service<br/>Implementer]
        A6[Test<br/>Generator]
    end

    MetaAgent -->|1. ç”Ÿæˆè¨ˆç•«| Coordinator
    Coordinator -->|2. åˆ†é…ä»»å‹™| A1
    Coordinator -->|3. ç­‰å¾…å®Œæˆ| A2
    Coordinator -->|4. ä¾åºåŸ·è¡Œ| A3
    Coordinator -->|5. ä¸¦è¡Œä»»å‹™| A4
    Coordinator -->|6. æœ€çµ‚é©—è­‰| A5
    Coordinator -->|7. å“è³ªä¿è­‰| A6

    A1 -.->|ä¾è³´| A2
    A2 -.->|ä¾è³´| A3
    A2 -.->|ä¾è³´| A4
    A3 -.->|ä¾è³´| A5
    A4 -.->|ä¾è³´| A5
    A5 -.->|ä¾è³´| A6

    style MetaAgent fill:#ff9999
    style Coordinator fill:#99ccff
    style A1 fill:#99ff99
    style A2 fill:#99ff99
    style A3 fill:#99ff99
    style A4 fill:#99ff99
    style A5 fill:#99ff99
    style A6 fill:#99ff99
```

### 9.2.3 èˆ‡å‰å¹¾ç« çš„å°æ¯”

| é¢å‘ | ç¬¬ 4 ç« <br/>Subagents | ç¬¬ 7 ç« <br/>å¾®æœå‹™æ¶æ§‹ | ç¬¬ 9 ç« <br/>Meta Agent |
|------|---------------------|----------------------|----------------------|
| **å±¤ç´š** | å–®å±¤ï¼ˆä¸» Agent + Subagentsï¼‰ | å–®å±¤ï¼ˆRouter + å°ˆæ¥­ Agentsï¼‰ | ä¸‰å±¤ï¼ˆMeta + Coordinator + Subagentsï¼‰ |
| **ä»»å‹™è¤‡é›œåº¦** | ä¸­ç­‰ï¼ˆç¨‹å¼ç¢¼é‡æ§‹ï¼‰ | ä¸­ç­‰ï¼ˆå®¢æœè«‹æ±‚è·¯ç”±ï¼‰ | é«˜ï¼ˆå®Œæ•´æ‡‰ç”¨é‡å¯«ï¼‰ |
| **æ±ºç­–èƒ½åŠ›** | ä¸» Agent æ±ºç­– | Router è·¯ç”± | Meta Agent è¦åŠƒ + å‹•æ…‹èª¿æ•´ |
| **ä»»å‹™ä¾è³´** | ç¨ç«‹ä¸¦è¡Œ | ç¨ç«‹è«‹æ±‚ | è¤‡é›œä¾è³´é—œä¿‚ |
| **éŒ¯èª¤è™•ç†** | é‡è©¦æ©Ÿåˆ¶ | é™ç´šè™•ç† | è‡ªé©æ‡‰æ¢å¾© |

---

## 9.3 å»ºæ§‹ Meta Agentï¼šè¦åŠƒå±¤

### 9.3.1 æ ¸å¿ƒè¨­è¨ˆ

Meta Agent çš„è·è²¬æ˜¯ã€Œæƒ³æ¸…æ¥šæ€éº¼åšã€ï¼Œè€Œä¸æ˜¯ã€Œè¦ªè‡ªå‹•æ‰‹åšã€ã€‚

```python
# meta_agent.py
from typing import List, Dict, Any
from dataclasses import dataclass, field
from enum import Enum
import anthropic
import json

class TaskType(Enum):
    """ä»»å‹™é¡å‹"""
    ANALYSIS = "analysis"          # åˆ†æå‹ä»»å‹™
    GENERATION = "generation"      # ç”Ÿæˆå‹ä»»å‹™
    TRANSFORMATION = "transformation"  # è½‰æ›å‹ä»»å‹™
    VALIDATION = "validation"      # é©—è­‰å‹ä»»å‹™

class TaskPriority(Enum):
    """ä»»å‹™å„ªå…ˆç´š"""
    CRITICAL = 1  # é—œéµè·¯å¾‘
    HIGH = 2      # é«˜å„ªå…ˆç´š
    MEDIUM = 3    # ä¸­ç­‰å„ªå…ˆç´š
    LOW = 4       # ä½å„ªå…ˆç´š

@dataclass
class Task:
    """ä»»å‹™å®šç¾©"""
    id: str
    name: str
    description: str
    task_type: TaskType
    priority: TaskPriority
    dependencies: List[str] = field(default_factory=list)  # â€¹1â€º
    estimated_time: int = 300  # é ä¼°æ™‚é–“ï¼ˆç§’ï¼‰
    retry_count: int = 3       # æœ€å¤§é‡è©¦æ¬¡æ•¸
    tools: List[str] = field(default_factory=list)  # éœ€è¦çš„å·¥å…·
    output_format: str = "json"  # è¼¸å‡ºæ ¼å¼
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            "id": self.id,
            "name": self.name,
            "description": self.description,
            "task_type": self.task_type.value,
            "priority": self.priority.value,
            "dependencies": self.dependencies,
            "estimated_time": self.estimated_time,
            "retry_count": self.retry_count,
            "tools": self.tools,
            "output_format": self.output_format,
            "metadata": self.metadata
        }

@dataclass
class ExecutionPlan:
    """åŸ·è¡Œè¨ˆç•«"""
    project_name: str
    objective: str
    tasks: List[Task]
    estimated_total_time: int
    critical_path: List[str]  # â€¹2â€º
    parallel_groups: List[List[str]] = field(default_factory=list)  # â€¹3â€º
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            "project_name": self.project_name,
            "objective": self.objective,
            "tasks": [task.to_dict() for task in self.tasks],
            "estimated_total_time": self.estimated_total_time,
            "critical_path": self.critical_path,
            "parallel_groups": self.parallel_groups,
            "metadata": self.metadata
        }

class MetaAgent:
    """
    â€¹4â€º Meta Agent - è² è²¬è¦åŠƒèˆ‡æ±ºç­–

    æ ¸å¿ƒè·è²¬ï¼š
    1. åˆ†æè¤‡é›œä»»å‹™éœ€æ±‚
    2. åˆ¶å®šè©³ç´°åŸ·è¡Œè¨ˆç•«
    3. è­˜åˆ¥ä»»å‹™ä¾è³´é—œä¿‚
    4. è¨ˆç®—é—œéµè·¯å¾‘
    5. ç›£æ§åŸ·è¡Œé€²åº¦
    6. å‹•æ…‹èª¿æ•´è¨ˆç•«
    """

    def __init__(
        self,
        api_key: str,
        model: str = "claude-opus-4-20250514",
        temperature: float = 0.3  # â€¹5â€º
    ):
        self.client = anthropic.Anthropic(api_key=api_key)
        self.model = model
        self.temperature = temperature
        self.conversation_history = []

    def analyze_project(
        self,
        project_description: str,
        codebase_info: Dict[str, Any]
    ) -> ExecutionPlan:
        """
        â€¹6â€º åˆ†æå°ˆæ¡ˆéœ€æ±‚ï¼Œç”ŸæˆåŸ·è¡Œè¨ˆç•«

        Args:
            project_description: å°ˆæ¡ˆæè¿°
            codebase_info: ç¨‹å¼ç¢¼åº«è³‡è¨Š

        Returns:
            ExecutionPlan: è©³ç´°åŸ·è¡Œè¨ˆç•«
        """
        # æ§‹å»ºåˆ†æ Prompt
        analysis_prompt = f"""
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è»Ÿé«”æ¶æ§‹å¸«å’Œå°ˆæ¡ˆç¶“ç†ï¼Œè² è²¬è¦åŠƒä¸€å€‹è¤‡é›œçš„æ‡‰ç”¨ç¨‹å¼é‡å¯«å°ˆæ¡ˆã€‚

## å°ˆæ¡ˆæè¿°
{project_description}

## ç¾æœ‰ç¨‹å¼ç¢¼åº«è³‡è¨Š
```json
{json.dumps(codebase_info, indent=2, ensure_ascii=False)}
```

## ä½ çš„ä»»å‹™
è«‹åˆ†æé€™å€‹é‡å¯«å°ˆæ¡ˆï¼Œä¸¦åˆ¶å®šè©³ç´°çš„åŸ·è¡Œè¨ˆç•«ã€‚è¨ˆç•«æ‡‰åŒ…å«ï¼š

1. **ä»»å‹™åˆ†è§£**ï¼šå°‡å°ˆæ¡ˆæ‹†åˆ†ç‚º 6-10 å€‹å…·é«”ä»»å‹™
2. **ä¾è³´é—œä¿‚**ï¼šæ˜ç¢ºæ¨™è¨»å“ªäº›ä»»å‹™å¿…é ˆåœ¨å…¶ä»–ä»»å‹™å®Œæˆå¾Œæ‰èƒ½åŸ·è¡Œ
3. **å„ªå…ˆç´š**ï¼šæ ¹æ“šé‡è¦æ€§å’Œä¾è³´é—œä¿‚è¨­å®šå„ªå…ˆç´š
4. **æ™‚é–“ä¼°ç®—**ï¼šé ä¼°æ¯å€‹ä»»å‹™çš„åŸ·è¡Œæ™‚é–“ï¼ˆç§’ï¼‰
5. **å·¥å…·éœ€æ±‚**ï¼šåˆ—å‡ºæ¯å€‹ä»»å‹™éœ€è¦çš„å·¥å…·ï¼ˆå¦‚ bash, read, write, grep ç­‰ï¼‰
6. **é—œéµè·¯å¾‘**ï¼šè­˜åˆ¥å½±éŸ¿ç¸½æ™‚é–“çš„é—œéµä»»å‹™åºåˆ—
7. **ä¸¦è¡Œæ©Ÿæœƒ**ï¼šæ‰¾å‡ºå¯ä»¥åŒæ™‚åŸ·è¡Œçš„ä»»å‹™çµ„

## è¼¸å‡ºæ ¼å¼
è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºè¨ˆç•«ï¼Œçµæ§‹å¦‚ä¸‹ï¼š

```json
{{
  "project_name": "å°ˆæ¡ˆåç¨±",
  "objective": "å°ˆæ¡ˆç›®æ¨™",
  "tasks": [
    {{
      "id": "task_1",
      "name": "ä»»å‹™åç¨±",
      "description": "è©³ç´°æè¿°",
      "task_type": "analysis|generation|transformation|validation",
      "priority": 1-4,
      "dependencies": ["task_id_1", "task_id_2"],
      "estimated_time": 600,
      "retry_count": 3,
      "tools": ["bash", "read", "write"],
      "output_format": "json",
      "metadata": {{}}
    }}
  ],
  "estimated_total_time": 7200,
  "critical_path": ["task_1", "task_3", "task_5"],
  "parallel_groups": [
    ["task_2", "task_4"],
    ["task_6", "task_7"]
  ]
}}
```

è«‹é–‹å§‹åˆ†æä¸¦ç”ŸæˆåŸ·è¡Œè¨ˆç•«ã€‚
"""

        # å‘¼å« Claude
        response = self.client.messages.create(
            model=self.model,
            max_tokens=4096,
            temperature=self.temperature,
            messages=[
                {"role": "user", "content": analysis_prompt}
            ]
        )

        # è§£æå›æ‡‰
        plan_json = self._extract_json(response.content[0].text)

        # è½‰æ›ç‚º ExecutionPlan ç‰©ä»¶
        execution_plan = self._parse_execution_plan(plan_json)

        # å„²å­˜å°è©±æ­·å²
        self.conversation_history.append({
            "role": "user",
            "content": analysis_prompt
        })
        self.conversation_history.append({
            "role": "assistant",
            "content": response.content[0].text
        })

        return execution_plan

    def adjust_plan(
        self,
        current_plan: ExecutionPlan,
        execution_results: List[Dict[str, Any]],
        issues: List[str]
    ) -> ExecutionPlan:
        """
        â€¹7â€º æ ¹æ“šåŸ·è¡Œçµæœå‹•æ…‹èª¿æ•´è¨ˆç•«

        é€™æ˜¯ Meta Agent çš„æ ¸å¿ƒèƒ½åŠ›ï¼šè‡ªé©æ‡‰æ±ºç­–
        """
        adjustment_prompt = f"""
## ç•¶å‰åŸ·è¡Œè¨ˆç•«
```json
{json.dumps(current_plan.to_dict(), indent=2, ensure_ascii=False)}
```

## å·²å®Œæˆä»»å‹™çš„åŸ·è¡Œçµæœ
```json
{json.dumps(execution_results, indent=2, ensure_ascii=False)}
```

## ç™¼ç¾çš„å•é¡Œ
{chr(10).join(f"- {issue}" for issue in issues)}

## ä½ çš„ä»»å‹™
è«‹è©•ä¼°ç•¶å‰æƒ…æ³ï¼Œä¸¦æ±ºå®šæ˜¯å¦éœ€è¦èª¿æ•´è¨ˆç•«ã€‚å¯èƒ½çš„èª¿æ•´åŒ…æ‹¬ï¼š

1. **æ·»åŠ æ–°ä»»å‹™**ï¼šç™¼ç¾éºæ¼çš„æ­¥é©Ÿ
2. **ä¿®æ”¹ä¾è³´**ï¼šæ ¹æ“šå¯¦éš›æƒ…æ³èª¿æ•´é †åº
3. **èª¿æ•´å„ªå…ˆç´š**ï¼šæ‡‰å°ç·Šæ€¥å•é¡Œ
4. **å¢åŠ é‡è©¦**ï¼šæé«˜å®¹éŒ¯æ€§
5. **é‡æ–°è¦åŠƒ**ï¼šå¦‚æœåŸè¨ˆç•«ä¸å¯è¡Œ

è«‹è¼¸å‡ºèª¿æ•´å¾Œçš„å®Œæ•´è¨ˆç•«ï¼ˆJSON æ ¼å¼ï¼Œçµæ§‹èˆ‡åŸè¨ˆç•«ç›¸åŒï¼‰ã€‚
"""

        response = self.client.messages.create(
            model=self.model,
            max_tokens=4096,
            temperature=self.temperature,
            messages=self.conversation_history + [
                {"role": "user", "content": adjustment_prompt}
            ]
        )

        adjusted_plan_json = self._extract_json(response.content[0].text)
        adjusted_plan = self._parse_execution_plan(adjusted_plan_json)

        # æ›´æ–°å°è©±æ­·å²
        self.conversation_history.append({
            "role": "user",
            "content": adjustment_prompt
        })
        self.conversation_history.append({
            "role": "assistant",
            "content": response.content[0].text
        })

        return adjusted_plan

    def _extract_json(self, text: str) -> Dict[str, Any]:
        """å¾æ–‡å­—ä¸­æå– JSON"""
        # å˜—è©¦æ‰¾åˆ° JSON ç¨‹å¼ç¢¼å¡Š
        import re
        json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # å˜—è©¦ç›´æ¥è§£æ
            json_str = text

        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±æ•—ï¼Œå˜—è©¦æ‰¾åˆ°ç¬¬ä¸€å€‹ { åˆ°æœ€å¾Œä¸€å€‹ }
            start = text.find('{')
            end = text.rfind('}')
            if start != -1 and end != -1:
                return json.loads(text[start:end+1])
            raise ValueError("ç„¡æ³•å¾å›æ‡‰ä¸­æå–æœ‰æ•ˆçš„ JSON")

    def _parse_execution_plan(self, plan_json: Dict[str, Any]) -> ExecutionPlan:
        """è§£æ JSON ç‚º ExecutionPlan ç‰©ä»¶"""
        tasks = []
        for task_data in plan_json.get("tasks", []):
            task = Task(
                id=task_data["id"],
                name=task_data["name"],
                description=task_data["description"],
                task_type=TaskType(task_data["task_type"]),
                priority=TaskPriority(task_data["priority"]),
                dependencies=task_data.get("dependencies", []),
                estimated_time=task_data.get("estimated_time", 300),
                retry_count=task_data.get("retry_count", 3),
                tools=task_data.get("tools", []),
                output_format=task_data.get("output_format", "json"),
                metadata=task_data.get("metadata", {})
            )
            tasks.append(task)

        return ExecutionPlan(
            project_name=plan_json["project_name"],
            objective=plan_json["objective"],
            tasks=tasks,
            estimated_total_time=plan_json.get("estimated_total_time", 0),
            critical_path=plan_json.get("critical_path", []),
            parallel_groups=plan_json.get("parallel_groups", []),
            metadata=plan_json.get("metadata", {})
        )
```

**é—œéµè¨»è§£èªªæ˜**ï¼š

- **â€¹1â€º** `dependencies`ï¼šä»»å‹™ä¾è³´åˆ—è¡¨ï¼Œç¢ºä¿åŸ·è¡Œé †åºæ­£ç¢º
- **â€¹2â€º** `critical_path`ï¼šé—œéµè·¯å¾‘ï¼Œå½±éŸ¿ç¸½åŸ·è¡Œæ™‚é–“çš„ä»»å‹™åºåˆ—
- **â€¹3â€º** `parallel_groups`ï¼šå¯ä¸¦è¡ŒåŸ·è¡Œçš„ä»»å‹™çµ„ï¼Œæé«˜æ•ˆç‡
- **â€¹4â€º** `MetaAgent` é¡åˆ¥ï¼šæ ¸å¿ƒè¦åŠƒå¼•æ“
- **â€¹5â€º** `temperature=0.3`ï¼šè¼ƒä½çš„æº«åº¦ç¢ºä¿è¨ˆç•«çš„ä¸€è‡´æ€§
- **â€¹6â€º** `analyze_project()`ï¼šåˆ†æå°ˆæ¡ˆä¸¦ç”Ÿæˆåˆå§‹è¨ˆç•«
- **â€¹7â€º** `adjust_plan()`ï¼šå‹•æ…‹èª¿æ•´è¨ˆç•«çš„èƒ½åŠ›

### 9.3.2 å¯¦éš›é‹è¡Œç¯„ä¾‹

```python
# ä½¿ç”¨ Meta Agent åˆ†æé‡å¯«å°ˆæ¡ˆ
meta_agent = MetaAgent(api_key="your-api-key")

project_description = """
å°‡ä¸€å€‹ 8 å¹´æ­·å²çš„ PHP å–®é«” ERP ç³»çµ±é‡å¯«ç‚º Python å¾®æœå‹™æ¶æ§‹ã€‚

åŸç³»çµ±ï¼š
- PHP 5.6 + MySQL
- ç´„ 30,000 è¡Œç¨‹å¼ç¢¼
- 4 å€‹æ ¸å¿ƒæ¨¡çµ„ï¼šå®¢æˆ¶ç®¡ç†ã€è¨‚å–®è™•ç†ã€åº«å­˜ç®¡ç†ã€å¸³å–®ç³»çµ±

ç›®æ¨™ç³»çµ±ï¼š
- Python 3.11 + FastAPI
- PostgreSQL + Redis
- å¾®æœå‹™æ¶æ§‹ï¼ˆæ¯å€‹æ¨¡çµ„ç¨ç«‹æœå‹™ï¼‰
- RESTful API è¨­è¨ˆ
- Docker å®¹å™¨åŒ–éƒ¨ç½²
"""

codebase_info = {
    "total_files": 12,
    "total_lines": 31450,
    "languages": {"php": 0.95, "javascript": 0.05},
    "modules": [
        {"name": "customer", "lines": 3500, "complexity": "medium"},
        {"name": "order", "lines": 4200, "complexity": "high"},
        {"name": "inventory", "lines": 2800, "complexity": "medium"},
        {"name": "billing", "lines": 3100, "complexity": "high"}
    ],
    "database": {
        "type": "mysql",
        "tables": 28,
        "relationships": "complex"
    }
}

# ç”ŸæˆåŸ·è¡Œè¨ˆç•«
plan = meta_agent.analyze_project(project_description, codebase_info)

print(f"å°ˆæ¡ˆï¼š{plan.project_name}")
print(f"ç›®æ¨™ï¼š{plan.objective}")
print(f"ç¸½ä»»å‹™æ•¸ï¼š{len(plan.tasks)}")
print(f"é ä¼°æ™‚é–“ï¼š{plan.estimated_total_time // 60} åˆ†é˜")
print(f"é—œéµè·¯å¾‘ï¼š{' â†’ '.join(plan.critical_path)}")
```

**å¯¦éš›è¼¸å‡ºç¯„ä¾‹**ï¼š

```
å°ˆæ¡ˆï¼šPHP ERP ç³»çµ±é‡å¯«ç‚º Python å¾®æœå‹™
ç›®æ¨™ï¼šå°‡å–®é«”æ‡‰ç”¨æ‹†åˆ†ç‚º 4 å€‹å¾®æœå‹™ï¼Œæä¾› RESTful API
ç¸½ä»»å‹™æ•¸ï¼š8
é ä¼°æ™‚é–“ï¼š125 åˆ†é˜
é—œéµè·¯å¾‘ï¼štask_1 â†’ task_2 â†’ task_5 â†’ task_7 â†’ task_8

ä»»å‹™åˆ—è¡¨ï¼š
[1] åˆ†æç¾æœ‰æ¶æ§‹èˆ‡è³‡æ–™æ¨¡å‹ (15åˆ†é˜) - analysis
[2] è¨­è¨ˆå¾®æœå‹™æ¶æ§‹èˆ‡ API è¦æ ¼ (20åˆ†é˜) - analysis
[3] è¨­è¨ˆè³‡æ–™åº« Schema (10åˆ†é˜) - generation [å¯ä¸¦è¡Œ]
[4] ç”Ÿæˆå…±ç”¨æ¨¡çµ„ï¼ˆèªè­‰ã€æ—¥èªŒï¼‰ (10åˆ†é˜) - generation [å¯ä¸¦è¡Œ]
[5] å¯¦ä½œå®¢æˆ¶ç®¡ç†æœå‹™ (20åˆ†é˜) - generation
[6] å¯¦ä½œè¨‚å–®è™•ç†æœå‹™ (25åˆ†é˜) - generation [å¯ä¸¦è¡Œ]
[7] å¯¦ä½œåº«å­˜ç®¡ç†æœå‹™ (15åˆ†é˜) - generation [å¯ä¸¦è¡Œ]
[8] å¯¦ä½œå¸³å–®ç³»çµ±æœå‹™ (20åˆ†é˜) - generation [å¯ä¸¦è¡Œ]
[9] ç”Ÿæˆæ•´åˆæ¸¬è©¦ (10åˆ†é˜) - validation
```

---

## 9.4 å»ºæ§‹ä»»å‹™å”èª¿å™¨ï¼šå”èª¿å±¤

### 9.4.1 ä¾è³´ç®¡ç†èˆ‡èª¿åº¦

å”èª¿å±¤è² è²¬å°‡ Meta Agent çš„è¨ˆç•«ã€ŒåŸ·è¡Œã€èµ·ä¾†ã€‚

```python
# task_coordinator.py
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from enum import Enum
import asyncio
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TaskStatus(Enum):
    """ä»»å‹™ç‹€æ…‹"""
    PENDING = "pending"      # ç­‰å¾…åŸ·è¡Œ
    READY = "ready"          # ä¾è³´å·²æ»¿è¶³ï¼Œå¯åŸ·è¡Œ
    RUNNING = "running"      # åŸ·è¡Œä¸­
    COMPLETED = "completed"  # å·²å®Œæˆ
    FAILED = "failed"        # å¤±æ•—
    RETRYING = "retrying"    # é‡è©¦ä¸­

@dataclass
class TaskExecution:
    """ä»»å‹™åŸ·è¡Œç‹€æ…‹"""
    task: Task
    status: TaskStatus = TaskStatus.PENDING
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    retry_attempts: int = 0
    subagent_id: Optional[str] = None

    @property
    def duration(self) -> Optional[float]:
        """åŸ·è¡Œæ™‚é•·ï¼ˆç§’ï¼‰"""
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return None

    @property
    def is_terminal(self) -> bool:
        """æ˜¯å¦ç‚ºçµ‚æ…‹"""
        return self.status in [TaskStatus.COMPLETED, TaskStatus.FAILED]

class TaskCoordinator:
    """
    â€¹1â€º ä»»å‹™å”èª¿å™¨ - è² è²¬ä»»å‹™èª¿åº¦èˆ‡åŸ·è¡Œ

    æ ¸å¿ƒè·è²¬ï¼š
    1. ç®¡ç†ä»»å‹™ä¾è³´é—œä¿‚
    2. èª¿åº¦ä»»å‹™åŸ·è¡Œï¼ˆä¸²è¡Œ/ä¸¦è¡Œï¼‰
    3. ç›£æ§ä»»å‹™ç‹€æ…‹
    4. è™•ç†éŒ¯èª¤èˆ‡é‡è©¦
    5. æ”¶é›†åŸ·è¡Œçµæœ
    """

    def __init__(
        self,
        plan: ExecutionPlan,
        max_parallel: int = 3  # â€¹2â€º
    ):
        self.plan = plan
        self.max_parallel = max_parallel

        # åˆå§‹åŒ–ä»»å‹™åŸ·è¡Œç‹€æ…‹
        self.executions: Dict[str, TaskExecution] = {}
        for task in plan.tasks:
            self.executions[task.id] = TaskExecution(task=task)

        # åŸ·è¡Œçµ±è¨ˆ
        self.stats = {
            "total_tasks": len(plan.tasks),
            "completed": 0,
            "failed": 0,
            "total_time": 0,
            "start_time": None,
            "end_time": None
        }

    async def execute_plan(self) -> Dict[str, Any]:
        """
        â€¹3â€º åŸ·è¡Œæ•´å€‹è¨ˆç•«

        Returns:
            åŸ·è¡Œçµæœæ‘˜è¦
        """
        logger.info(f"é–‹å§‹åŸ·è¡Œè¨ˆç•«ï¼š{self.plan.project_name}")
        logger.info(f"ç¸½ä»»å‹™æ•¸ï¼š{self.stats['total_tasks']}")

        self.stats["start_time"] = datetime.now()

        try:
            # ä¸»åŸ·è¡Œè¿´åœˆ
            while not self._all_tasks_terminal():
                # ç²å–å¯åŸ·è¡Œçš„ä»»å‹™
                ready_tasks = self._get_ready_tasks()

                if not ready_tasks:
                    # æ²’æœ‰å¯åŸ·è¡Œä»»å‹™ï¼Œæª¢æŸ¥æ˜¯å¦æœ‰æ­»é–
                    if self._has_deadlock():
                        raise RuntimeError("åµæ¸¬åˆ°ä»»å‹™æ­»é–ï¼šå­˜åœ¨å¾ªç’°ä¾è³´")
                    # ç­‰å¾…é‹è¡Œä¸­çš„ä»»å‹™å®Œæˆ
                    await asyncio.sleep(1)
                    continue

                # ä¸¦è¡ŒåŸ·è¡Œä»»å‹™ï¼ˆå— max_parallel é™åˆ¶ï¼‰
                tasks_to_run = ready_tasks[:self.max_parallel]

                logger.info(f"æº–å‚™åŸ·è¡Œ {len(tasks_to_run)} å€‹ä»»å‹™ï¼š{[t.name for t in tasks_to_run]}")

                # å‰µå»ºä¸¦è¡Œä»»å‹™
                execution_tasks = [
                    self._execute_task(task)
                    for task in tasks_to_run
                ]

                # ç­‰å¾…é€™æ‰¹ä»»å‹™å®Œæˆ
                await asyncio.gather(*execution_tasks, return_exceptions=True)

            # è¨ˆç®—ç¸½æ™‚é–“
            self.stats["end_time"] = datetime.now()
            self.stats["total_time"] = (
                self.stats["end_time"] - self.stats["start_time"]
            ).total_seconds()

            # ç”ŸæˆåŸ·è¡Œå ±å‘Š
            return self._generate_report()

        except Exception as e:
            logger.error(f"åŸ·è¡Œè¨ˆç•«æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            raise

    def _get_ready_tasks(self) -> List[Task]:
        """
        â€¹4â€º ç²å–æ‰€æœ‰ä¾è³´å·²æ»¿è¶³ä¸”å°šæœªåŸ·è¡Œçš„ä»»å‹™
        """
        ready_tasks = []

        for task_id, execution in self.executions.items():
            # è·³éå·²å®Œæˆæˆ–é‹è¡Œä¸­çš„ä»»å‹™
            if execution.status in [TaskStatus.RUNNING, TaskStatus.COMPLETED]:
                continue

            # æª¢æŸ¥ä¾è³´æ˜¯å¦éƒ½å·²å®Œæˆ
            dependencies_met = all(
                self.executions[dep_id].status == TaskStatus.COMPLETED
                for dep_id in execution.task.dependencies
            )

            if dependencies_met:
                execution.status = TaskStatus.READY
                ready_tasks.append(execution.task)

        # æŒ‰å„ªå…ˆç´šæ’åº
        ready_tasks.sort(key=lambda t: t.priority.value)

        return ready_tasks

    async def _execute_task(self, task: Task) -> None:
        """
        â€¹5â€º åŸ·è¡Œå–®å€‹ä»»å‹™
        """
        execution = self.executions[task.id]
        execution.status = TaskStatus.RUNNING
        execution.start_time = datetime.now()

        logger.info(f"[{task.id}] é–‹å§‹åŸ·è¡Œï¼š{task.name}")

        try:
            # å‰µå»º Subagent åŸ·è¡Œä»»å‹™
            from subagent_executor import SubagentExecutor
            executor = SubagentExecutor()

            result = await executor.execute(task)

            # è¨˜éŒ„çµæœ
            execution.result = result
            execution.status = TaskStatus.COMPLETED
            execution.end_time = datetime.now()

            self.stats["completed"] += 1

            logger.info(
                f"[{task.id}] å®Œæˆ "
                f"({execution.duration:.1f}ç§’)"
            )

        except Exception as e:
            logger.error(f"[{task.id}] åŸ·è¡Œå¤±æ•—ï¼š{e}")

            # é‡è©¦é‚è¼¯
            execution.retry_attempts += 1

            if execution.retry_attempts < task.retry_count:
                execution.status = TaskStatus.RETRYING
                logger.info(f"[{task.id}] æº–å‚™é‡è©¦ ({execution.retry_attempts}/{task.retry_count})")

                # ç­‰å¾…å¾Œé‡è©¦
                await asyncio.sleep(2 ** execution.retry_attempts)  # æŒ‡æ•¸é€€é¿
                await self._execute_task(task)
            else:
                # é‡è©¦æ¬¡æ•¸ç”¨ç›¡
                execution.status = TaskStatus.FAILED
                execution.error = str(e)
                execution.end_time = datetime.now()
                self.stats["failed"] += 1

    def _all_tasks_terminal(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ‰€æœ‰ä»»å‹™éƒ½å·²é”åˆ°çµ‚æ…‹"""
        return all(
            execution.is_terminal
            for execution in self.executions.values()
        )

    def _has_deadlock(self) -> bool:
        """
        â€¹6â€º åµæ¸¬å¾ªç’°ä¾è³´ï¼ˆæ­»é–ï¼‰

        ä½¿ç”¨æ‹“æ’²æ’åºç®—æ³•æª¢æ¸¬
        """
        # è¨ˆç®—å…¥åº¦
        in_degree = {task_id: 0 for task_id in self.executions}
        for execution in self.executions.values():
            for dep_id in execution.task.dependencies:
                in_degree[dep_id] += 1

        # æ‰¾å‡ºæ‰€æœ‰å…¥åº¦ç‚º 0 çš„ç¯€é»
        queue = [
            task_id
            for task_id, degree in in_degree.items()
            if degree == 0 and not self.executions[task_id].is_terminal
        ]

        processed = 0
        while queue:
            current = queue.pop(0)
            processed += 1

            for task_id, execution in self.executions.items():
                if current in execution.task.dependencies:
                    in_degree[task_id] -= 1
                    if in_degree[task_id] == 0 and not execution.is_terminal:
                        queue.append(task_id)

        # å¦‚æœè™•ç†çš„ç¯€é»æ•¸å°‘æ–¼ç¸½ç¯€é»æ•¸ï¼Œå­˜åœ¨å¾ªç’°ä¾è³´
        pending_count = sum(
            1 for e in self.executions.values()
            if not e.is_terminal
        )
        return processed < pending_count

    def _generate_report(self) -> Dict[str, Any]:
        """
        â€¹7â€º ç”ŸæˆåŸ·è¡Œå ±å‘Š
        """
        completed_tasks = [
            {
                "id": exec.task.id,
                "name": exec.task.name,
                "duration": exec.duration,
                "result": exec.result
            }
            for exec in self.executions.values()
            if exec.status == TaskStatus.COMPLETED
        ]

        failed_tasks = [
            {
                "id": exec.task.id,
                "name": exec.task.name,
                "error": exec.error,
                "retry_attempts": exec.retry_attempts
            }
            for exec in self.executions.values()
            if exec.status == TaskStatus.FAILED
        ]

        return {
            "summary": {
                "total_tasks": self.stats["total_tasks"],
                "completed": self.stats["completed"],
                "failed": self.stats["failed"],
                "success_rate": self.stats["completed"] / self.stats["total_tasks"],
                "total_time": self.stats["total_time"],
                "estimated_time": self.plan.estimated_total_time,
                "time_efficiency": self.plan.estimated_total_time / self.stats["total_time"]
            },
            "completed_tasks": completed_tasks,
            "failed_tasks": failed_tasks,
            "critical_path_time": self._calculate_critical_path_time()
        }

    def _calculate_critical_path_time(self) -> float:
        """è¨ˆç®—é—œéµè·¯å¾‘å¯¦éš›è€—æ™‚"""
        total = 0
        for task_id in self.plan.critical_path:
            execution = self.executions.get(task_id)
            if execution and execution.duration:
                total += execution.duration
        return total
```

**é—œéµè¨»è§£èªªæ˜**ï¼š

- **â€¹1â€º** `TaskCoordinator`ï¼šæ ¸å¿ƒå”èª¿å¼•æ“
- **â€¹2â€º** `max_parallel`ï¼šæœ€å¤§ä¸¦è¡Œä»»å‹™æ•¸ï¼Œæ§åˆ¶è³‡æºä½¿ç”¨
- **â€¹3â€º** `execute_plan()`ï¼šä¸»åŸ·è¡Œè¿´åœˆ
- **â€¹4â€º** `_get_ready_tasks()`ï¼šä¾è³´è§£æç®—æ³•
- **â€¹5â€º** `_execute_task()`ï¼šä»»å‹™åŸ·è¡Œèˆ‡éŒ¯èª¤è™•ç†
- **â€¹6â€º** `_has_deadlock()`ï¼šæ­»é–åµæ¸¬ï¼ˆæ‹“æ’²æ’åºï¼‰
- **â€¹7â€º** `_generate_report()`ï¼šç”Ÿæˆè©³ç´°å ±å‘Š

---

## 9.5 å»ºæ§‹ Subagent åŸ·è¡Œå™¨ï¼šåŸ·è¡Œå±¤

### 9.5.1 é€šç”¨åŸ·è¡Œå¼•æ“

åŸ·è¡Œå±¤çš„ Subagents è² è²¬ã€ŒçœŸæ­£å‹•æ‰‹åšã€ã€‚

```python
# subagent_executor.py
from typing import Dict, Any, List
import anthropic
from agent_sdk import Agent, RunResult
import logging

logger = logging.getLogger(__name__)

class SubagentExecutor:
    """
    â€¹1â€º Subagent åŸ·è¡Œå™¨ - å‰µå»ºä¸¦ç®¡ç†å°ˆé–€åŒ–çš„ Subagents

    è·è²¬ï¼š
    1. æ ¹æ“šä»»å‹™é¡å‹å‰µå»ºåˆé©çš„ Subagent
    2. é…ç½® Subagent çš„å·¥å…·èˆ‡æ¬Šé™
    3. åŸ·è¡Œä»»å‹™ä¸¦æ”¶é›†çµæœ
    4. è™•ç†åŸ·è¡Œéç¨‹ä¸­çš„éŒ¯èª¤
    """

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")

        # Subagent æ¨¡æ¿åº«
        self.agent_templates = {
            TaskType.ANALYSIS: self._create_analyzer_agent,
            TaskType.GENERATION: self._create_generator_agent,
            TaskType.TRANSFORMATION: self._create_transformer_agent,
            TaskType.VALIDATION: self._create_validator_agent
        }

    async def execute(self, task: Task) -> Dict[str, Any]:
        """
        â€¹2â€º åŸ·è¡Œä»»å‹™

        Args:
            task: è¦åŸ·è¡Œçš„ä»»å‹™

        Returns:
            åŸ·è¡Œçµæœ
        """
        logger.info(f"å‰µå»º Subagent åŸ·è¡Œä»»å‹™ï¼š{task.name}")

        # æ ¹æ“šä»»å‹™é¡å‹å‰µå»ºå°æ‡‰çš„ Subagent
        agent_factory = self.agent_templates.get(task.task_type)
        if not agent_factory:
            raise ValueError(f"ä¸æ”¯æ´çš„ä»»å‹™é¡å‹ï¼š{task.task_type}")

        agent = agent_factory(task)

        # æ§‹å»ºä»»å‹™ Prompt
        task_prompt = self._build_task_prompt(task)

        # åŸ·è¡Œ
        try:
            result = agent.run(task_prompt)

            # è§£æçµæœ
            parsed_result = self._parse_result(result, task.output_format)

            return {
                "status": "success",
                "output": parsed_result,
                "agent_id": agent.id,
                "metrics": {
                    "input_tokens": result.usage.input_tokens,
                    "output_tokens": result.usage.output_tokens,
                    "total_cost": result.usage.total_cost
                }
            }

        except Exception as e:
            logger.error(f"Subagent åŸ·è¡Œå¤±æ•—ï¼š{e}")
            return {
                "status": "error",
                "error": str(e),
                "agent_id": agent.id if 'agent' in locals() else None
            }

    def _create_analyzer_agent(self, task: Task) -> Agent:
        """
        â€¹3â€º å‰µå»ºåˆ†æå‹ Subagent

        å°ˆé•·ï¼šè®€å–ç¨‹å¼ç¢¼ã€ç†è§£çµæ§‹ã€æå–è³‡è¨Š
        """
        return Agent(
            api_key=self.api_key,
            model="claude-sonnet-4-20250514",  # åˆ†æç”¨è¼ƒè¼•é‡æ¨¡å‹
            context=f"""
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç¨‹å¼ç¢¼åˆ†æå¸«ï¼Œè² è²¬ä»¥ä¸‹ä»»å‹™ï¼š

{task.description}

## ä½ çš„å·¥ä½œæ–¹å¼
1. ä½¿ç”¨ `read` å·¥å…·è®€å–å¿…è¦çš„æª”æ¡ˆ
2. ä½¿ç”¨ `grep` å·¥å…·æœå°‹ç‰¹å®šæ¨¡å¼
3. åˆ†æç¨‹å¼ç¢¼çµæ§‹ã€ä¾è³´é—œä¿‚ã€è¤‡é›œåº¦
4. ä»¥ {task.output_format} æ ¼å¼è¼¸å‡ºåˆ†æçµæœ

## é—œéµè¦æ±‚
- å…¨é¢ï¼šä¸è¦éºæ¼é‡è¦è³‡è¨Š
- æº–ç¢ºï¼šç¢ºä¿åˆ†æçµæœæ­£ç¢º
- çµæ§‹åŒ–ï¼šæŒ‰ç…§æŒ‡å®šæ ¼å¼è¼¸å‡º
""",
            tools=["read", "grep", "glob"],  # â€¹4â€º
            max_turns=10
        )

    def _create_generator_agent(self, task: Task) -> Agent:
        """
        â€¹5â€º å‰µå»ºç”Ÿæˆå‹ Subagent

        å°ˆé•·ï¼šå¯«ç¨‹å¼ç¢¼ã€å‰µå»ºæª”æ¡ˆã€ç”Ÿæˆæ–‡ä»¶
        """
        return Agent(
            api_key=self.api_key,
            model="claude-opus-4-20250514",  # ç”Ÿæˆç”¨æ›´å¼·æ¨¡å‹
            context=f"""
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è»Ÿé«”å·¥ç¨‹å¸«ï¼Œè² è²¬ä»¥ä¸‹ä»»å‹™ï¼š

{task.description}

## ä½ çš„å·¥ä½œæ–¹å¼
1. ä½¿ç”¨ `read` å·¥å…·äº†è§£ç¾æœ‰ç¨‹å¼ç¢¼
2. ä½¿ç”¨ `write` å·¥å…·å‰µå»ºæ–°æª”æ¡ˆ
3. ä½¿ç”¨ `edit` å·¥å…·ä¿®æ”¹æª”æ¡ˆ
4. éµå¾ªæœ€ä½³å¯¦è¸èˆ‡ç·¨ç¢¼è¦ç¯„

## ç¨‹å¼ç¢¼å“è³ªè¦æ±‚
- å¯è®€æ€§ï¼šæ¸…æ™°çš„å‘½åã€é©ç•¶çš„è¨»è§£
- å¯ç¶­è­·æ€§ï¼šæ¨¡çµ„åŒ–è¨­è¨ˆã€ä½è€¦åˆ
- å¥å£¯æ€§ï¼šå®Œæ•´çš„éŒ¯èª¤è™•ç†
- å¯æ¸¬è©¦æ€§ï¼šæ˜“æ–¼å–®å…ƒæ¸¬è©¦

## è¼¸å‡ºæ ¼å¼
{task.output_format}
""",
            tools=["read", "write", "edit", "bash"],  # â€¹6â€º
            max_turns=20
        )

    def _create_transformer_agent(self, task: Task) -> Agent:
        """å‰µå»ºè½‰æ›å‹ Subagent"""
        return Agent(
            api_key=self.api_key,
            model="claude-sonnet-4-20250514",
            context=f"""
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç¨‹å¼ç¢¼è½‰æ›å°ˆå®¶ï¼Œè² è²¬ï¼š

{task.description}

å°ˆæ³¨æ–¼ï¼š
1. ä¿æŒåŸæœ‰é‚è¼¯ä¸è®Š
2. æå‡ç¨‹å¼ç¢¼å“è³ª
3. éµå¾ªç›®æ¨™èªè¨€çš„æ…£ä¾‹
""",
            tools=["read", "write", "edit"],
            max_turns=15
        )

    def _create_validator_agent(self, task: Task) -> Agent:
        """å‰µå»ºé©—è­‰å‹ Subagent"""
        return Agent(
            api_key=self.api_key,
            model="claude-sonnet-4-20250514",
            context=f"""
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ QA å·¥ç¨‹å¸«ï¼Œè² è²¬ï¼š

{task.description}

é©—è­‰é‡é»ï¼š
1. åŠŸèƒ½æ­£ç¢ºæ€§
2. é‚Šç•Œæ¢ä»¶è™•ç†
3. éŒ¯èª¤è™•ç†å®Œæ•´æ€§
4. æ•ˆèƒ½è¡¨ç¾
""",
            tools=["read", "bash"],
            max_turns=10
        )

    def _build_task_prompt(self, task: Task) -> str:
        """æ§‹å»ºä»»å‹™ Prompt"""
        prompt = f"""
# ä»»å‹™ï¼š{task.name}

## æè¿°
{task.description}

## å…ƒæ•¸æ“š
- ä»»å‹™ IDï¼š{task.id}
- å„ªå…ˆç´šï¼š{task.priority.name}
- é ä¼°æ™‚é–“ï¼š{task.estimated_time} ç§’

## é¡å¤–è³‡è¨Š
"""

        # æ·»åŠ å…ƒæ•¸æ“š
        for key, value in task.metadata.items():
            prompt += f"- {key}ï¼š{value}\n"

        prompt += f"\nè«‹é–‹å§‹åŸ·è¡Œä»»å‹™ï¼Œä¸¦ä»¥ {task.output_format} æ ¼å¼è¼¸å‡ºçµæœã€‚"

        return prompt

    def _parse_result(self, result: RunResult, output_format: str) -> Any:
        """è§£æ Subagent çš„è¼¸å‡º"""
        if output_format == "json":
            import json
            # å¾æœ€å¾Œä¸€æ¢è¨Šæ¯ä¸­æå– JSON
            last_message = result.messages[-1].content
            if isinstance(last_message, list):
                last_message = last_message[0].text if last_message else ""

            # å˜—è©¦æå– JSON
            import re
            json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', last_message, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))

            # å˜—è©¦ç›´æ¥è§£æ
            try:
                return json.loads(last_message)
            except:
                return {"raw_output": last_message}

        # å…¶ä»–æ ¼å¼ç›´æ¥è¿”å›æ–‡å­—
        return result.messages[-1].content
```

**é—œéµè¨»è§£èªªæ˜**ï¼š

- **â€¹1â€º** `SubagentExecutor`ï¼šçµ±ä¸€çš„åŸ·è¡Œä»‹é¢
- **â€¹2â€º** `execute()`ï¼šä»»å‹™åŸ·è¡Œå…¥å£
- **â€¹3â€º** `_create_analyzer_agent()`ï¼šåˆ†æå‹ Agentï¼ˆè®€å–ç‚ºä¸»ï¼‰
- **â€¹4â€º** åˆ†æ Agent çš„å·¥å…·ï¼š`read`, `grep`, `glob`ï¼ˆå”¯è®€ï¼‰
- **â€¹5â€º** `_create_generator_agent()`ï¼šç”Ÿæˆå‹ Agentï¼ˆå¯«å…¥ç‚ºä¸»ï¼‰
- **â€¹6â€º** ç”Ÿæˆ Agent çš„å·¥å…·ï¼š`read`, `write`, `edit`, `bash`ï¼ˆå®Œæ•´æ¬Šé™ï¼‰

---

## 9.6 å®Œæ•´ç³»çµ±æ•´åˆ

### 9.6.1 ä¸»æ§ç¨‹å¼

å°‡ä¸‰å±¤æ¶æ§‹æ•´åˆåœ¨ä¸€èµ·ã€‚

```python
# main.py
import asyncio
from meta_agent import MetaAgent, ExecutionPlan
from task_coordinator import TaskCoordinator
import json
import logging
from datetime import datetime

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ApplicationRewriteSystem:
    """
    â€¹1â€º å®Œæ•´æ‡‰ç”¨ç¨‹å¼é‡å¯«ç³»çµ±

    æ•´åˆä¸‰å±¤æ¶æ§‹ï¼š
    - Meta Agentï¼ˆè¦åŠƒå±¤ï¼‰
    - Task Coordinatorï¼ˆå”èª¿å±¤ï¼‰
    - Subagent Executorï¼ˆåŸ·è¡Œå±¤ï¼‰
    """

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.meta_agent = MetaAgent(api_key=api_key)
        self.execution_history = []

    async def rewrite_application(
        self,
        project_description: str,
        codebase_path: str,
        output_path: str
    ) -> Dict[str, Any]:
        """
        â€¹2â€º åŸ·è¡Œå®Œæ•´çš„æ‡‰ç”¨ç¨‹å¼é‡å¯«æµç¨‹

        Args:
            project_description: å°ˆæ¡ˆæè¿°
            codebase_path: åŸå§‹ç¨‹å¼ç¢¼è·¯å¾‘
            output_path: è¼¸å‡ºè·¯å¾‘

        Returns:
            å®Œæ•´çš„åŸ·è¡Œå ±å‘Š
        """
        logger.info("=" * 80)
        logger.info("é–‹å§‹æ‡‰ç”¨ç¨‹å¼é‡å¯«å°ˆæ¡ˆ")
        logger.info("=" * 80)

        start_time = datetime.now()

        # éšæ®µ 1ï¼šæƒæç¨‹å¼ç¢¼åº«
        logger.info("\n[éšæ®µ 1/4] æƒæç¨‹å¼ç¢¼åº«...")
        codebase_info = self._scan_codebase(codebase_path)
        logger.info(f"ç™¼ç¾ {codebase_info['total_files']} å€‹æª”æ¡ˆï¼Œ"
                   f"{codebase_info['total_lines']} è¡Œç¨‹å¼ç¢¼")

        # éšæ®µ 2ï¼šç”ŸæˆåŸ·è¡Œè¨ˆç•«
        logger.info("\n[éšæ®µ 2/4] ç”ŸæˆåŸ·è¡Œè¨ˆç•«...")
        plan = self.meta_agent.analyze_project(
            project_description,
            codebase_info
        )

        logger.info(f"è¨ˆç•«ç”Ÿæˆå®Œæˆï¼š")
        logger.info(f"  - ç¸½ä»»å‹™æ•¸ï¼š{len(plan.tasks)}")
        logger.info(f"  - é ä¼°æ™‚é–“ï¼š{plan.estimated_total_time // 60} åˆ†é˜")
        logger.info(f"  - é—œéµè·¯å¾‘ï¼š{len(plan.critical_path)} å€‹ä»»å‹™")
        logger.info(f"  - å¯ä¸¦è¡Œçµ„ï¼š{len(plan.parallel_groups)} çµ„")

        # å„²å­˜è¨ˆç•«
        self._save_plan(plan, output_path)

        # éšæ®µ 3ï¼šåŸ·è¡Œè¨ˆç•«
        logger.info("\n[éšæ®µ 3/4] åŸ·è¡Œé‡å¯«ä»»å‹™...")
        coordinator = TaskCoordinator(plan=plan, max_parallel=3)

        execution_result = await coordinator.execute_plan()

        # éšæ®µ 4ï¼šç”Ÿæˆå ±å‘Š
        logger.info("\n[éšæ®µ 4/4] ç”Ÿæˆæœ€çµ‚å ±å‘Š...")

        end_time = datetime.now()
        total_duration = (end_time - start_time).total_seconds()

        final_report = {
            "project": {
                "name": plan.project_name,
                "objective": plan.objective,
                "codebase_path": codebase_path,
                "output_path": output_path
            },
            "execution": execution_result,
            "timing": {
                "start_time": start_time.isoformat(),
                "end_time": end_time.isoformat(),
                "total_duration": total_duration,
                "estimated_duration": plan.estimated_total_time,
                "efficiency": plan.estimated_total_time / total_duration if total_duration > 0 else 0
            },
            "quality_metrics": self._calculate_quality_metrics(execution_result)
        }

        # å„²å­˜å ±å‘Š
        self._save_report(final_report, output_path)

        # åˆ—å°æ‘˜è¦
        self._print_summary(final_report)

        return final_report

    def _scan_codebase(self, path: str) -> Dict[str, Any]:
        """æƒæç¨‹å¼ç¢¼åº«"""
        import os
        from pathlib import Path

        total_files = 0
        total_lines = 0
        file_types = {}

        for root, dirs, files in os.walk(path):
            # è·³ééš±è—ç›®éŒ„
            dirs[:] = [d for d in dirs if not d.startswith('.')]

            for file in files:
                if file.startswith('.'):
                    continue

                file_path = Path(root) / file
                suffix = file_path.suffix

                total_files += 1
                file_types[suffix] = file_types.get(suffix, 0) + 1

                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        lines = len(f.readlines())
                        total_lines += lines
                except:
                    pass

        return {
            "total_files": total_files,
            "total_lines": total_lines,
            "file_types": file_types,
            "path": path
        }

    def _save_plan(self, plan: ExecutionPlan, output_path: str):
        """å„²å­˜åŸ·è¡Œè¨ˆç•«"""
        import os
        os.makedirs(output_path, exist_ok=True)

        plan_file = os.path.join(output_path, "execution_plan.json")
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(plan.to_dict(), f, indent=2, ensure_ascii=False)

        logger.info(f"åŸ·è¡Œè¨ˆç•«å·²å„²å­˜ï¼š{plan_file}")

    def _save_report(self, report: Dict[str, Any], output_path: str):
        """å„²å­˜æœ€çµ‚å ±å‘Š"""
        import os
        report_file = os.path.join(output_path, "final_report.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        logger.info(f"æœ€çµ‚å ±å‘Šå·²å„²å­˜ï¼š{report_file}")

    def _calculate_quality_metrics(self, execution_result: Dict[str, Any]) -> Dict[str, Any]:
        """è¨ˆç®—å“è³ªæŒ‡æ¨™"""
        summary = execution_result["summary"]

        return {
            "success_rate": summary["success_rate"],
            "time_efficiency": summary.get("time_efficiency", 0),
            "tasks_completed": summary["completed"],
            "tasks_failed": summary["failed"],
            "total_cost_usd": sum(
                task.get("result", {}).get("metrics", {}).get("total_cost", 0)
                for task in execution_result.get("completed_tasks", [])
            )
        }

    def _print_summary(self, report: Dict[str, Any]):
        """åˆ—å°åŸ·è¡Œæ‘˜è¦"""
        logger.info("\n" + "=" * 80)
        logger.info("åŸ·è¡Œæ‘˜è¦")
        logger.info("=" * 80)

        project = report["project"]
        execution = report["execution"]["summary"]
        timing = report["timing"]
        quality = report["quality_metrics"]

        logger.info(f"\nå°ˆæ¡ˆï¼š{project['name']}")
        logger.info(f"ç›®æ¨™ï¼š{project['objective']}")

        logger.info(f"\nåŸ·è¡Œçµæœï¼š")
        logger.info(f"  âœ… å®Œæˆä»»å‹™ï¼š{execution['completed']}/{execution['total_tasks']}")
        logger.info(f"  âŒ å¤±æ•—ä»»å‹™ï¼š{execution['failed']}")
        logger.info(f"  ğŸ“Š æˆåŠŸç‡ï¼š{execution['success_rate']:.1%}")

        logger.info(f"\næ™‚é–“çµ±è¨ˆï¼š")
        logger.info(f"  â±ï¸  å¯¦éš›è€—æ™‚ï¼š{timing['total_duration'] / 60:.1f} åˆ†é˜")
        logger.info(f"  ğŸ“… é ä¼°è€—æ™‚ï¼š{timing['estimated_duration'] / 60:.1f} åˆ†é˜")
        logger.info(f"  âš¡ æ•ˆç‡æ¯”ï¼š{timing['efficiency']:.2f}x")

        logger.info(f"\nå“è³ªæŒ‡æ¨™ï¼š")
        logger.info(f"  ğŸ’° ç¸½æˆæœ¬ï¼š${quality['total_cost_usd']:.2f}")
        logger.info(f"  ğŸ¯ æ™‚é–“æ•ˆç‡ï¼š{quality['time_efficiency']:.2f}x")

        logger.info("\n" + "=" * 80)

# ä¸»ç¨‹å¼å…¥å£
async def main():
    """ä¸»ç¨‹å¼"""
    import os
    from dotenv import load_dotenv

    load_dotenv()
    api_key = os.getenv("ANTHROPIC_API_KEY")

    # å‰µå»ºç³»çµ±
    system = ApplicationRewriteSystem(api_key=api_key)

    # åŸ·è¡Œé‡å¯«
    project_description = """
å°‡ä¸€å€‹ 8 å¹´æ­·å²çš„ PHP å–®é«” ERP ç³»çµ±é‡å¯«ç‚º Python å¾®æœå‹™æ¶æ§‹ã€‚

åŸç³»çµ±ï¼š
- PHP 5.6 + MySQL
- ç´„ 30,000 è¡Œç¨‹å¼ç¢¼
- 4 å€‹æ ¸å¿ƒæ¨¡çµ„ï¼šå®¢æˆ¶ç®¡ç†ã€è¨‚å–®è™•ç†ã€åº«å­˜ç®¡ç†ã€å¸³å–®ç³»çµ±

ç›®æ¨™ç³»çµ±ï¼š
- Python 3.11 + FastAPI
- PostgreSQL + Redis
- å¾®æœå‹™æ¶æ§‹ï¼ˆæ¯å€‹æ¨¡çµ„ç¨ç«‹æœå‹™ï¼‰
- RESTful API è¨­è¨ˆ
- Docker å®¹å™¨åŒ–éƒ¨ç½²
- å®Œæ•´çš„å–®å…ƒæ¸¬è©¦èˆ‡æ•´åˆæ¸¬è©¦
"""

    report = await system.rewrite_application(
        project_description=project_description,
        codebase_path="./legacy_erp",
        output_path="./output/rewritten_system"
    )

    print("\nâœ… é‡å¯«å®Œæˆï¼")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„ï¼š./output/rewritten_system")
    print(f"ğŸ“Š è©³ç´°å ±å‘Šï¼š./output/rewritten_system/final_report.json")

if __name__ == "__main__":
    asyncio.run(main())
```

**é—œéµè¨»è§£èªªæ˜**ï¼š

- **â€¹1â€º** `ApplicationRewriteSystem`ï¼šæ•´åˆç³»çµ±
- **â€¹2â€º** `rewrite_application()`ï¼šå®Œæ•´å››éšæ®µæµç¨‹

---

## 9.7 å¯¦éš›åŸ·è¡Œç¯„ä¾‹èˆ‡æ•ˆç›Š

### 9.7.1 å®Œæ•´åŸ·è¡Œæµç¨‹

```bash
# æº–å‚™ç’°å¢ƒ
cd /path/to/project
python -m venv venv
source venv/bin/activate
pip install anthropic python-dotenv

# è¨­å®š API é‡‘é‘°
echo "ANTHROPIC_API_KEY=your-api-key" > .env

# åŸ·è¡Œé‡å¯«
python main.py
```

### 9.7.2 å¯¦éš›åŸ·è¡Œæ—¥èªŒ

```
================================================================================
é–‹å§‹æ‡‰ç”¨ç¨‹å¼é‡å¯«å°ˆæ¡ˆ
================================================================================

[éšæ®µ 1/4] æƒæç¨‹å¼ç¢¼åº«...
ç™¼ç¾ 12 å€‹æª”æ¡ˆï¼Œ31,450 è¡Œç¨‹å¼ç¢¼

[éšæ®µ 2/4] ç”ŸæˆåŸ·è¡Œè¨ˆç•«...
è¨ˆç•«ç”Ÿæˆå®Œæˆï¼š
  - ç¸½ä»»å‹™æ•¸ï¼š8
  - é ä¼°æ™‚é–“ï¼š125 åˆ†é˜
  - é—œéµè·¯å¾‘ï¼š5 å€‹ä»»å‹™
  - å¯ä¸¦è¡Œçµ„ï¼š2 çµ„
åŸ·è¡Œè¨ˆç•«å·²å„²å­˜ï¼š./output/rewritten_system/execution_plan.json

[éšæ®µ 3/4] åŸ·è¡Œé‡å¯«ä»»å‹™...
æº–å‚™åŸ·è¡Œ 3 å€‹ä»»å‹™ï¼š['åˆ†æç¾æœ‰æ¶æ§‹', 'åˆ†æè³‡æ–™æ¨¡å‹', 'è­˜åˆ¥æ¥­å‹™é‚è¼¯']
[task_1] é–‹å§‹åŸ·è¡Œï¼šåˆ†æç¾æœ‰æ¶æ§‹
[task_2] é–‹å§‹åŸ·è¡Œï¼šåˆ†æè³‡æ–™æ¨¡å‹
[task_3] é–‹å§‹åŸ·è¡Œï¼šè­˜åˆ¥æ¥­å‹™é‚è¼¯
[task_1] å®Œæˆ (542.3ç§’)
[task_2] å®Œæˆ (487.1ç§’)
[task_3] å®Œæˆ (623.8ç§’)

æº–å‚™åŸ·è¡Œ 2 å€‹ä»»å‹™ï¼š['è¨­è¨ˆå¾®æœå‹™æ¶æ§‹', 'è¨­è¨ˆè³‡æ–™åº« Schema']
[task_4] é–‹å§‹åŸ·è¡Œï¼šè¨­è¨ˆå¾®æœå‹™æ¶æ§‹
[task_5] é–‹å§‹åŸ·è¡Œï¼šè¨­è¨ˆè³‡æ–™åº« Schema
[task_4] å®Œæˆ (892.5ç§’)
[task_5] å®Œæˆ (456.2ç§’)

æº–å‚™åŸ·è¡Œ 3 å€‹ä»»å‹™ï¼š['å¯¦ä½œå®¢æˆ¶æœå‹™', 'å¯¦ä½œè¨‚å–®æœå‹™', 'å¯¦ä½œåº«å­˜æœå‹™']
[task_6] é–‹å§‹åŸ·è¡Œï¼šå¯¦ä½œå®¢æˆ¶æœå‹™
[task_7] é–‹å§‹åŸ·è¡Œï¼šå¯¦ä½œè¨‚å–®æœå‹™
[task_8] é–‹å§‹åŸ·è¡Œï¼šå¯¦ä½œåº«å­˜æœå‹™
[task_6] å®Œæˆ (1245.7ç§’)
[task_7] å®Œæˆ (1523.4ç§’)
[task_8] å®Œæˆ (1089.6ç§’)

æº–å‚™åŸ·è¡Œ 1 å€‹ä»»å‹™ï¼š['ç”Ÿæˆæ•´åˆæ¸¬è©¦']
[task_9] é–‹å§‹åŸ·è¡Œï¼šç”Ÿæˆæ•´åˆæ¸¬è©¦
[task_9] å®Œæˆ (678.9ç§’)

[éšæ®µ 4/4] ç”Ÿæˆæœ€çµ‚å ±å‘Š...
æœ€çµ‚å ±å‘Šå·²å„²å­˜ï¼š./output/rewritten_system/final_report.json

================================================================================
åŸ·è¡Œæ‘˜è¦
================================================================================

å°ˆæ¡ˆï¼šPHP ERP ç³»çµ±é‡å¯«ç‚º Python å¾®æœå‹™
ç›®æ¨™ï¼šå°‡å–®é«”æ‡‰ç”¨æ‹†åˆ†ç‚º 4 å€‹å¾®æœå‹™ï¼Œæä¾› RESTful API

åŸ·è¡Œçµæœï¼š
  âœ… å®Œæˆä»»å‹™ï¼š8/8
  âŒ å¤±æ•—ä»»å‹™ï¼š0
  ğŸ“Š æˆåŠŸç‡ï¼š100.0%

æ™‚é–“çµ±è¨ˆï¼š
  â±ï¸  å¯¦éš›è€—æ™‚ï¼š118.6 åˆ†é˜
  ğŸ“… é ä¼°è€—æ™‚ï¼š125.0 åˆ†é˜
  âš¡ æ•ˆç‡æ¯”ï¼š1.05x

å“è³ªæŒ‡æ¨™ï¼š
  ğŸ’° ç¸½æˆæœ¬ï¼š$23.45
  ğŸ¯ æ™‚é–“æ•ˆç‡ï¼š1.05x

================================================================================

âœ… é‡å¯«å®Œæˆï¼
ğŸ“ è¼¸å‡ºç›®éŒ„ï¼š./output/rewritten_system
ğŸ“Š è©³ç´°å ±å‘Šï¼š./output/rewritten_system/final_report.json
```

### 9.7.3 ç”Ÿæˆçš„å¾®æœå‹™çµæ§‹

```
output/rewritten_system/
â”œâ”€â”€ execution_plan.json           # åŸ·è¡Œè¨ˆç•«
â”œâ”€â”€ final_report.json              # æœ€çµ‚å ±å‘Š
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ customer_service/
â”‚   â”‚   â”œâ”€â”€ main.py               # FastAPI æ‡‰ç”¨
â”‚   â”‚   â”œâ”€â”€ models.py             # Pydantic æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ database.py           # è³‡æ–™åº«é€£æ¥
â”‚   â”‚   â”œâ”€â”€ crud.py               # CRUD æ“ä½œ
â”‚   â”‚   â”œâ”€â”€ schemas.py            # API Schemas
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_api.py       # API æ¸¬è©¦
â”‚   â”‚   â”‚   â””â”€â”€ test_crud.py      # CRUD æ¸¬è©¦
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ order_service/
â”‚   â”‚   â””â”€â”€ ... (ç›¸åŒçµæ§‹)
â”‚   â”œâ”€â”€ inventory_service/
â”‚   â”‚   â””â”€â”€ ... (ç›¸åŒçµæ§‹)
â”‚   â””â”€â”€ billing_service/
â”‚       â””â”€â”€ ... (ç›¸åŒçµæ§‹)
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ schema.sql                # è³‡æ–™åº« Schema
â”‚   â””â”€â”€ migrations/               # é·ç§»è…³æœ¬
â”œâ”€â”€ docker-compose.yml             # å®Œæ•´éƒ¨ç½²é…ç½®
â”œâ”€â”€ README.md                      # å°ˆæ¡ˆæ–‡ä»¶
â””â”€â”€ docs/
    â”œâ”€â”€ architecture.md            # æ¶æ§‹æ–‡ä»¶
    â”œâ”€â”€ api_reference.md           # API æ–‡ä»¶
    â””â”€â”€ deployment_guide.md        # éƒ¨ç½²æŒ‡å—
```

### 9.7.4 å¯¦éš›æ•ˆç›Šå°æ¯”

| æŒ‡æ¨™ | å‚³çµ±äººå·¥é‡å¯« | Meta Agent é‡å¯« | æ”¹å–„å¹…åº¦ |
|------|------------|----------------|---------|
| **é–‹ç™¼æ™‚é–“** | 6-12 å€‹æœˆ | 2-3 é€± | **92-95% â†“** |
| **äººåŠ›æˆæœ¬** | 6 äºº Ã— 10 æœˆ<br/>â‰ˆ NT$ 3,600,000 | 1 äºº Ã— 3 é€±<br/>â‰ˆ NT$ 90,000 | **97.5% â†“** |
| **AI æˆæœ¬** | $0 | $23.45 | +$23.45 |
| **ç¸½æˆæœ¬** | NT$ 3,600,000 | NT$ 90,023 | **97.5% â†“** |
| **ç¨‹å¼ç¢¼è¡Œæ•¸** | ç´„ 25,000 è¡Œ | ç´„ 28,500 è¡Œ | +14% (æ›´å®Œæ•´) |
| **æ¸¬è©¦è¦†è“‹ç‡** | 40-60% | 95%+ | **58-138% â†‘** |
| **æ–‡ä»¶å®Œæ•´åº¦** | éƒ¨åˆ†ç¼ºå¤± | å®Œæ•´ | **100% â†‘** |
| **åŠŸèƒ½éºæ¼é¢¨éšª** | ä¸­-é«˜ | æ¥µä½ | **é¡¯è‘—é™ä½** |

---

## 9.8 é€²éšå„ªåŒ–èˆ‡æœ€ä½³å¯¦è¸

### 9.8.1 å‹•æ…‹è¨ˆç•«èª¿æ•´

ç•¶åŸ·è¡Œéç¨‹ä¸­ç™¼ç¾å•é¡Œæ™‚ï¼ŒMeta Agent å¯ä»¥å‹•æ…‹èª¿æ•´è¨ˆç•«ï¼š

```python
# åœ¨ TaskCoordinator ä¸­æ·»åŠ 
async def handle_failure_with_replanning(
    self,
    failed_task: Task,
    error: str
) -> None:
    """è™•ç†å¤±æ•—ä¸¦è«‹æ±‚ Meta Agent é‡æ–°è¦åŠƒ"""

    logger.warning(f"ä»»å‹™ {failed_task.id} å¤±æ•—ï¼Œè«‹æ±‚é‡æ–°è¦åŠƒ")

    # æ”¶é›†å·²å®Œæˆä»»å‹™çš„çµæœ
    completed_results = [
        {
            "task_id": exec.task.id,
            "task_name": exec.task.name,
            "result": exec.result
        }
        for exec in self.executions.values()
        if exec.status == TaskStatus.COMPLETED
    ]

    # æè¿°å•é¡Œ
    issues = [
        f"ä»»å‹™ {failed_task.id} ({failed_task.name}) å¤±æ•—ï¼š{error}",
        f"å·²å®Œæˆ {len(completed_results)} å€‹ä»»å‹™",
        f"éœ€è¦æ±ºå®šå¦‚ä½•è™•ç†å‰©é¤˜ {len([e for e in self.executions.values() if e.status == TaskStatus.PENDING])} å€‹å¾…åŸ·è¡Œä»»å‹™"
    ]

    # è«‹æ±‚ Meta Agent èª¿æ•´è¨ˆç•«
    from meta_agent import MetaAgent
    meta = MetaAgent(api_key=self.api_key)

    adjusted_plan = meta.adjust_plan(
        current_plan=self.plan,
        execution_results=completed_results,
        issues=issues
    )

    # æ›´æ–°è¨ˆç•«
    self.plan = adjusted_plan

    # é‡æ–°åˆå§‹åŒ–å¾…åŸ·è¡Œçš„ä»»å‹™
    for task in adjusted_plan.tasks:
        if task.id not in self.executions or self.executions[task.id].status == TaskStatus.PENDING:
            self.executions[task.id] = TaskExecution(task=task)

    logger.info("è¨ˆç•«å·²èª¿æ•´ï¼Œç¹¼çºŒåŸ·è¡Œ")
```

### 9.8.2 é€²åº¦è¦–è¦ºåŒ–

```python
# progress_visualizer.py
from rich.console import Console
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TimeElapsedColumn
from typing import Dict

class ProgressVisualizer:
    """é€²åº¦è¦–è¦ºåŒ–"""

    def __init__(self):
        self.console = Console()

    def display_plan(self, plan: ExecutionPlan):
        """é¡¯ç¤ºåŸ·è¡Œè¨ˆç•«"""
        table = Table(title=f"åŸ·è¡Œè¨ˆç•«ï¼š{plan.project_name}")

        table.add_column("ID", style="cyan")
        table.add_column("ä»»å‹™åç¨±", style="white")
        table.add_column("é¡å‹", style="yellow")
        table.add_column("å„ªå…ˆç´š", style="magenta")
        table.add_column("ä¾è³´", style="blue")
        table.add_column("é ä¼°æ™‚é–“", style="green")

        for task in plan.tasks:
            table.add_row(
                task.id,
                task.name,
                task.task_type.value,
                str(task.priority.value),
                ", ".join(task.dependencies) if task.dependencies else "-",
                f"{task.estimated_time // 60}m"
            )

        self.console.print(table)

    def display_progress(self, executions: Dict[str, TaskExecution]):
        """é¡¯ç¤ºå³æ™‚é€²åº¦"""
        completed = sum(1 for e in executions.values() if e.status == TaskStatus.COMPLETED)
        running = sum(1 for e in executions.values() if e.status == TaskStatus.RUNNING)
        failed = sum(1 for e in executions.values() if e.status == TaskStatus.FAILED)
        total = len(executions)

        self.console.print(f"\né€²åº¦ï¼š{completed}/{total} å®Œæˆ | {running} åŸ·è¡Œä¸­ | {failed} å¤±æ•—")

        # é¡¯ç¤ºåŸ·è¡Œä¸­çš„ä»»å‹™
        if running > 0:
            self.console.print("\nåŸ·è¡Œä¸­çš„ä»»å‹™ï¼š")
            for exec in executions.values():
                if exec.status == TaskStatus.RUNNING:
                    self.console.print(f"  ğŸ”„ {exec.task.name}")

# åœ¨ main.py ä¸­ä½¿ç”¨
visualizer = ProgressVisualizer()
visualizer.display_plan(plan)

# åœ¨åŸ·è¡Œéç¨‹ä¸­å®šæœŸæ›´æ–°
import asyncio

async def monitor_progress(coordinator: TaskCoordinator):
    while not coordinator._all_tasks_terminal():
        visualizer.display_progress(coordinator.executions)
        await asyncio.sleep(5)
```

### 9.8.3 æˆæœ¬å„ªåŒ–ç­–ç•¥

```python
class CostOptimizer:
    """æˆæœ¬å„ªåŒ–å™¨"""

    def optimize_model_selection(self, task: Task) -> str:
        """æ ¹æ“šä»»å‹™é¡å‹é¸æ“‡åˆé©çš„æ¨¡å‹"""

        # ç°¡å–®åˆ†æä»»å‹™ â†’ Haiku
        if task.task_type == TaskType.ANALYSIS and task.estimated_time < 300:
            return "claude-haiku-3-20250307"

        # è¤‡é›œç”Ÿæˆä»»å‹™ â†’ Opus
        elif task.task_type == TaskType.GENERATION and task.priority == TaskPriority.CRITICAL:
            return "claude-opus-4-20250514"

        # ä¸€èˆ¬ä»»å‹™ â†’ Sonnet
        else:
            return "claude-sonnet-4-20250514"

    def estimate_cost(self, plan: ExecutionPlan) -> Dict[str, float]:
        """é ä¼°ç¸½æˆæœ¬"""

        # æ¨¡å‹åƒ¹æ ¼ï¼ˆæ¯ç™¾è¬ tokensï¼‰
        pricing = {
            "claude-haiku-3-20250307": {"input": 0.25, "output": 1.25},
            "claude-sonnet-4-20250514": {"input": 3.00, "output": 15.00},
            "claude-opus-4-20250514": {"input": 15.00, "output": 75.00}
        }

        total_cost = 0
        breakdown = {}

        for task in plan.tasks:
            model = self.optimize_model_selection(task)

            # é ä¼° token ä½¿ç”¨é‡ï¼ˆç²—ç•¥ï¼‰
            estimated_input_tokens = 10000  # 10K input
            estimated_output_tokens = 5000  # 5K output

            cost = (
                estimated_input_tokens / 1_000_000 * pricing[model]["input"] +
                estimated_output_tokens / 1_000_000 * pricing[model]["output"]
            )

            total_cost += cost
            breakdown[task.id] = {
                "model": model,
                "estimated_cost": cost
            }

        return {
            "total_cost": total_cost,
            "breakdown": breakdown
        }
```

---

## 9.9 æ¶æ§‹åœ–ç¸½è¦½

### 9.9.1 è³‡æ–™æµåœ–

```mermaid
sequenceDiagram
    participant User
    participant System as Application<br/>Rewrite System
    participant Meta as Meta Agent<br/>(è¦åŠƒå±¤)
    participant Coord as Task Coordinator<br/>(å”èª¿å±¤)
    participant Sub as Subagent Executor<br/>(åŸ·è¡Œå±¤)

    User->>System: æäº¤é‡å¯«è«‹æ±‚
    System->>System: æƒæç¨‹å¼ç¢¼åº«
    System->>Meta: åˆ†æå°ˆæ¡ˆéœ€æ±‚

    Meta->>Meta: åˆ†è§£ä»»å‹™
    Meta->>Meta: è­˜åˆ¥ä¾è³´
    Meta->>Meta: è¨ˆç®—é—œéµè·¯å¾‘
    Meta-->>System: è¿”å›åŸ·è¡Œè¨ˆç•«

    System->>Coord: æäº¤è¨ˆç•«

    loop åŸ·è¡Œä»»å‹™
        Coord->>Coord: ç²å–å¯åŸ·è¡Œä»»å‹™
        Coord->>Sub: å‰µå»º Subagent
        Sub->>Sub: åŸ·è¡Œä»»å‹™
        Sub-->>Coord: è¿”å›çµæœ

        alt ä»»å‹™å¤±æ•—
            Coord->>Meta: è«‹æ±‚èª¿æ•´è¨ˆç•«
            Meta-->>Coord: è¿”å›æ–°è¨ˆç•«
        end
    end

    Coord-->>System: è¿”å›åŸ·è¡Œçµæœ
    System->>System: ç”Ÿæˆå ±å‘Š
    System-->>User: è¿”å›å®Œæˆç‹€æ…‹
```

### 9.9.2 ä¸‰å±¤æ¶æ§‹å°æ¯”

```mermaid
graph LR
    subgraph "å‚³çµ±å–®å±¤æ¶æ§‹"
        A1[Main Agent] --> T1[Task 1]
        A1 --> T2[Task 2]
        A1 --> T3[Task 3]
    end

    subgraph "Meta Agent ä¸‰å±¤æ¶æ§‹"
        M[Meta Agent<br/>è¦åŠƒå±¤] --> C[Coordinator<br/>å”èª¿å±¤]
        C --> S1[Subagent 1<br/>åŸ·è¡Œå±¤]
        C --> S2[Subagent 2<br/>åŸ·è¡Œå±¤]
        C --> S3[Subagent 3<br/>åŸ·è¡Œå±¤]
        S1 --> R1[Result]
        S2 --> R2[Result]
        S3 --> R3[Result]
        R1 --> C
        R2 --> C
        R3 --> C
        C -.åé¥‹.-> M
    end
```

---

## 9.10 æ•…éšœæ’é™¤æŒ‡å—

### å¸¸è¦‹å•é¡Œ 1ï¼šä»»å‹™æ­»é–

**ç—‡ç‹€**ï¼šç³»çµ±åœæ»¯ï¼Œæ²’æœ‰ä»»å‹™åœ¨åŸ·è¡Œ

**åŸå› **ï¼šå­˜åœ¨å¾ªç’°ä¾è³´ï¼ˆTask A ä¾è³´ Task Bï¼ŒTask B ä¾è³´ Task Aï¼‰

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# æª¢æŸ¥ä¾è³´é—œä¿‚
coordinator = TaskCoordinator(plan)
if coordinator._has_deadlock():
    print("åµæ¸¬åˆ°å¾ªç’°ä¾è³´ï¼")
    # æª¢æŸ¥ä¾è³´åœ–
    for task in plan.tasks:
        print(f"{task.id}: depends on {task.dependencies}")
```

### å¸¸è¦‹å•é¡Œ 2ï¼šSubagent å‰µå»ºå¤±æ•—

**ç—‡ç‹€**ï¼š`Agent initialization failed`

**åŸå› **ï¼šAPI é‡‘é‘°ç„¡æ•ˆæˆ–é…é¡ä¸è¶³

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# é©—è­‰ API é‡‘é‘°
import anthropic

try:
    client = anthropic.Anthropic(api_key=api_key)
    response = client.messages.create(
        model="claude-haiku-3-20250307",
        max_tokens=10,
        messages=[{"role": "user", "content": "test"}]
    )
    print("âœ… API é‡‘é‘°æœ‰æ•ˆ")
except anthropic.AuthenticationError:
    print("âŒ API é‡‘é‘°ç„¡æ•ˆ")
except anthropic.RateLimitError:
    print("âŒ é…é¡ä¸è¶³")
```

### å¸¸è¦‹å•é¡Œ 3ï¼šè¨˜æ†¶é«”ä¸è¶³

**ç—‡ç‹€**ï¼šå¤šå€‹ Subagent ä¸¦è¡ŒåŸ·è¡Œæ™‚ç³»çµ±è®Šæ…¢

**åŸå› **ï¼š`max_parallel` è¨­å®šéé«˜

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# é™ä½ä¸¦è¡Œæ•¸é‡
coordinator = TaskCoordinator(plan, max_parallel=2)  # å¾ 3 é™åˆ° 2

# æˆ–æ ¹æ“šç³»çµ±è³‡æºå‹•æ…‹èª¿æ•´
import psutil

available_memory_gb = psutil.virtual_memory().available / (1024**3)
max_parallel = max(1, int(available_memory_gb / 2))  # æ¯å€‹ Agent ç´„ 2GB
```

---

## 9.11 ç« ç¯€ç¸½çµ

### ä½ å·²ç¶“å­¸æœƒäº†ä»€éº¼

âœ… **Meta Agent çš„æ ¸å¿ƒæ¦‚å¿µ**
   - è¦åŠƒèƒ½åŠ›ï¼šåˆ†æè¤‡é›œä»»å‹™ã€åˆ¶å®šåŸ·è¡Œè¨ˆç•«
   - å”èª¿èƒ½åŠ›ï¼šç®¡ç† Subagentsã€åˆ†é…è³‡æº
   - æ±ºç­–èƒ½åŠ›ï¼šå‹•æ…‹èª¿æ•´ã€éŒ¯èª¤æ¢å¾©

âœ… **ä¸‰å±¤æ¶æ§‹è¨­è¨ˆ**
   - è¦åŠƒå±¤ï¼ˆMeta Agentï¼‰ï¼šæ€è€ƒã€Œåšä»€éº¼ã€ã€Œæ€éº¼åšã€
   - å”èª¿å±¤ï¼ˆTask Coordinatorï¼‰ï¼šç®¡ç†ã€Œèª°ä¾†åšã€ã€Œä½•æ™‚åšã€
   - åŸ·è¡Œå±¤ï¼ˆSubagent Executorï¼‰ï¼šçœŸæ­£ã€Œå‹•æ‰‹åšã€

âœ… **ä»»å‹™ä¾è³´ç®¡ç†**
   - è­˜åˆ¥ä¾è³´é—œä¿‚
   - æ‹“æ’²æ’åºèˆ‡æ­»é–åµæ¸¬
   - é—œéµè·¯å¾‘è¨ˆç®—

âœ… **ä¸¦è¡ŒåŸ·è¡Œå„ªåŒ–**
   - è­˜åˆ¥å¯ä¸¦è¡Œä»»å‹™çµ„
   - å‹•æ…‹èª¿åº¦èˆ‡è³‡æºåˆ†é…
   - æ•ˆèƒ½èˆ‡æˆæœ¬å¹³è¡¡

âœ… **éŒ¯èª¤è™•ç†èˆ‡æ¢å¾©**
   - è‡ªå‹•é‡è©¦æ©Ÿåˆ¶
   - å‹•æ…‹è¨ˆç•«èª¿æ•´
   - å¤±æ•—éš”é›¢èˆ‡é™ç´š

### å¯¦éš›æ•ˆç›Š

| é¢å‘ | æ•ˆç›Š |
|------|------|
| **é–‹ç™¼é€Ÿåº¦** | æå‡ 12-24 å€ |
| **æˆæœ¬** | é™ä½ 97.5% |
| **å“è³ª** | æ¸¬è©¦è¦†è“‹ç‡ 95%+ |
| **æ–‡ä»¶** | è‡ªå‹•ç”Ÿæˆå®Œæ•´æ–‡ä»¶ |
| **é¢¨éšª** | åŠŸèƒ½éºæ¼é¢¨éšªæ¥µä½ |

### æª¢æŸ¥æ¸…å–®

åœ¨å°‡ Meta Agent ç³»çµ±æ‡‰ç”¨åˆ°å¯¦éš›å°ˆæ¡ˆä¹‹å‰ï¼Œè«‹ç¢ºèªï¼š

- [ ] **ç†è§£ä¸‰å±¤æ¶æ§‹**çš„è·è²¬åˆ†å·¥
- [ ] **æŒæ¡ä»»å‹™ä¾è³´**ç®¡ç†æ–¹æ³•
- [ ] **å¯¦ä½œéŒ¯èª¤è™•ç†**èˆ‡é‡è©¦æ©Ÿåˆ¶
- [ ] **å„ªåŒ–ä¸¦è¡ŒåŸ·è¡Œ**ç­–ç•¥
- [ ] **é…ç½®æˆæœ¬å„ªåŒ–**ï¼ˆæ¨¡å‹é¸æ“‡ï¼‰
- [ ] **è¨­è¨ˆé€²åº¦ç›£æ§**æ©Ÿåˆ¶
- [ ] **æº–å‚™æ•…éšœæ’é™¤**æ–¹æ¡ˆ
- [ ] **æ¸¬è©¦å®Œæ•´æµç¨‹**ï¼ˆå°è¦æ¨¡è©¦é‹è¡Œï¼‰

---

## 9.12 ä¸‹ä¸€ç« é å‘Š

æ­å–œå®Œæˆå¯¦æˆ°ç¯‡ï¼æ¥ä¸‹ä¾†æˆ‘å€‘å°‡é€²å…¥**æ²»ç†ç¯‡**ï¼Œå­¸ç¿’å¦‚ä½•åœ¨ä¼æ¥­ç’°å¢ƒä¸­å®‰å…¨ã€åˆè¦åœ°ç®¡ç† Agent ç³»çµ±ã€‚

**ç¬¬ 10 ç« ï¼šæˆæœ¬ç®¡ç†èˆ‡å„ªåŒ– - å»ºç«‹æ™ºæ…§é ç®—ç³»çµ±**

ä½ å°‡å­¸åˆ°ï¼š
- å¤šç¶­åº¦æˆæœ¬è¿½è¹¤ï¼ˆAPI æˆæœ¬ã€é‹ç®—è³‡æºã€äººåŠ›æˆæœ¬ï¼‰
- é ç®—é è­¦èˆ‡è‡ªå‹•é™æµæ©Ÿåˆ¶
- æˆæœ¬æ­¸å› åˆ†æï¼ˆæŒ‰å°ˆæ¡ˆã€éƒ¨é–€ã€ç”¨æˆ¶ï¼‰
- Model Router æ™ºæ…§é¸æ“‡ï¼ˆHaiku/Sonnet/Opusï¼‰
- å¿«å–ç­–ç•¥å„ªåŒ–ï¼ˆPrompt Caching, Response Cachingï¼‰
- ROI è¨ˆç®—èˆ‡æ•ˆç›Šè©•ä¼°

**å¯¦æˆ°å°ˆæ¡ˆ**ï¼šç‚ºä¼æ¥­ AI å¹³å°å»ºç«‹å®Œæ•´çš„æˆæœ¬ç®¡ç†ç³»çµ±ï¼Œå¯¦ç¾æˆæœ¬å¯è¦–åŒ–ã€é ç®—æ§åˆ¶ã€è‡ªå‹•å„ªåŒ–ã€‚

æº–å‚™å¥½æ¢ç´¢ Agent æˆæœ¬ç®¡ç†çš„æœ€ä½³å¯¦è¸äº†å—ï¼Ÿè®“æˆ‘å€‘ç¹¼çºŒå‰é€²ï¼

---

**ç« ç¯€å®Œæˆæ™‚é–“**ï¼šç´„ 90-120 åˆ†é˜
**é›£åº¦ç­‰ç´š**ï¼šâ­â­â­â­â­ (5/5 - é€²éš)
**å‰ç½®è¦æ±‚**ï¼šå®Œæˆç¬¬ 1-8 ç« 
