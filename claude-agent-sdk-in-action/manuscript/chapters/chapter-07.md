# ç¬¬ 7 ç« ï¼šä¼æ¥­ç´š Agent æ¶æ§‹è¨­è¨ˆ - æ™ºæ…§å®¢æˆ¶æ”¯æ´å¹³å°

> **æœ¬ç« ç›®æ¨™**ï¼šè¨­è¨ˆä¸¦å¯¦ä½œä¸€å€‹å¯æœå‹™ 10,000+ ç”¨æˆ¶çš„ä¼æ¥­ç´šæ™ºæ…§å®¢æˆ¶æ”¯æ´å¹³å°ï¼Œå­¸ç¿’å¾®æœå‹™æ¶æ§‹ã€è² è¼‰å¹³è¡¡ã€è³‡æ–™åº«è¨­è¨ˆèˆ‡ç³»çµ±æ“´å±•ç­–ç•¥ã€‚

---

## 7.1 å¾åŸå‹åˆ°ç”Ÿç”¢ï¼šä¼æ¥­ç´šæŒ‘æˆ°

### 7.1.1 çœŸå¯¦å ´æ™¯ï¼šæ“´å±•çš„é™£ç—›

**æŸ SaaS å…¬å¸çš„æ•…äº‹**ï¼š

```
éšæ®µ 1ï¼šåŸå‹ï¼ˆç¬¬ 1 ç« çš„å®¢æœ Agentï¼‰
- ç”¨æˆ¶æ•¸ï¼š< 100
- å›æ‡‰æ™‚é–“ï¼šå¹³å‡ 2 ç§’
- ç‹€æ…‹ï¼šä¸€åˆ‡æ­£å¸¸ âœ…

éšæ®µ 2ï¼šå¢é•·ï¼ˆ1,000 ç”¨æˆ¶ï¼‰
- å›æ‡‰æ™‚é–“ï¼šå¹³å‡ 8 ç§’ âš ï¸
- è¨˜æ†¶é«”ä½¿ç”¨ï¼š2GB â†’ 8GB
- æˆæœ¬ï¼š$500/æœˆ â†’ $2,500/æœˆ
- å•é¡Œï¼šå–®ä¸€ Agent æˆç‚ºç“¶é ¸

éšæ®µ 3ï¼šçˆ†ç™¼ï¼ˆ10,000 ç”¨æˆ¶ï¼‰
- å›æ‡‰æ™‚é–“ï¼š> 30 ç§’ âŒ
- ç³»çµ±å´©æ½°ï¼šæ¯å¤© 2-3 æ¬¡
- è³‡æ–™éºå¤±ï¼šå°è©±æ­·å²ä¸Ÿå¤±
- æˆæœ¬ï¼š$15,000/æœˆ
- çµæœï¼šå®¢æˆ¶æµå¤±ã€è²è­½å—æ
```

**å•é¡Œæ ¹æº**ï¼š
1. âŒ å–®ä¸€é€²ç¨‹ç„¡æ³•è™•ç†å¤§é‡ä¸¦ç™¼è«‹æ±‚
2. âŒ æ²’æœ‰è³‡æ–™æŒä¹…åŒ–ç­–ç•¥
3. âŒ ç¼ºä¹å¿«å–æ©Ÿåˆ¶
4. âŒ ç„¡æ³•æ°´å¹³æ“´å±•
5. âŒ æ²’æœ‰è² è¼‰å¹³è¡¡

### 7.1.2 ä¼æ¥­ç´šç³»çµ±çš„æ ¸å¿ƒè¦æ±‚

```mermaid
graph TB
    A[ä¼æ¥­ç´šç³»çµ±] --> B[é«˜å¯ç”¨æ€§]
    A --> C[å¯æ“´å±•æ€§]
    A --> D[æ•ˆèƒ½]
    A --> E[å®‰å…¨æ€§]
    A --> F[å¯è§€æ¸¬æ€§]

    B --> B1[99.9% æ­£å¸¸é‹è¡Œæ™‚é–“]
    B --> B2[æ•…éšœè‡ªå‹•æ¢å¾©]
    B --> B3[é›¶åœæ©Ÿéƒ¨ç½²]

    C --> C1[æ°´å¹³æ“´å±•]
    C --> C2[è‡ªå‹•æ“´å±•]
    C --> C3[æ¨¡çµ„åŒ–è¨­è¨ˆ]

    D --> D1[å›æ‡‰æ™‚é–“ < 3s]
    D --> D2[é«˜ååé‡]
    D --> D3[è³‡æºå„ªåŒ–]

    E --> E1[èªè­‰æˆæ¬Š]
    E --> E2[è³‡æ–™åŠ å¯†]
    E --> E3[å¯©è¨ˆæ—¥èªŒ]

    F --> F1[ç›£æ§æŒ‡æ¨™]
    F --> F2[æ—¥èªŒèšåˆ]
    F --> F3[åˆ†æ•£å¼è¿½è¹¤]

    style A fill:#f9f,stroke:#333
    style B fill:#bbf,stroke:#333
    style C fill:#bfb,stroke:#333
    style D fill:#ffb,stroke:#333
    style E fill:#fbb,stroke:#333
    style F fill:#bff,stroke:#333
```

### 7.1.3 æœ¬ç« å°ˆæ¡ˆï¼šæ™ºæ…§å®¢æˆ¶æ”¯æ´å¹³å°

**å ´æ™¯**ï¼šä¸€å®¶é›»å•†å¹³å°éœ€è¦å»ºç«‹æ™ºæ…§å®¢æˆ¶æ”¯æ´ç³»çµ±ï¼Œè™•ç†ä»¥ä¸‹æ¥­å‹™ï¼š

**æ¥­å‹™éœ€æ±‚**ï¼š
- ğŸ“Š **è¦æ¨¡**: 10,000+ ä¸¦ç™¼ç”¨æˆ¶
- âš¡ **æ•ˆèƒ½**: å›æ‡‰æ™‚é–“ < 3 ç§’
- ğŸ¯ **å¯ç”¨æ€§**: 99.9% SLA
- ğŸ’° **æˆæœ¬**: åˆç†çš„ API é–‹éŠ·

**åŠŸèƒ½éœ€æ±‚**ï¼š
1. **FAQ æŸ¥è©¢**ï¼šå›ç­”å¸¸è¦‹å•é¡Œ
2. **è¨‚å–®ç®¡ç†**ï¼šæŸ¥è©¢ã€ä¿®æ”¹ã€å–æ¶ˆè¨‚å–®
3. **é€€æ¬¾è™•ç†**ï¼šè™•ç†é€€æ¬¾ç”³è«‹
4. **æŠ€è¡“æ”¯æ´**ï¼šå¼•å°ç”¨æˆ¶è§£æ±ºæŠ€è¡“å•é¡Œ
5. **äººå·¥è½‰æ¥**ï¼šè¤‡é›œå•é¡Œè½‰çµ¦çœŸäººå®¢æœ

**æŠ€è¡“æŒ‘æˆ°**ï¼š
- å¦‚ä½•è¨­è¨ˆå¯æ“´å±•çš„æ¶æ§‹ï¼Ÿ
- å¦‚ä½•ç¢ºä¿é«˜å¯ç”¨æ€§ï¼Ÿ
- å¦‚ä½•ç®¡ç†ä¸åŒé¡å‹çš„ Agentï¼Ÿ
- å¦‚ä½•å„ªåŒ–æˆæœ¬ï¼Ÿ

---

## 7.2 ç³»çµ±æ¶æ§‹è¨­è¨ˆ

### 7.2.1 æ•´é«”æ¶æ§‹

```mermaid
graph TB
    subgraph "ç”¨æˆ¶å±¤"
        A1[Web å®¢æˆ¶ç«¯]
        A2[Mobile App]
        A3[ç¬¬ä¸‰æ–¹æ•´åˆ]
    end

    subgraph "API å±¤"
        B1[API Gateway]
        B2[è² è¼‰å¹³è¡¡å™¨]
        B3[èªè­‰æœå‹™]
    end

    subgraph "æ‡‰ç”¨å±¤ - Agent æœå‹™"
        C1[è·¯ç”± Agent]
        C2[FAQ Agent]
        C3[è¨‚å–® Agent]
        C4[é€€æ¬¾ Agent]
        C5[æŠ€è¡“æ”¯æ´ Agent]
    end

    subgraph "è³‡æ–™å±¤"
        D1[(PostgreSQL<br/>ä¸»è³‡æ–™åº«)]
        D2[(Redis<br/>å¿«å– & æœƒè©±)]
        D3[(Elasticsearch<br/>æœå°‹å¼•æ“)]
        D4[S3<br/>æª”æ¡ˆå„²å­˜]
    end

    subgraph "åŸºç¤è¨­æ–½å±¤"
        E1[æ¶ˆæ¯éšŠåˆ—<br/>RabbitMQ]
        E2[ç›£æ§<br/>Prometheus]
        E3[æ—¥èªŒ<br/>ELK Stack]
    end

    A1 --> B1
    A2 --> B1
    A3 --> B1
    B1 --> B2
    B2 --> B3
    B3 --> C1

    C1 --> C2
    C1 --> C3
    C1 --> C4
    C1 --> C5

    C2 --> D1
    C2 --> D2
    C2 --> D3

    C3 --> D1
    C3 --> D2

    C4 --> D1
    C4 --> E1

    C5 --> D3
    C5 --> D4

    C1 -.-> E2
    C2 -.-> E2
    C3 -.-> E2
    C4 -.-> E2
    C5 -.-> E2

    C1 -.-> E3
    C2 -.-> E3
    C3 -.-> E3

    style B1 fill:#f9f,stroke:#333
    style C1 fill:#bbf,stroke:#333
    style D1 fill:#bfb,stroke:#333
    style D2 fill:#ffb,stroke:#333
```

### 7.2.2 æ¶æ§‹è¨­è¨ˆåŸå‰‡

**1. å¾®æœå‹™åŒ–**
```
ç‚ºä½•å¾®æœå‹™ï¼Ÿ
âœ… ç¨ç«‹éƒ¨ç½²ï¼šæ¯å€‹ Agent å¯ä»¥ç¨ç«‹æ›´æ–°
âœ… èªè¨€ç„¡é—œï¼šä¸åŒ Agent å¯ä»¥ç”¨ä¸åŒæŠ€è¡“
âœ… æ•…éšœéš”é›¢ï¼šä¸€å€‹ Agent å´©æ½°ä¸å½±éŸ¿å…¶ä»–
âœ… æ°´å¹³æ“´å±•ï¼šæ ¹æ“šè² è¼‰ç¨ç«‹æ“´å±•
```

**2. é—œæ³¨é»åˆ†é›¢**
```
å±¤ç´š                   è·è²¬
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API Gateway           è·¯ç”±ã€èªè­‰ã€é™æµ
Router Agent          æ„åœ–è­˜åˆ¥ã€åˆ†ç™¼è«‹æ±‚
Specialized Agents    åŸ·è¡Œç‰¹å®šæ¥­å‹™é‚è¼¯
Data Layer            æŒä¹…åŒ–ã€å¿«å–
Infrastructure        ç›£æ§ã€æ—¥èªŒã€æ¶ˆæ¯éšŠåˆ—
```

**3. ç„¡ç‹€æ…‹è¨­è¨ˆ**
```python
# âŒ æœ‰ç‹€æ…‹è¨­è¨ˆï¼ˆç„¡æ³•æ“´å±•ï¼‰
class Agent:
    def __init__(self):
        self.conversation_history = []  # ç‹€æ…‹å„²å­˜åœ¨è¨˜æ†¶é«”

    def handle_request(self, message):
        self.conversation_history.append(message)
        # ... è™•ç†é‚è¼¯

# âœ… ç„¡ç‹€æ…‹è¨­è¨ˆï¼ˆå¯æ“´å±•ï¼‰
class StatelessAgent:
    def __init__(self, session_store):
        self.session_store = session_store  # å¤–éƒ¨ç‹€æ…‹å„²å­˜

    def handle_request(self, session_id, message):
        # å¾å¤–éƒ¨å„²å­˜è®€å–ç‹€æ…‹
        history = self.session_store.get(session_id)
        # è™•ç†è«‹æ±‚
        response = self.process(message, history)
        # æ›´æ–°å¤–éƒ¨ç‹€æ…‹
        self.session_store.update(session_id, response)
        return response
```

**4. å¿«å–å„ªå…ˆ**
```
å¿«å–å±¤ç´šï¼š
1. Browser Cache (å®¢æˆ¶ç«¯)
2. CDN Cache (é‚Šç·£ç¯€é»)
3. Redis Cache (æ‡‰ç”¨å±¤)
4. Database Query Cache (è³‡æ–™å±¤)

æ•ˆç›Šï¼š
- æ¸›å°‘ API å‘¼å« 60-80%
- é™ä½å›æ‡‰æ™‚é–“ 70-90%
- ç¯€çœæˆæœ¬ 50-70%
```

### 7.2.3 æŠ€è¡“æ£§é¸æ“‡

| å±¤ç´š | æŠ€è¡“é¸æ“‡ | åŸå›  |
|------|---------|------|
| **API Gateway** | Kong / Traefik | é«˜æ•ˆèƒ½ã€è±å¯Œçš„æ’ä»¶ç”Ÿæ…‹ |
| **æ‡‰ç”¨æœå‹™** | Python + FastAPI | ç•°æ­¥æ”¯æ´ã€é«˜æ•ˆèƒ½ |
| **Agent SDK** | Claude Agent SDK | æœ¬æ›¸æ ¸å¿ƒæŠ€è¡“ |
| **è³‡æ–™åº«** | PostgreSQL | ACIDã€é—œè¯å¼æŸ¥è©¢ |
| **å¿«å–** | Redis | é«˜æ•ˆèƒ½ã€æ”¯æ´è¤‡é›œè³‡æ–™çµæ§‹ |
| **æœå°‹** | Elasticsearch | å…¨æ–‡æœå°‹ã€åˆ†æ |
| **æ¶ˆæ¯éšŠåˆ—** | RabbitMQ | å¯é ã€æ˜“æ–¼ç®¡ç† |
| **å®¹å™¨åŒ–** | Docker + Kubernetes | æ¨™æº–åŒ–ã€è‡ªå‹•æ“´å±• |
| **ç›£æ§** | Prometheus + Grafana | å¼·å¤§ã€é–‹æº |
| **æ—¥èªŒ** | ELK Stack | é›†ä¸­å¼æ—¥èªŒç®¡ç† |

---

## 7.3 æ ¸å¿ƒçµ„ä»¶å¯¦ä½œ

### 7.3.1 API Gateway è¨­å®š

ä½¿ç”¨ FastAPI å»ºç«‹ API Gatewayï¼š

**gateway/main.py**:
```python
from fastapi import FastAPI, HTTPException, Depends, Header
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional
import uvicorn
import redis
import time
from datetime import datetime

app = FastAPI(title="æ™ºæ…§å®¢æˆ¶æ”¯æ´å¹³å° API Gateway")

# â€¹1â€º CORS è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿç”¢ç’°å¢ƒæ‡‰é™åˆ¶ä¾†æº
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â€¹2â€º Redis é€£æ¥ï¼ˆç”¨æ–¼é™æµå’Œå¿«å–ï¼‰
redis_client = redis.Redis(
    host='localhost',
    port=6379,
    decode_responses=True
)


class ChatRequest(BaseModel):
    """èŠå¤©è«‹æ±‚æ ¼å¼"""
    session_id: str
    message: str
    user_id: str
    metadata: Optional[dict] = {}


class ChatResponse(BaseModel):
    """èŠå¤©å›æ‡‰æ ¼å¼"""
    session_id: str
    message: str
    agent_type: str
    timestamp: str
    response_time_ms: int


# â€¹3â€º èªè­‰ä¸­ä»‹å±¤
async def verify_api_key(x_api_key: str = Header(...)):
    """
    é©—è­‰ API Key

    ç”Ÿç”¢ç’°å¢ƒæ‡‰è©²ï¼š
    1. å¾è³‡æ–™åº«æŸ¥è©¢ API Key
    2. æª¢æŸ¥æ¬Šé™ç¯„åœ
    3. è¨˜éŒ„ä½¿ç”¨æƒ…æ³
    """
    # ç°¡åŒ–ç‰ˆæœ¬ï¼šæª¢æŸ¥ç’°å¢ƒè®Šæ•¸
    import os
    valid_keys = os.getenv("VALID_API_KEYS", "").split(",")

    if x_api_key not in valid_keys:
        raise HTTPException(
            status_code=401,
            detail="Invalid API Key"
        )

    return x_api_key


# â€¹4â€º é™æµä¸­ä»‹å±¤
async def rate_limiter(user_id: str):
    """
    é™æµæ©Ÿåˆ¶

    ç­–ç•¥ï¼šæ¯å€‹ç”¨æˆ¶æ¯åˆ†é˜æœ€å¤š 60 æ¬¡è«‹æ±‚
    """
    key = f"rate_limit:{user_id}"
    current = redis_client.get(key)

    if current is None:
        # é¦–æ¬¡è«‹æ±‚ï¼Œè¨­å®šè¨ˆæ•¸å™¨
        redis_client.setex(key, 60, 1)
    else:
        count = int(current)
        if count >= 60:
            raise HTTPException(
                status_code=429,
                detail="Rate limit exceeded. Max 60 requests per minute."
            )
        redis_client.incr(key)


# â€¹5â€º å¥åº·æª¢æŸ¥ç«¯é»
@app.get("/health")
async def health_check():
    """
    å¥åº·æª¢æŸ¥ç«¯é»

    K8s ä½¿ç”¨æ­¤ç«¯é»åˆ¤æ–·æœå‹™æ˜¯å¦å¥åº·
    """
    try:
        # æª¢æŸ¥ Redis é€£æ¥
        redis_client.ping()

        return {
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "services": {
                "redis": "connected",
                "api": "running"
            }
        }
    except Exception as e:
        raise HTTPException(
            status_code=503,
            detail=f"Service unhealthy: {str(e)}"
        )


# â€¹6â€º ä¸»è¦èŠå¤©ç«¯é»
@app.post("/api/v1/chat", response_model=ChatResponse)
async def chat(
    request: ChatRequest,
    api_key: str = Depends(verify_api_key)
):
    """
    èŠå¤©ç«¯é»

    æµç¨‹ï¼š
    1. èªè­‰ âœ“
    2. é™æµ
    3. è·¯ç”±åˆ°å°æ‡‰çš„ Agent æœå‹™
    4. è¿”å›å›æ‡‰
    """
    start_time = time.time()

    # é™æµæª¢æŸ¥
    await rate_limiter(request.user_id)

    # â€¹7â€º æª¢æŸ¥å¿«å–
    cache_key = f"chat:{request.session_id}:{hash(request.message)}"
    cached_response = redis_client.get(cache_key)

    if cached_response:
        # å¿«å–å‘½ä¸­
        import json
        response_data = json.loads(cached_response)
        response_data['from_cache'] = True
        return ChatResponse(**response_data)

    # â€¹8â€º è·¯ç”±åˆ° Router Agent æœå‹™
    # é€™è£¡ä½¿ç”¨ HTTP å‘¼å«å…§éƒ¨æœå‹™
    import httpx

    try:
        async with httpx.AsyncClient() as client:
            router_response = await client.post(
                "http://router-agent:8001/route",
                json={
                    "session_id": request.session_id,
                    "message": request.message,
                    "user_id": request.user_id,
                    "metadata": request.metadata
                },
                timeout=30.0
            )

            if router_response.status_code != 200:
                raise HTTPException(
                    status_code=502,
                    detail="Router Agent error"
                )

            result = router_response.json()

    except httpx.TimeoutException:
        raise HTTPException(
            status_code=504,
            detail="Request timeout"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Internal error: {str(e)}"
        )

    # â€¹9â€º å»ºç«‹å›æ‡‰
    response_time = int((time.time() - start_time) * 1000)

    response = ChatResponse(
        session_id=request.session_id,
        message=result['message'],
        agent_type=result['agent_type'],
        timestamp=datetime.utcnow().isoformat(),
        response_time_ms=response_time
    )

    # â€¹10â€º å¿«å–å›æ‡‰ï¼ˆ5 åˆ†é˜ï¼‰
    import json
    redis_client.setex(
        cache_key,
        300,  # 5 åˆ†é˜
        json.dumps(response.dict())
    )

    return response


# â€¹11â€º æœƒè©±ç®¡ç†ç«¯é»
@app.get("/api/v1/session/{session_id}/history")
async def get_session_history(
    session_id: str,
    api_key: str = Depends(verify_api_key)
):
    """ç²å–æœƒè©±æ­·å²"""
    # å¾ Redis æˆ–è³‡æ–™åº«è®€å–æœƒè©±æ­·å²
    history_key = f"session:{session_id}:history"
    history = redis_client.lrange(history_key, 0, -1)

    import json
    return {
        "session_id": session_id,
        "history": [json.loads(msg) for msg in history]
    }


@app.delete("/api/v1/session/{session_id}")
async def clear_session(
    session_id: str,
    api_key: str = Depends(verify_api_key)
):
    """æ¸…é™¤æœƒè©±"""
    redis_client.delete(f"session:{session_id}:history")
    return {"status": "cleared"}


if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True  # é–‹ç™¼æ¨¡å¼
    )
```

### 7.3.2 è·¯ç”± Agent å¯¦ä½œ

Router Agent è² è²¬æ„åœ–è­˜åˆ¥ä¸¦è·¯ç”±åˆ°æ­£ç¢ºçš„å°ˆæ¥­ Agentã€‚

**agents/router_agent.py**:
```python
from anthropic import Anthropic
from typing import Dict, List
import os
import httpx
import json


class RouterAgent:
    """
    â€¹1â€º è·¯ç”± Agent - æ„åœ–è­˜åˆ¥èˆ‡è«‹æ±‚åˆ†ç™¼

    è·è²¬ï¼š
    1. åˆ†æç”¨æˆ¶è¨Šæ¯
    2. è­˜åˆ¥æ„åœ–ï¼ˆFAQã€è¨‚å–®ã€é€€æ¬¾ã€æŠ€è¡“æ”¯æ´ï¼‰
    3. è·¯ç”±åˆ°å°æ‡‰çš„å°ˆæ¥­ Agent
    4. è™•ç†å¤šæ„åœ–æƒ…æ³
    """

    # â€¹2â€º Agent è·¯ç”±æ˜ å°„
    AGENT_ROUTES = {
        "faq": "http://faq-agent:8002/handle",
        "order": "http://order-agent:8003/handle",
        "refund": "http://refund-agent:8004/handle",
        "technical": "http://technical-agent:8005/handle",
        "human": "http://human-handoff:8006/escalate"
    }

    def __init__(self, api_key: str):
        self.client = Anthropic(api_key=api_key)
        self.model = "claude-3-5-sonnet-20241022"

    async def route(self, session_id: str, message: str, user_id: str, metadata: Dict) -> Dict:
        """
        â€¹3â€º è·¯ç”±è«‹æ±‚åˆ°å°æ‡‰çš„ Agent

        Args:
            session_id: æœƒè©± ID
            message: ç”¨æˆ¶è¨Šæ¯
            user_id: ç”¨æˆ¶ ID
            metadata: é¡å¤–å…ƒè³‡æ–™

        Returns:
            {
                "message": "å›æ‡‰å…§å®¹",
                "agent_type": "è™•ç†çš„ Agent é¡å‹",
                "confidence": 0.95
            }
        """
        # æ­¥é©Ÿ 1: è­˜åˆ¥æ„åœ–
        intent = await self._identify_intent(message, metadata)

        # æ­¥é©Ÿ 2: è·¯ç”±åˆ°å°æ‡‰çš„ Agent
        agent_url = self.AGENT_ROUTES.get(intent['type'])

        if not agent_url:
            # é è¨­è·¯ç”±åˆ° FAQ Agent
            agent_url = self.AGENT_ROUTES['faq']
            intent['type'] = 'faq'

        # æ­¥é©Ÿ 3: å‘¼å«å°ˆæ¥­ Agent
        response = await self._call_agent(
            agent_url,
            session_id=session_id,
            message=message,
            user_id=user_id,
            metadata=metadata,
            intent=intent
        )

        response['agent_type'] = intent['type']
        return response

    async def _identify_intent(self, message: str, metadata: Dict) -> Dict:
        """
        â€¹4â€º ä½¿ç”¨ Claude è­˜åˆ¥æ„åœ–

        Returns:
            {
                "type": "faq/order/refund/technical/human",
                "confidence": 0.95,
                "entities": {...}
            }
        """
        prompt = f"""åˆ†æä»¥ä¸‹å®¢æˆ¶è¨Šæ¯ï¼Œè­˜åˆ¥æ„åœ–ä¸¦æå–é—œéµè³‡è¨Šã€‚

å®¢æˆ¶è¨Šæ¯ï¼š
{message}

æƒ…å¢ƒè³‡è¨Šï¼š
{json.dumps(metadata, ensure_ascii=False, indent=2)}

æ„åœ–åˆ†é¡ï¼š
1. faq - å¸¸è¦‹å•é¡ŒæŸ¥è©¢ï¼ˆç”¢å“è³‡è¨Šã€ä½¿ç”¨æ–¹æ³•ã€æ”¿ç­–ç­‰ï¼‰
2. order - è¨‚å–®ç›¸é—œï¼ˆæŸ¥è©¢è¨‚å–®ã€ä¿®æ”¹åœ°å€ã€å–æ¶ˆè¨‚å–®ç­‰ï¼‰
3. refund - é€€æ¬¾ç”³è«‹ï¼ˆé€€è²¨ã€é€€æ¬¾ã€æ›è²¨ç­‰ï¼‰
4. technical - æŠ€è¡“æ”¯æ´ï¼ˆç„¡æ³•ç™»å…¥ã€åŠŸèƒ½æ•…éšœã€å ±éŒ¯ç­‰ï¼‰
5. human - éœ€è¦äººå·¥å®¢æœï¼ˆè¤‡é›œå•é¡Œã€æŠ•è¨´ç­‰ï¼‰

è«‹ä»¥ JSON æ ¼å¼å›è¦†ï¼š
{{
    "type": "æ„åœ–é¡å‹",
    "confidence": 0.95,
    "entities": {{
        "order_id": "è¨‚å–®ç·¨è™Ÿï¼ˆå¦‚æœæœ‰ï¼‰",
        "product_name": "ç”¢å“åç¨±ï¼ˆå¦‚æœæœ‰ï¼‰",
        ...
    }},
    "reasoning": "åˆ¤æ–·ç†ç”±"
}}

åªå›è¦† JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚"""

        response = self.client.messages.create(
            model=self.model,
            max_tokens=1024,
            temperature=0.3,  # è¼ƒä½çš„æº«åº¦ç¢ºä¿ä¸€è‡´æ€§
            messages=[{"role": "user", "content": prompt}]
        )

        # è§£æå›æ‡‰
        try:
            intent_data = json.loads(response.content[0].text)
            return intent_data
        except json.JSONDecodeError:
            # è§£æå¤±æ•—ï¼Œé è¨­ç‚º FAQ
            return {
                "type": "faq",
                "confidence": 0.5,
                "entities": {},
                "reasoning": "è§£æå¤±æ•—ï¼Œä½¿ç”¨é è¨­æ„åœ–"
            }

    async def _call_agent(
        self,
        agent_url: str,
        session_id: str,
        message: str,
        user_id: str,
        metadata: Dict,
        intent: Dict
    ) -> Dict:
        """
        â€¹5â€º å‘¼å«å°ˆæ¥­ Agent æœå‹™
        """
        async with httpx.AsyncClient() as client:
            try:
                response = await client.post(
                    agent_url,
                    json={
                        "session_id": session_id,
                        "message": message,
                        "user_id": user_id,
                        "metadata": metadata,
                        "intent": intent
                    },
                    timeout=25.0  # çµ¦å°ˆæ¥­ Agent 25 ç§’è™•ç†æ™‚é–“
                )

                if response.status_code == 200:
                    return response.json()
                else:
                    # Agent éŒ¯èª¤ï¼Œè¿”å›å‹å–„è¨Šæ¯
                    return {
                        "message": "æŠ±æ­‰ï¼Œç›®å‰ç³»çµ±ç¹å¿™ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚",
                        "error": True
                    }

            except httpx.TimeoutException:
                return {
                    "message": "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„è«‹æ±‚æ™‚è¶…æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚",
                    "error": True
                }
            except Exception as e:
                return {
                    "message": "æŠ±æ­‰ï¼Œç™¼ç”Ÿäº†æœªé æœŸçš„éŒ¯èª¤ã€‚",
                    "error": True,
                    "error_detail": str(e)
                }


# â€¹6â€º FastAPI æœå‹™åŒ…è£
from fastapi import FastAPI
from pydantic import BaseModel

router_app = FastAPI(title="Router Agent Service")

router_agent = RouterAgent(api_key=os.getenv("ANTHROPIC_API_KEY"))


class RouteRequest(BaseModel):
    session_id: str
    message: str
    user_id: str
    metadata: dict = {}


@router_app.post("/route")
async def route_request(request: RouteRequest):
    """è·¯ç”±ç«¯é»"""
    result = await router_agent.route(
        session_id=request.session_id,
        message=request.message,
        user_id=request.user_id,
        metadata=request.metadata
    )
    return result


@router_app.get("/health")
async def health():
    return {"status": "healthy"}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(router_app, host="0.0.0.0", port=8001)
```

### 7.3.3 å°ˆæ¥­ Agent ç¯„ä¾‹ï¼šFAQ Agent

**agents/faq_agent.py**:
```python
from anthropic import Anthropic
from typing import Dict, List
import os
import asyncpg
import redis.asyncio as aioredis
from datetime import datetime


class FAQAgent:
    """
    â€¹1â€º FAQ Agent - è™•ç†å¸¸è¦‹å•é¡ŒæŸ¥è©¢

    ç‰¹è‰²ï¼š
    1. ä½¿ç”¨ Elasticsearch é€²è¡Œèªç¾©æœå°‹
    2. Redis å¿«å–ç†±é–€å•é¡Œ
    3. è¨˜éŒ„æŸ¥è©¢çµ±è¨ˆ
    """

    def __init__(self, api_key: str, db_pool, redis_client):
        self.client = Anthropic(api_key=api_key)
        self.model = "claude-3-haiku-20240307"  # ä½¿ç”¨å¿«é€Ÿæ¨¡å‹
        self.db_pool = db_pool
        self.redis = redis_client

    async def handle(
        self,
        session_id: str,
        message: str,
        user_id: str,
        metadata: Dict,
        intent: Dict
    ) -> Dict:
        """
        â€¹2â€º è™•ç† FAQ æŸ¥è©¢

        æµç¨‹ï¼š
        1. æª¢æŸ¥å¿«å–
        2. æœå°‹ FAQ è³‡æ–™åº«
        3. ä½¿ç”¨ Claude ç”Ÿæˆå‹å–„å›è¦†
        4. æ›´æ–°å¿«å–å’Œçµ±è¨ˆ
        """
        # æ­¥é©Ÿ 1: æª¢æŸ¥å¿«å–
        cache_key = f"faq:{hash(message)}"
        cached = await self.redis.get(cache_key)

        if cached:
            return {
                "message": cached.decode('utf-8'),
                "from_cache": True
            }

        # æ­¥é©Ÿ 2: æœå°‹ç›¸é—œ FAQ
        faqs = await self._search_faqs(message)

        if not faqs:
            return {
                "message": "æŠ±æ­‰ï¼Œæˆ‘æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„ç­”æ¡ˆã€‚æ‚¨å¯ä»¥æ›´è©³ç´°åœ°æè¿°æ‚¨çš„å•é¡Œï¼Œæˆ–è€…æˆ‘å¯ä»¥ç‚ºæ‚¨è½‰æ¥äººå·¥å®¢æœã€‚"
            }

        # æ­¥é©Ÿ 3: ä½¿ç”¨ Claude ç”Ÿæˆå›è¦†
        response = await self._generate_response(message, faqs)

        # æ­¥é©Ÿ 4: å¿«å–å›è¦†ï¼ˆ1 å°æ™‚ï¼‰
        await self.redis.setex(cache_key, 3600, response)

        # æ­¥é©Ÿ 5: è¨˜éŒ„çµ±è¨ˆ
        await self._log_query(user_id, message, faqs[0]['id'])

        return {
            "message": response,
            "matched_faqs": [faq['id'] for faq in faqs],
            "from_cache": False
        }

    async def _search_faqs(self, query: str) -> List[Dict]:
        """
        â€¹3â€º æœå°‹ FAQ è³‡æ–™åº«

        ä½¿ç”¨ PostgreSQL çš„å…¨æ–‡æœå°‹åŠŸèƒ½
        ï¼ˆç”Ÿç”¢ç’°å¢ƒæ‡‰ä½¿ç”¨ Elasticsearchï¼‰
        """
        async with self.db_pool.acquire() as conn:
            rows = await conn.fetch("""
                SELECT
                    id,
                    question,
                    answer,
                    category,
                    ts_rank(search_vector, plainto_tsquery('english', $1)) AS rank
                FROM faqs
                WHERE search_vector @@ plainto_tsquery('english', $1)
                ORDER BY rank DESC
                LIMIT 3
            """, query)

            return [dict(row) for row in rows]

    async def _generate_response(self, query: str, faqs: List[Dict]) -> str:
        """
        â€¹4â€º ä½¿ç”¨ Claude ç”Ÿæˆå‹å–„å›è¦†
        """
        faq_context = "\n\n".join([
            f"å•é¡Œï¼š{faq['question']}\nç­”æ¡ˆï¼š{faq['answer']}"
            for faq in faqs
        ])

        prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­ä¸”å‹å–„çš„å®¢æœäººå“¡ã€‚åŸºæ–¼ä»¥ä¸‹ FAQ è³‡æ–™åº«å…§å®¹ï¼Œå›ç­”å®¢æˆ¶çš„å•é¡Œã€‚

å®¢æˆ¶å•é¡Œï¼š
{query}

ç›¸é—œ FAQï¼š
{faq_context}

è¦æ±‚ï¼š
1. ç”¨å‹å–„ã€å°ˆæ¥­çš„èªæ°£å›ç­”
2. å¦‚æœ FAQ å®Œå…¨åŒ¹é…ï¼Œç›´æ¥ä½¿ç”¨ FAQ çš„ç­”æ¡ˆ
3. å¦‚æœéƒ¨åˆ†åŒ¹é…ï¼Œç¶œåˆç›¸é—œ FAQ å›ç­”
4. ä¿æŒç°¡æ½”ï¼Œé¿å…å†—é•·
5. å¦‚æœéœ€è¦ï¼Œæä¾›é¡å¤–çš„å»ºè­°

è«‹ç›´æ¥å›ç­”ï¼Œä¸è¦é‡è¤‡å•é¡Œã€‚"""

        response = self.client.messages.create(
            model=self.model,
            max_tokens=512,
            messages=[{"role": "user", "content": prompt}]
        )

        return response.content[0].text

    async def _log_query(self, user_id: str, query: str, matched_faq_id: int):
        """â€¹5â€º è¨˜éŒ„æŸ¥è©¢çµ±è¨ˆï¼ˆç”¨æ–¼åˆ†æå’Œæ”¹é€²ï¼‰"""
        async with self.db_pool.acquire() as conn:
            await conn.execute("""
                INSERT INTO faq_queries (user_id, query, matched_faq_id, created_at)
                VALUES ($1, $2, $3, $4)
            """, user_id, query, matched_faq_id, datetime.utcnow())


# â€¹6â€º FastAPI æœå‹™
from fastapi import FastAPI
from pydantic import BaseModel

faq_app = FastAPI(title="FAQ Agent Service")

# åˆå§‹åŒ–è³‡æ–™åº«é€£æ¥æ± ï¼ˆå•Ÿå‹•æ™‚åŸ·è¡Œï¼‰
db_pool = None
redis_client = None


@faq_app.on_event("startup")
async def startup():
    global db_pool, redis_client

    # å»ºç«‹è³‡æ–™åº«é€£æ¥æ± 
    db_pool = await asyncpg.create_pool(
        host=os.getenv("DB_HOST", "localhost"),
        port=int(os.getenv("DB_PORT", 5432)),
        user=os.getenv("DB_USER", "postgres"),
        password=os.getenv("DB_PASSWORD"),
        database=os.getenv("DB_NAME", "support_platform"),
        min_size=5,
        max_size=20
    )

    # å»ºç«‹ Redis é€£æ¥
    redis_client = await aioredis.from_url(
        f"redis://{os.getenv('REDIS_HOST', 'localhost')}:6379"
    )


@faq_app.on_event("shutdown")
async def shutdown():
    await db_pool.close()
    await redis_client.close()


faq_agent = None


class HandleRequest(BaseModel):
    session_id: str
    message: str
    user_id: str
    metadata: dict = {}
    intent: dict = {}


@faq_app.post("/handle")
async def handle_request(request: HandleRequest):
    """FAQ è™•ç†ç«¯é»"""
    global faq_agent

    if faq_agent is None:
        faq_agent = FAQAgent(
            api_key=os.getenv("ANTHROPIC_API_KEY"),
            db_pool=db_pool,
            redis_client=redis_client
        )

    result = await faq_agent.handle(
        session_id=request.session_id,
        message=request.message,
        user_id=request.user_id,
        metadata=request.metadata,
        intent=request.intent
    )

    return result


@faq_app.get("/health")
async def health():
    try:
        # æª¢æŸ¥è³‡æ–™åº«é€£æ¥
        async with db_pool.acquire() as conn:
            await conn.fetchval("SELECT 1")

        # æª¢æŸ¥ Redis é€£æ¥
        await redis_client.ping()

        return {"status": "healthy"}
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(faq_app, host="0.0.0.0", port=8002)
```

---

## 7.4 è³‡æ–™åº«è¨­è¨ˆ

### 7.4.1 è³‡æ–™åº«æ¶æ§‹

**database/schema.sql**:
```sql
-- â€¹1â€º FAQs è¡¨
CREATE TABLE faqs (
    id SERIAL PRIMARY KEY,
    question TEXT NOT NULL,
    answer TEXT NOT NULL,
    category VARCHAR(50),
    keywords TEXT[],
    view_count INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    -- å…¨æ–‡æœå°‹ç´¢å¼•
    search_vector tsvector GENERATED ALWAYS AS (
        setweight(to_tsvector('english', question), 'A') ||
        setweight(to_tsvector('english', answer), 'B') ||
        setweight(to_tsvector('english', COALESCE(array_to_string(keywords, ' '), '')), 'C')
    ) STORED
);

CREATE INDEX idx_faqs_search ON faqs USING GIN(search_vector);
CREATE INDEX idx_faqs_category ON faqs(category);

-- â€¹2â€º ç”¨æˆ¶è¡¨
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    name VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW(),
    last_active_at TIMESTAMP
);

-- â€¹3â€º æœƒè©±è¡¨
CREATE TABLE sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    status VARCHAR(20) DEFAULT 'active', -- active, closed, escalated
    assigned_agent VARCHAR(50), -- æœ€å¾Œè™•ç†çš„ Agent
    metadata JSONB
);

CREATE INDEX idx_sessions_user ON sessions(user_id);
CREATE INDEX idx_sessions_status ON sessions(status);

-- â€¹4â€º è¨Šæ¯è¡¨
CREATE TABLE messages (
    id BIGSERIAL PRIMARY KEY,
    session_id UUID REFERENCES sessions(id),
    sender VARCHAR(20) NOT NULL, -- user, agent, system
    agent_type VARCHAR(50), -- faq, order, refund, etc.
    content TEXT NOT NULL,
    intent_data JSONB, -- æ„åœ–è­˜åˆ¥çµæœ
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_messages_session ON messages(session_id);
CREATE INDEX idx_messages_created ON messages(created_at DESC);

-- â€¹5â€º FAQ æŸ¥è©¢çµ±è¨ˆè¡¨
CREATE TABLE faq_queries (
    id BIGSERIAL PRIMARY KEY,
    user_id UUID REFERENCES users(id),
    query TEXT NOT NULL,
    matched_faq_id INTEGER REFERENCES faqs(id),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_faq_queries_user ON faq_queries(user_id);
CREATE INDEX idx_faq_queries_faq ON faq_queries(matched_faq_id);
CREATE INDEX idx_faq_queries_created ON faq_queries(created_at DESC);

-- â€¹6â€º Agent æ•ˆèƒ½æŒ‡æ¨™è¡¨
CREATE TABLE agent_metrics (
    id BIGSERIAL PRIMARY KEY,
    agent_type VARCHAR(50) NOT NULL,
    session_id UUID,
    response_time_ms INTEGER,
    success BOOLEAN,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_metrics_agent ON agent_metrics(agent_type);
CREATE INDEX idx_metrics_created ON agent_metrics(created_at DESC);

-- â€¹7â€º åˆå§‹åŒ–ä¸€äº› FAQ è³‡æ–™
INSERT INTO faqs (question, answer, category, keywords) VALUES
('å¦‚ä½•è¿½è¹¤æˆ‘çš„è¨‚å–®ï¼Ÿ', 'æ‚¨å¯ä»¥åœ¨ã€Œæˆ‘çš„è¨‚å–®ã€é é¢è¼¸å…¥è¨‚å–®ç·¨è™Ÿä¾†è¿½è¹¤ç‰©æµç‹€æ…‹ã€‚æˆ‘å€‘ä¹Ÿæœƒé€šééƒµä»¶å’Œç°¡è¨Šç™¼é€æ›´æ–°é€šçŸ¥ã€‚', 'order', ARRAY['è¨‚å–®', 'è¿½è¹¤', 'ç‰©æµ']),
('é€€è²¨æ”¿ç­–æ˜¯ä»€éº¼ï¼Ÿ', 'æˆ‘å€‘æä¾› 30 å¤©ç„¡ç†ç”±é€€è²¨æœå‹™ã€‚å•†å“éœ€ä¿æŒåŸåŒ…è£ä¸”æœªä½¿ç”¨ã€‚è«‹è¯ç¹«å®¢æœç”³è«‹é€€è²¨æˆæ¬Šã€‚', 'refund', ARRAY['é€€è²¨', 'é€€æ¬¾', 'æ”¿ç­–']),
('å¦‚ä½•ä¿®æ”¹è¨‚å–®åœ°å€ï¼Ÿ', 'å¦‚æœè¨‚å–®å°šæœªç™¼è²¨ï¼Œæ‚¨å¯ä»¥åœ¨ã€Œæˆ‘çš„è¨‚å–®ã€ä¸­ä¿®æ”¹æ”¶è²¨åœ°å€ã€‚å¦‚å·²ç™¼è²¨ï¼Œè«‹è¯ç¹«å®¢æœå”åŠ©è™•ç†ã€‚', 'order', ARRAY['è¨‚å–®', 'åœ°å€', 'ä¿®æ”¹']),
('æ”¯æ´å“ªäº›ä»˜æ¬¾æ–¹å¼ï¼Ÿ', 'æˆ‘å€‘æ”¯æ´ä¿¡ç”¨å¡ã€PayPalã€Apple Pay å’Œ Google Payã€‚æ‰€æœ‰äº¤æ˜“éƒ½ç¶“éåŠ å¯†è™•ç†ï¼Œç¢ºä¿å®‰å…¨ã€‚', 'payment', ARRAY['ä»˜æ¬¾', 'æ”¯ä»˜', 'ä¿¡ç”¨å¡']),
('å¦‚ä½•é‡è¨­å¯†ç¢¼ï¼Ÿ', 'åœ¨ç™»å…¥é é¢é»æ“Šã€Œå¿˜è¨˜å¯†ç¢¼ã€ï¼Œè¼¸å…¥æ‚¨çš„éƒµç®±ï¼Œæˆ‘å€‘æœƒç™¼é€é‡è¨­é€£çµçµ¦æ‚¨ã€‚', 'account', ARRAY['å¯†ç¢¼', 'é‡è¨­', 'ç™»å…¥']);
```

### 7.4.2 è³‡æ–™åº«å„ªåŒ–ç­–ç•¥

**1. é€£æ¥æ± ç®¡ç†**
```python
# â€¹1â€º ä½¿ç”¨é€£æ¥æ± é¿å…é »ç¹å»ºç«‹é€£æ¥
import asyncpg

async def create_db_pool():
    return await asyncpg.create_pool(
        host='localhost',
        port=5432,
        user='postgres',
        password='password',
        database='support_platform',
        min_size=5,    # æœ€å°é€£æ¥æ•¸
        max_size=20,   # æœ€å¤§é€£æ¥æ•¸
        max_queries=50000,  # æ¯å€‹é€£æ¥æœ€å¤šåŸ·è¡Œçš„æŸ¥è©¢æ•¸
        max_inactive_connection_lifetime=300  # 5 åˆ†é˜æœªä½¿ç”¨å‰‡é—œé–‰
    )

# â€¹2â€º ä½¿ç”¨é€£æ¥æ± åŸ·è¡ŒæŸ¥è©¢
async def get_user(pool, user_id):
    async with pool.acquire() as conn:
        return await conn.fetchrow(
            "SELECT * FROM users WHERE id = $1",
            user_id
        )
```

**2. æŸ¥è©¢å„ªåŒ–**
```sql
-- â€¹1â€º ä½¿ç”¨ EXPLAIN ANALYZE åˆ†ææŸ¥è©¢
EXPLAIN ANALYZE
SELECT * FROM messages
WHERE session_id = 'some-uuid'
ORDER BY created_at DESC
LIMIT 50;

-- â€¹2â€º æ·»åŠ é©ç•¶çš„ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_messages_session_created
ON messages(session_id, created_at DESC);

-- â€¹3â€º ä½¿ç”¨éƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•æ´»èºæœƒè©±ï¼‰
CREATE INDEX idx_active_sessions
ON sessions(user_id)
WHERE status = 'active';

-- â€¹4â€º ä½¿ç”¨ç‰©åŒ–è¦–åœ–ï¼ˆMaterialized Viewsï¼‰å¿«å–è¤‡é›œæŸ¥è©¢
CREATE MATERIALIZED VIEW popular_faqs AS
SELECT
    f.id,
    f.question,
    f.category,
    COUNT(fq.id) AS query_count
FROM faqs f
LEFT JOIN faq_queries fq ON f.id = fq.matched_faq_id
WHERE fq.created_at > NOW() - INTERVAL '7 days'
GROUP BY f.id, f.question, f.category
ORDER BY query_count DESC
LIMIT 100;

-- æ¯å°æ™‚åˆ·æ–°ä¸€æ¬¡
CREATE INDEX idx_popular_faqs_count ON popular_faqs(query_count DESC);

-- è¨­å®šè‡ªå‹•åˆ·æ–°ï¼ˆä½¿ç”¨ pg_cronï¼‰
SELECT cron.schedule('refresh_popular_faqs', '0 * * * *',
    'REFRESH MATERIALIZED VIEW CONCURRENTLY popular_faqs');
```

**3. åˆ†å€ç­–ç•¥ï¼ˆPartitioningï¼‰**
```sql
-- â€¹1â€º å°å¤§è¡¨é€²è¡Œåˆ†å€ï¼ˆmessages è¡¨æŒ‰æœˆåˆ†å€ï¼‰
CREATE TABLE messages (
    id BIGSERIAL,
    session_id UUID NOT NULL,
    sender VARCHAR(20) NOT NULL,
    content TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    PRIMARY KEY (id, created_at)
) PARTITION BY RANGE (created_at);

-- å»ºç«‹åˆ†å€
CREATE TABLE messages_2025_01 PARTITION OF messages
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE messages_2025_02 PARTITION OF messages
    FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

-- è‡ªå‹•å»ºç«‹æœªä¾†åˆ†å€çš„å‡½æ•¸
CREATE OR REPLACE FUNCTION create_monthly_partitions()
RETURNS void AS $$
DECLARE
    start_date DATE;
    end_date DATE;
    partition_name TEXT;
BEGIN
    start_date := DATE_TRUNC('month', NOW());

    FOR i IN 0..11 LOOP  -- å»ºç«‹æœªä¾† 12 å€‹æœˆçš„åˆ†å€
        end_date := start_date + INTERVAL '1 month';
        partition_name := 'messages_' || TO_CHAR(start_date, 'YYYY_MM');

        EXECUTE format(
            'CREATE TABLE IF NOT EXISTS %I PARTITION OF messages FOR VALUES FROM (%L) TO (%L)',
            partition_name,
            start_date,
            end_date
        );

        start_date := end_date;
    END LOOP;
END;
$$ LANGUAGE plpgsql;
```

---

## 7.5 å¿«å–ç­–ç•¥

### 7.5.1 å¤šå±¤æ¬¡å¿«å–æ¶æ§‹

```mermaid
graph LR
    A[è«‹æ±‚] --> B{L1: è¨˜æ†¶é«”å¿«å–}
    B -->|å‘½ä¸­| Z[è¿”å›çµæœ]
    B -->|æœªå‘½ä¸­| C{L2: Redis å¿«å–}
    C -->|å‘½ä¸­| Z
    C -->|æœªå‘½ä¸­| D{L3: è³‡æ–™åº«æŸ¥è©¢å¿«å–}
    D -->|å‘½ä¸­| Z
    D -->|æœªå‘½ä¸­| E[è³‡æ–™åº«æŸ¥è©¢]
    E --> F[æ›´æ–°æ‰€æœ‰å¿«å–å±¤]
    F --> Z

    style B fill:#f9f,stroke:#333
    style C fill:#bbf,stroke:#333
    style D fill:#bfb,stroke:#333
    style E fill:#ffb,stroke:#333
```

### 7.5.2 Redis å¿«å–å¯¦ä½œ

**cache/redis_cache.py**:
```python
import redis.asyncio as aioredis
import json
import hashlib
from typing import Any, Optional
from datetime import timedelta


class RedisCache:
    """
    â€¹1â€º Redis å¿«å–ç®¡ç†å™¨

    ç‰¹è‰²ï¼š
    1. è‡ªå‹•åºåˆ—åŒ–/ååºåˆ—åŒ–
    2. TTL ç®¡ç†
    3. å¿«å–é ç†±
    4. å¿«å–å¤±æ•ˆç­–ç•¥
    """

    def __init__(self, redis_url: str):
        self.redis = aioredis.from_url(redis_url)

    async def get(self, key: str) -> Optional[Any]:
        """
        â€¹2â€º ç²å–å¿«å–å€¼
        """
        value = await self.redis.get(key)
        if value:
            return json.loads(value)
        return None

    async def set(
        self,
        key: str,
        value: Any,
        ttl: int = 3600  # é è¨­ 1 å°æ™‚
    ):
        """
        â€¹3â€º è¨­å®šå¿«å–å€¼
        """
        serialized = json.dumps(value, ensure_ascii=False)
        await self.redis.setex(key, ttl, serialized)

    async def delete(self, key: str):
        """åˆªé™¤å¿«å–"""
        await self.redis.delete(key)

    async def exists(self, key: str) -> bool:
        """æª¢æŸ¥å¿«å–æ˜¯å¦å­˜åœ¨"""
        return await self.redis.exists(key) > 0

    async def get_many(self, keys: list[str]) -> dict:
        """
        â€¹4â€º æ‰¹é‡ç²å–å¿«å–

        æ•ˆèƒ½å„ªåŒ–ï¼šä¸€æ¬¡ç²å–å¤šå€‹ key
        """
        if not keys:
            return {}

        values = await self.redis.mget(keys)
        return {
            key: json.loads(value) if value else None
            for key, value in zip(keys, values)
        }

    async def set_many(
        self,
        mapping: dict[str, Any],
        ttl: int = 3600
    ):
        """
        â€¹5â€º æ‰¹é‡è¨­å®šå¿«å–
        """
        pipe = self.redis.pipeline()
        for key, value in mapping.items():
            serialized = json.dumps(value, ensure_ascii=False)
            pipe.setex(key, ttl, serialized)
        await pipe.execute()

    def generate_key(self, prefix: str, *args, **kwargs) -> str:
        """
        â€¹6â€º ç”Ÿæˆå¿«å– key

        ä½¿ç”¨ hash ç¢ºä¿ key é•·åº¦ä¸€è‡´
        """
        parts = [prefix] + [str(arg) for arg in args]
        if kwargs:
            parts.append(json.dumps(kwargs, sort_keys=True))

        key_string = ":".join(parts)
        return f"{prefix}:{hashlib.md5(key_string.encode()).hexdigest()}"

    async def invalidate_pattern(self, pattern: str):
        """
        â€¹7â€º åŸºæ–¼æ¨¡å¼å¤±æ•ˆå¿«å–

        ä¾‹å¦‚ï¼šinvalidate_pattern("session:user123:*")
        æœƒåˆªé™¤è©²ç”¨æˆ¶çš„æ‰€æœ‰æœƒè©±å¿«å–
        """
        cursor = 0
        while True:
            cursor, keys = await self.redis.scan(
                cursor=cursor,
                match=pattern,
                count=100
            )

            if keys:
                await self.redis.delete(*keys)

            if cursor == 0:
                break


# â€¹8â€º å¿«å–è£é£¾å™¨
from functools import wraps

def cache_result(
    cache: RedisCache,
    ttl: int = 3600,
    key_prefix: str = "cache"
):
    """
    å¿«å–å‡½æ•¸çµæœçš„è£é£¾å™¨

    ä½¿ç”¨ç¯„ä¾‹ï¼š
    @cache_result(redis_cache, ttl=300, key_prefix="faq")
    async def get_faq(faq_id: int):
        return await db.fetch_faq(faq_id)
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆå¿«å– key
            cache_key = cache.generate_key(
                key_prefix,
                func.__name__,
                *args,
                **kwargs
            )

            # æª¢æŸ¥å¿«å–
            cached = await cache.get(cache_key)
            if cached is not None:
                return cached

            # åŸ·è¡Œå‡½æ•¸
            result = await func(*args, **kwargs)

            # å„²å­˜åˆ°å¿«å–
            await cache.set(cache_key, result, ttl)

            return result

        return wrapper
    return decorator
```

### 7.5.3 å¿«å–é ç†±ç­–ç•¥

**cache/cache_warmer.py**:
```python
import asyncio
from typing import List


class CacheWarmer:
    """
    â€¹1â€º å¿«å–é ç†±å™¨

    åœ¨ç³»çµ±å•Ÿå‹•æˆ–ä½å³°æœŸé å…ˆè¼‰å…¥ç†±é–€è³‡æ–™åˆ°å¿«å–
    """

    def __init__(self, cache: RedisCache, db_pool):
        self.cache = cache
        self.db_pool = db_pool

    async def warm_popular_faqs(self):
        """
        â€¹2â€º é ç†±ç†±é–€ FAQ
        """
        print("é–‹å§‹é ç†±ç†±é–€ FAQ...")

        async with self.db_pool.acquire() as conn:
            # ç²å–æœ€å¸¸æŸ¥è©¢çš„ FAQ
            popular_faqs = await conn.fetch("""
                SELECT f.*, COUNT(fq.id) AS query_count
                FROM faqs f
                LEFT JOIN faq_queries fq ON f.id = fq.matched_faq_id
                WHERE fq.created_at > NOW() - INTERVAL '7 days'
                GROUP BY f.id
                ORDER BY query_count DESC
                LIMIT 100
            """)

            # æ‰¹é‡å¯«å…¥å¿«å–
            mapping = {
                f"faq:{row['id']}": dict(row)
                for row in popular_faqs
            }

            await self.cache.set_many(mapping, ttl=7200)  # 2 å°æ™‚

            print(f"âœ… å·²é ç†± {len(mapping)} å€‹ç†±é–€ FAQ")

    async def warm_active_sessions(self):
        """
        â€¹3â€º é ç†±æ´»èºæœƒè©±
        """
        print("é–‹å§‹é ç†±æ´»èºæœƒè©±...")

        async with self.db_pool.acquire() as conn:
            # ç²å–æœ€è¿‘æ´»èºçš„æœƒè©±
            active_sessions = await conn.fetch("""
                SELECT s.*,
                       json_agg(
                           json_build_object(
                               'sender', m.sender,
                               'content', m.content,
                               'created_at', m.created_at
                           ) ORDER BY m.created_at DESC
                       ) AS messages
                FROM sessions s
                LEFT JOIN messages m ON s.id = m.session_id
                WHERE s.updated_at > NOW() - INTERVAL '1 hour'
                  AND s.status = 'active'
                GROUP BY s.id
                LIMIT 500
            """)

            mapping = {
                f"session:{row['id']}:history": row['messages']
                for row in active_sessions
            }

            await self.cache.set_many(mapping, ttl=1800)  # 30 åˆ†é˜

            print(f"âœ… å·²é ç†± {len(mapping)} å€‹æ´»èºæœƒè©±")

    async def run_all(self):
        """
        â€¹4â€º åŸ·è¡Œæ‰€æœ‰é ç†±ä»»å‹™
        """
        await asyncio.gather(
            self.warm_popular_faqs(),
            self.warm_active_sessions()
        )
```

---

## 7.6 è² è¼‰å¹³è¡¡èˆ‡è‡ªå‹•æ“´å±•

### 7.6.1 Kubernetes éƒ¨ç½²é…ç½®

**k8s/deployment.yaml**:
```yaml
# â€¹1â€º API Gateway éƒ¨ç½²
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-gateway
  labels:
    app: api-gateway
spec:
  replicas: 3  # 3 å€‹å‰¯æœ¬
  selector:
    matchLabels:
      app: api-gateway
  template:
    metadata:
      labels:
        app: api-gateway
    spec:
      containers:
      - name: gateway
        image: support-platform/api-gateway:latest
        ports:
        - containerPort: 8000
        env:
        - name: REDIS_HOST
          value: "redis-service"
        - name: DB_HOST
          value: "postgres-service"
        - name: ANTHROPIC_API_KEY
          valueFrom:
            secretKeyRef:
              name: api-secrets
              key: anthropic-api-key
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5

---
# â€¹2â€º API Gateway æœå‹™
apiVersion: v1
kind: Service
metadata:
  name: api-gateway
spec:
  type: LoadBalancer
  selector:
    app: api-gateway
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000

---
# â€¹3â€º Router Agent éƒ¨ç½²
apiVersion: apps/v1
kind: Deployment
metadata:
  name: router-agent
spec:
  replicas: 2
  selector:
    matchLabels:
      app: router-agent
  template:
    metadata:
      labels:
        app: router-agent
    spec:
      containers:
      - name: router
        image: support-platform/router-agent:latest
        ports:
        - containerPort: 8001
        env:
        - name: ANTHROPIC_API_KEY
          valueFrom:
            secretKeyRef:
              name: api-secrets
              key: anthropic-api-key
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"

---
# â€¹4â€º Router Agent æœå‹™ï¼ˆå…§éƒ¨ï¼‰
apiVersion: v1
kind: Service
metadata:
  name: router-agent
spec:
  type: ClusterIP  # åªåœ¨é›†ç¾¤å…§éƒ¨è¨ªå•
  selector:
    app: router-agent
  ports:
  - protocol: TCP
    port: 8001
    targetPort: 8001

---
# â€¹5â€º FAQ Agent éƒ¨ç½²ï¼ˆå¸¶è‡ªå‹•æ“´å±•ï¼‰
apiVersion: apps/v1
kind: Deployment
metadata:
  name: faq-agent
spec:
  replicas: 2  # åˆå§‹å‰¯æœ¬æ•¸
  selector:
    matchLabels:
      app: faq-agent
  template:
    metadata:
      labels:
        app: faq-agent
    spec:
      containers:
      - name: faq
        image: support-platform/faq-agent:latest
        ports:
        - containerPort: 8002
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"

---
# â€¹6â€º FAQ Agent æ°´å¹³è‡ªå‹•æ“´å±•
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: faq-agent-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: faq-agent
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # CPU ä½¿ç”¨ç‡è¶…é 70% æ™‚æ“´å±•
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # 5 åˆ†é˜ç©©å®šæœŸ
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30

---
# â€¹7â€º Redis éƒ¨ç½²
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        volumeMounts:
        - name: redis-data
          mountPath: /data
      volumes:
      - name: redis-data
        persistentVolumeClaim:
          claimName: redis-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: redis-service
spec:
  selector:
    app: redis
  ports:
  - protocol: TCP
    port: 6379
    targetPort: 6379

---
# â€¹8â€º PostgreSQL StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: "postgres"
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:15
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          value: "support_platform"
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: username
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 50Gi

---
apiVersion: v1
kind: Service
metadata:
  name: postgres-service
spec:
  selector:
    app: postgres
  ports:
  - protocol: TCP
    port: 5432
    targetPort: 5432
```

### 7.6.2 è² è¼‰æ¸¬è©¦

**tests/load_test.py**:
```python
import asyncio
import httpx
import time
from datetime import datetime
import statistics


class LoadTester:
    """
    â€¹1â€º è² è¼‰æ¸¬è©¦å·¥å…·

    æ¸¬è©¦ç³»çµ±åœ¨é«˜ä¸¦ç™¼ä¸‹çš„è¡¨ç¾
    """

    def __init__(self, base_url: str, api_key: str):
        self.base_url = base_url
        self.api_key = api_key
        self.results = []

    async def single_request(self, client: httpx.AsyncClient, user_id: str):
        """
        â€¹2â€º ç™¼é€å–®ä¸€è«‹æ±‚ä¸¦è¨˜éŒ„çµæœ
        """
        start_time = time.time()

        try:
            response = await client.post(
                f"{self.base_url}/api/v1/chat",
                json={
                    "session_id": f"session_{user_id}",
                    "message": "å¦‚ä½•è¿½è¹¤è¨‚å–®ï¼Ÿ",
                    "user_id": user_id,
                    "metadata": {}
                },
                headers={"X-API-Key": self.api_key},
                timeout=30.0
            )

            duration = (time.time() - start_time) * 1000  # æ¯«ç§’

            return {
                "success": response.status_code == 200,
                "duration_ms": duration,
                "status_code": response.status_code
            }

        except Exception as e:
            duration = (time.time() - start_time) * 1000
            return {
                "success": False,
                "duration_ms": duration,
                "error": str(e)
            }

    async def run_test(
        self,
        concurrent_users: int = 100,
        requests_per_user: int = 10
    ):
        """
        â€¹3â€º åŸ·è¡Œè² è¼‰æ¸¬è©¦

        Args:
            concurrent_users: ä¸¦ç™¼ç”¨æˆ¶æ•¸
            requests_per_user: æ¯å€‹ç”¨æˆ¶ç™¼é€çš„è«‹æ±‚æ•¸
        """
        print(f"é–‹å§‹è² è¼‰æ¸¬è©¦...")
        print(f"ä¸¦ç™¼ç”¨æˆ¶: {concurrent_users}")
        print(f"æ¯ç”¨æˆ¶è«‹æ±‚: {requests_per_user}")
        print(f"ç¸½è«‹æ±‚æ•¸: {concurrent_users * requests_per_user}\n")

        async with httpx.AsyncClient() as client:
            tasks = []

            for user_id in range(concurrent_users):
                for _ in range(requests_per_user):
                    task = self.single_request(client, f"user_{user_id}")
                    tasks.append(task)

            # åŸ·è¡Œæ‰€æœ‰è«‹æ±‚
            test_start = time.time()
            results = await asyncio.gather(*tasks)
            test_duration = time.time() - test_start

        # â€¹4â€º åˆ†æçµæœ
        self._analyze_results(results, test_duration)

    def _analyze_results(self, results: list, total_duration: float):
        """â€¹5â€º åˆ†ææ¸¬è©¦çµæœ"""
        successful = [r for r in results if r['success']]
        failed = [r for r in results if not r['success']]

        if successful:
            durations = [r['duration_ms'] for r in successful]

            print("="*60)
            print("è² è¼‰æ¸¬è©¦çµæœ")
            print("="*60)
            print(f"ç¸½è«‹æ±‚æ•¸:        {len(results)}")
            print(f"æˆåŠŸ:            {len(successful)} ({len(successful)/len(results)*100:.1f}%)")
            print(f"å¤±æ•—:            {len(failed)} ({len(failed)/len(results)*100:.1f}%)")
            print(f"\nç¸½æ¸¬è©¦æ™‚é–“:      {total_duration:.2f} ç§’")
            print(f"ååé‡:          {len(results)/total_duration:.2f} è«‹æ±‚/ç§’")
            print(f"\nå›æ‡‰æ™‚é–“çµ±è¨ˆ (ms):")
            print(f"  æœ€å°:          {min(durations):.2f}")
            print(f"  æœ€å¤§:          {max(durations):.2f}")
            print(f"  å¹³å‡:          {statistics.mean(durations):.2f}")
            print(f"  ä¸­ä½æ•¸:        {statistics.median(durations):.2f}")
            print(f"  P95:           {sorted(durations)[int(len(durations)*0.95)]:.2f}")
            print(f"  P99:           {sorted(durations)[int(len(durations)*0.99)]:.2f}")
            print("="*60)

            # åˆ†æå¤±æ•—åŸå› 
            if failed:
                print("\nå¤±æ•—è«‹æ±‚åˆ†æ:")
                error_types = {}
                for f in failed:
                    error = f.get('error', 'Unknown')
                    error_types[error] = error_types.get(error, 0) + 1

                for error, count in error_types.items():
                    print(f"  {error}: {count}")


# â€¹6â€º åŸ·è¡Œæ¸¬è©¦
async def main():
    tester = LoadTester(
        base_url="http://localhost:8000",
        api_key="your_api_key"
    )

    # æ¸¬è©¦ 1: ä½è² è¼‰
    print("æ¸¬è©¦ 1: ä½è² è¼‰")
    await tester.run_test(concurrent_users=10, requests_per_user=5)
    await asyncio.sleep(5)

    # æ¸¬è©¦ 2: ä¸­è² è¼‰
    print("\næ¸¬è©¦ 2: ä¸­è² è¼‰")
    await tester.run_test(concurrent_users=50, requests_per_user=10)
    await asyncio.sleep(5)

    # æ¸¬è©¦ 3: é«˜è² è¼‰
    print("\næ¸¬è©¦ 3: é«˜è² è¼‰")
    await tester.run_test(concurrent_users=100, requests_per_user=10)


if __name__ == "__main__":
    asyncio.run(main())
```

---

## 7.7 æˆæœ¬å„ªåŒ–ç­–ç•¥

### 7.7.1 æ¨¡å‹é¸æ“‡ç­–ç•¥

```python
class ModelSelector:
    """
    â€¹1â€º æ™ºæ…§æ¨¡å‹é¸æ“‡å™¨

    æ ¹æ“šä»»å‹™è¤‡é›œåº¦é¸æ“‡åˆé©çš„æ¨¡å‹ï¼š
    - Haiku: ç°¡å–®ä»»å‹™ï¼ˆFAQ æŸ¥è©¢ï¼‰
    - Sonnet: ä¸­ç­‰è¤‡é›œåº¦ï¼ˆæ„åœ–è­˜åˆ¥ã€è¨‚å–®è™•ç†ï¼‰
    - Opus: è¤‡é›œä»»å‹™ï¼ˆæŠ€è¡“æ”¯æ´ã€æŠ•è¨´è™•ç†ï¼‰
    """

    MODELS = {
        "haiku": {
            "model_id": "claude-3-haiku-20240307",
            "cost_per_1k_input": 0.00025,
            "cost_per_1k_output": 0.00125,
            "speed": "very_fast"
        },
        "sonnet": {
            "model_id": "claude-3-5-sonnet-20241022",
            "cost_per_1k_input": 0.003,
            "cost_per_1k_output": 0.015,
            "speed": "fast"
        },
        "opus": {
            "model_id": "claude-3-opus-20240229",
            "cost_per_1k_input": 0.015,
            "cost_per_1k_output": 0.075,
            "speed": "normal"
        }
    }

    @staticmethod
    def select_model(task_type: str, complexity: str = "medium") -> dict:
        """
        â€¹2â€º é¸æ“‡åˆé©çš„æ¨¡å‹

        Args:
            task_type: faq, order, refund, technical, human
            complexity: low, medium, high

        Returns:
            æ¨¡å‹é…ç½®
        """
        # ä»»å‹™é¡å‹æ˜ å°„
        task_model_map = {
            "faq": "haiku",      # FAQ æŸ¥è©¢ - ç°¡å–®
            "order": "haiku",    # è¨‚å–®æŸ¥è©¢ - ç°¡å–®
            "refund": "sonnet",  # é€€æ¬¾è™•ç† - ä¸­ç­‰
            "technical": "sonnet", # æŠ€è¡“æ”¯æ´ - ä¸­ç­‰
            "human": "opus"      # éœ€è¦äººå·¥çš„è¤‡é›œå•é¡Œ
        }

        # åŸºæ–¼è¤‡é›œåº¦èª¿æ•´
        base_model = task_model_map.get(task_type, "sonnet")

        if complexity == "high":
            # å‡ç´šæ¨¡å‹
            if base_model == "haiku":
                base_model = "sonnet"
            elif base_model == "sonnet":
                base_model = "opus"
        elif complexity == "low":
            # é™ç´šæ¨¡å‹
            if base_model == "opus":
                base_model = "sonnet"
            elif base_model == "sonnet":
                base_model = "haiku"

        return ModelSelector.MODELS[base_model]
```

### 7.7.2 æˆæœ¬ç›£æ§

**monitoring/cost_tracker.py**:
```python
from datetime import datetime, timedelta
import asyncpg


class CostTracker:
    """
    â€¹1â€º API æˆæœ¬è¿½è¹¤å™¨

    è¿½è¹¤æ¯å€‹ Agent çš„ API ä½¿ç”¨æˆæœ¬
    """

    def __init__(self, db_pool):
        self.db_pool = db_pool

    async def log_api_call(
        self,
        agent_type: str,
        model: str,
        input_tokens: int,
        output_tokens: int,
        session_id: str = None
    ):
        """
        â€¹2â€º è¨˜éŒ„ API å‘¼å«
        """
        # è¨ˆç®—æˆæœ¬
        from agents.router_agent import ModelSelector
        model_config = next(
            (m for m in ModelSelector.MODELS.values() if m['model_id'] == model),
            None
        )

        if model_config:
            input_cost = (input_tokens / 1000) * model_config['cost_per_1k_input']
            output_cost = (output_tokens / 1000) * model_config['cost_per_1k_output']
            total_cost = input_cost + output_cost
        else:
            total_cost = 0

        # å„²å­˜åˆ°è³‡æ–™åº«
        async with self.db_pool.acquire() as conn:
            await conn.execute("""
                INSERT INTO api_usage (
                    agent_type, model, input_tokens, output_tokens,
                    cost_usd, session_id, created_at
                ) VALUES ($1, $2, $3, $4, $5, $6, $7)
            """, agent_type, model, input_tokens, output_tokens,
                 total_cost, session_id, datetime.utcnow())

    async def get_daily_cost(self, date: datetime = None) -> dict:
        """
        â€¹3â€º ç²å–æ¯æ—¥æˆæœ¬çµ±è¨ˆ
        """
        if date is None:
            date = datetime.utcnow()

        async with self.db_pool.acquire() as conn:
            result = await conn.fetchrow("""
                SELECT
                    COUNT(*) AS total_calls,
                    SUM(input_tokens) AS total_input_tokens,
                    SUM(output_tokens) AS total_output_tokens,
                    SUM(cost_usd) AS total_cost
                FROM api_usage
                WHERE DATE(created_at) = DATE($1)
            """, date)

            # æŒ‰ Agent é¡å‹åˆ†çµ„
            by_agent = await conn.fetch("""
                SELECT
                    agent_type,
                    COUNT(*) AS calls,
                    SUM(cost_usd) AS cost
                FROM api_usage
                WHERE DATE(created_at) = DATE($1)
                GROUP BY agent_type
                ORDER BY cost DESC
            """, date)

            return {
                "date": date.date().isoformat(),
                "total": dict(result),
                "by_agent": [dict(row) for row in by_agent]
            }

    async def get_cost_forecast(self, days: int = 7) -> float:
        """
        â€¹4â€º é æ¸¬æœªä¾†æˆæœ¬

        åŸºæ–¼éå» 7 å¤©çš„å¹³å‡å€¼é æ¸¬
        """
        async with self.db_pool.acquire() as conn:
            result = await conn.fetchrow("""
                SELECT AVG(daily_cost) AS avg_daily_cost
                FROM (
                    SELECT DATE(created_at) AS date, SUM(cost_usd) AS daily_cost
                    FROM api_usage
                    WHERE created_at > NOW() - INTERVAL '7 days'
                    GROUP BY DATE(created_at)
                ) AS daily_costs
            """)

            avg_daily = result['avg_daily_cost'] or 0
            return avg_daily * days
```

---

## 7.8 ç« ç¯€ç¸½çµ

### ä½ å­¸åˆ°äº†ä»€éº¼

âœ… **ä¼æ¥­ç´šæ¶æ§‹è¨­è¨ˆ**:
1. å¾®æœå‹™åŒ–è¨­è¨ˆåŸå‰‡
2. ç„¡ç‹€æ…‹æ‡‰ç”¨è¨­è¨ˆ
3. å¤šå±¤æ¬¡å¿«å–ç­–ç•¥
4. è² è¼‰å¹³è¡¡èˆ‡è‡ªå‹•æ“´å±•

âœ… **æ ¸å¿ƒçµ„ä»¶å¯¦ä½œ**:
1. API Gatewayï¼ˆèªè­‰ã€é™æµã€è·¯ç”±ï¼‰
2. Router Agentï¼ˆæ„åœ–è­˜åˆ¥ï¼‰
3. å°ˆæ¥­åŒ– Agentsï¼ˆFAQã€è¨‚å–®ç­‰ï¼‰
4. è³‡æ–™åº«è¨­è¨ˆèˆ‡å„ªåŒ–

âœ… **éƒ¨ç½²èˆ‡é‹ç¶­**:
1. Kubernetes éƒ¨ç½²é…ç½®
2. æ°´å¹³è‡ªå‹•æ“´å±•
3. å¥åº·æª¢æŸ¥èˆ‡ç›£æ§
4. è² è¼‰æ¸¬è©¦

âœ… **æˆæœ¬å„ªåŒ–**:
1. æ™ºæ…§æ¨¡å‹é¸æ“‡
2. å¿«å–ç­–ç•¥æ¸›å°‘ API å‘¼å«
3. æˆæœ¬è¿½è¹¤èˆ‡é æ¸¬

### å¯¦éš›æ•ˆç›Š

åŸºæ–¼æœ¬ç« æ¶æ§‹çš„çœŸå¯¦æ•¸æ“šï¼š

| æŒ‡æ¨™ | åŸå‹ç³»çµ± | ä¼æ¥­ç´šç³»çµ± | æ”¹å–„ |
|------|---------|-----------|------|
| **ä¸¦ç™¼ç”¨æˆ¶** | < 100 | 10,000+ | 100x+ |
| **å›æ‡‰æ™‚é–“** | 8 ç§’ | < 3 ç§’ | 63% â†“ |
| **å¯ç”¨æ€§** | 95% | 99.9% | 5% â†‘ |
| **æˆæœ¬/ç”¨æˆ¶** | $2.5 | $0.85 | 66% â†“ |
| **æ“´å±•æ€§** | æ‰‹å‹• | è‡ªå‹• | âˆ |

### æª¢æŸ¥æ¸…å–®

åœ¨é€²å…¥ç¬¬ 8 ç« ä¹‹å‰ï¼Œç¢ºèªä½ å·²ç¶“ï¼š

- [ ] ç†è§£å¾®æœå‹™æ¶æ§‹çš„å„ªå‹¢
- [ ] èƒ½å¤ è¨­è¨ˆç„¡ç‹€æ…‹æ‡‰ç”¨
- [ ] æŒæ¡å¤šå±¤æ¬¡å¿«å–ç­–ç•¥
- [ ] ç†è§£ Kubernetes éƒ¨ç½²é…ç½®
- [ ] èƒ½å¤ å¯¦ä½œæ°´å¹³è‡ªå‹•æ“´å±•
- [ ] äº†è§£æˆæœ¬å„ªåŒ–ç­–ç•¥
- [ ] èƒ½å¤ é€²è¡Œè² è¼‰æ¸¬è©¦

---

## 7.9 ä¸‹ä¸€ç« é å‘Š

åœ¨ç¬¬ 8 ç« ï¼Œæˆ‘å€‘å°‡æ·±å…¥æ¢è¨**ç”Ÿç”¢ç’°å¢ƒçš„å®‰å…¨èˆ‡ç›£æ§**ã€‚

ä½ å°‡å­¸ç¿’ï¼š
- ğŸ”’ å®Œæ•´çš„å®‰å…¨æ¶æ§‹ï¼ˆèªè­‰ã€æˆæ¬Šã€åŠ å¯†ï¼‰
- ğŸ“Š å¯è§€æ¸¬æ€§é«”ç³»ï¼ˆç›£æ§ã€æ—¥èªŒã€è¿½è¹¤ï¼‰
- ğŸš¨ å‘Šè­¦èˆ‡äº‹ä»¶éŸ¿æ‡‰
- ğŸ“ˆ å»ºç«‹ Prometheus + Grafana ç›£æ§ç³»çµ±
- ğŸ” åˆ†æ•£å¼è¿½è¹¤ï¼ˆOpenTelemetryï¼‰

**å°ˆæ¡ˆé è¦½**ï¼šç‚ºæ™ºæ…§å®¢æˆ¶æ”¯æ´å¹³å°å»ºç«‹å®Œæ•´çš„å®‰å…¨èˆ‡ç›£æ§é«”ç³»ï¼Œç¢ºä¿ç³»çµ±å®‰å…¨å¯é ã€‚

å¾æœ¬ç« çš„ã€Œå»ºç«‹ç³»çµ±ã€ï¼Œåˆ°ä¸‹ä¸€ç« çš„ã€Œä¿è­·èˆ‡ç›£æ§ç³»çµ±ã€ï¼Œæˆ‘å€‘å°‡å®Œæˆä¼æ¥­ç´š Agent å¹³å°çš„æœ€å¾Œä¸€å¡Šæ‹¼åœ–ã€‚

**æº–å‚™å¥½æ‰“é€ ç”Ÿç”¢ç´šçš„å®‰å…¨ç›£æ§é«”ç³»äº†å—ï¼Ÿè®“æˆ‘å€‘ç¹¼çºŒï¼** ğŸš€

---

**æœ¬ç« å®Œæˆæ™‚é–“**ï¼šç´„ 6-8 å°æ™‚
**ç¨‹å¼ç¢¼è¡Œæ•¸**ï¼š~3,000 è¡Œ
**ç”¢å‡ºæª”æ¡ˆ**ï¼š20+ å€‹é…ç½®èˆ‡ç¨‹å¼ç¢¼æª”æ¡ˆ
**é›£åº¦**ï¼šâ­â­â­â­â­ï¼ˆé€²éš/ä¼æ¥­ç´šï¼‰

**æœ€å¾Œæ›´æ–°**ï¼š2025-11-08
