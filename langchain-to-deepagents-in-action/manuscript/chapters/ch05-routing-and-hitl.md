# Chapter 5: è·¯ç”±æ¨¡å¼èˆ‡äººæ©Ÿå”ä½œ (HITL)

> ã€Œæœ€å¥½çš„ AI ç³»çµ±çŸ¥é“ä½•æ™‚è©²è®“äººé¡ä»‹å…¥ã€‚ã€

---

## æœ¬ç« å­¸ç¿’ç›®æ¨™

å®Œæˆæœ¬ç« å¾Œï¼Œä½ å°‡èƒ½å¤ ï¼š

- æŒæ¡é€²éšè·¯ç”±æ¨¡å¼ï¼šåŸºæ–¼ä¿¡å¿ƒåˆ†æ•¸ã€å¤šæ¢ä»¶ã€å‹•æ…‹è·¯ç”±
- å¯¦ç¾ Human-in-the-Loop (HITL) æµç¨‹
- ä½¿ç”¨ Checkpointer ä¿å­˜èˆ‡æ¢å¾©ç‹€æ…‹
- è¨­è¨ˆä¸­æ–·é»èˆ‡äººå·¥å¯©æ ¸æ©Ÿåˆ¶
- å®Œæˆ TechAssist v0.6ï¼šå…·å‚™äººæ©Ÿå”ä½œèƒ½åŠ›çš„åŠ©ç†

---

## 5.1 å ´æ™¯å¼•å…¥ï¼šç‚ºä»€éº¼éœ€è¦äººæ©Ÿå”ä½œï¼Ÿ

TechAssist v0.5 èƒ½è‡ªå‹•è™•ç†å¤§å¤šæ•¸è«‹æ±‚ï¼Œä½†æœ‰äº›å ´æ™¯éœ€è¦äººé¡ä»‹å…¥ï¼š

| å ´æ™¯ | å•é¡Œ | è§£æ±ºæ–¹æ¡ˆ |
|------|------|----------|
| **ä½ä¿¡å¿ƒå›ç­”** | LLM ä¸ç¢ºå®šæ™‚å¯èƒ½ççŒœ | è®“äººé¡ç¢ºèªæˆ–è£œå…… |
| **æ•æ„Ÿæ“ä½œ** | åˆªé™¤è³‡æ–™ã€ç™¼é€éƒµä»¶ | äººå·¥å¯©æ‰¹ |
| **è³‡è¨Šä¸è¶³** | ç¼ºå°‘å¿…è¦ä¸Šä¸‹æ–‡ | è«‹æ±‚ç”¨æˆ¶æ¾„æ¸… |
| **é«˜é¢¨éšªæ±ºç­–** | é‡‘èã€é†«ç™‚å»ºè­° | äººé¡æœ€çµ‚æ±ºå®š |
| **å­¸ç¿’æ”¹é€²** | æ”¶é›†äººé¡åé¥‹ | æ”¹å–„æœªä¾†å›ç­” |

é€™å°±æ˜¯ **Human-in-the-Loop (HITL)** çš„åƒ¹å€¼ã€‚

### 5.1.1 HITL çš„è¨­è¨ˆåŸå‰‡

å¥½çš„ HITL ç³»çµ±æ‡‰è©²ï¼š

```mermaid
graph LR
    A[AI è‡ªå‹•è™•ç†] -->|é«˜ä¿¡å¿ƒ| B[ç›´æ¥è¼¸å‡º]
    A -->|ä¸­ç­‰ä¿¡å¿ƒ| C[å»ºè­° + ç¢ºèª]
    A -->|ä½ä¿¡å¿ƒ| D[è«‹æ±‚äººé¡å”åŠ©]
    A -->|æ•æ„Ÿæ“ä½œ| E[å¼·åˆ¶å¯©æ ¸]
```

**åŸå‰‡ 1ï¼šæ¼¸é€²å¼ä»‹å…¥**
- ä¸æ˜¯æ‰€æœ‰è«‹æ±‚éƒ½éœ€è¦äººé¡
- åªåœ¨å¿…è¦æ™‚æ‰ä¸­æ–·

**åŸå‰‡ 2ï¼šä¿ç•™ä¸Šä¸‹æ–‡**
- äººé¡ä»‹å…¥æ™‚èƒ½çœ‹åˆ°å®Œæ•´è³‡è¨Š
- ä¸­æ–·å¾Œèƒ½ç„¡ç¸«ç¹¼çºŒ

**åŸå‰‡ 3ï¼šæ™‚é–“å®¹å¿**
- é•·æ™‚é–“ç­‰å¾…äººé¡å›æ‡‰
- ç‹€æ…‹æŒä¹…åŒ–

---

## 5.2 é€²éšè·¯ç”±æ¨¡å¼

### 5.2.1 åŸºæ–¼ä¿¡å¿ƒåˆ†æ•¸çš„è·¯ç”±

```python
from typing import TypedDict, Literal

class RoutingState(TypedDict):
    query: str
    response: str
    confidence: float
    route_taken: str

def confidence_router(state: RoutingState) -> Literal["high", "medium", "low"]:
    """åŸºæ–¼ä¿¡å¿ƒåˆ†æ•¸è·¯ç”±"""
    confidence = state["confidence"]

    if confidence >= 0.8:
        return "high"      # ç›´æ¥è¼¸å‡º
    elif confidence >= 0.5:
        return "medium"    # è¼¸å‡ºä½†æ¨™è¨˜ä¸ç¢ºå®š
    else:
        return "low"       # è«‹æ±‚äººé¡å”åŠ©

# åœ¨ Graph ä¸­ä½¿ç”¨
graph.add_conditional_edges(
    "generate_response",
    confidence_router,
    {
        "high": "output",
        "medium": "add_disclaimer",
        "low": "request_human_help"
    }
)
```

### 5.2.2 å¤šæ¢ä»¶è·¯ç”±

ç•¶è·¯ç”±é‚è¼¯è¤‡é›œæ™‚ï¼Œä½¿ç”¨çµæ§‹åŒ–çš„åˆ¤æ–·ï¼š

```python
from dataclasses import dataclass

@dataclass
class RoutingDecision:
    """è·¯ç”±æ±ºç­–"""
    destination: str
    reason: str
    priority: int

def complex_router(state: AgentState) -> str:
    """å¤šæ¢ä»¶è·¯ç”±å™¨"""
    decisions = []

    # æ¢ä»¶ 1ï¼šéŒ¯èª¤æª¢æŸ¥ï¼ˆæœ€é«˜å„ªå…ˆï¼‰
    if state.get("error"):
        decisions.append(RoutingDecision(
            destination="error_handler",
            reason="å­˜åœ¨éŒ¯èª¤éœ€è¦è™•ç†",
            priority=100
        ))

    # æ¢ä»¶ 2ï¼šè¿­ä»£é™åˆ¶
    if state["iteration"] >= state["max_iterations"]:
        decisions.append(RoutingDecision(
            destination="force_complete",
            reason="é”åˆ°è¿­ä»£ä¸Šé™",
            priority=90
        ))

    # æ¢ä»¶ 3ï¼šæ•æ„Ÿæ“ä½œæª¢æ¸¬
    if detect_sensitive_operation(state):
        decisions.append(RoutingDecision(
            destination="human_approval",
            reason="æª¢æ¸¬åˆ°æ•æ„Ÿæ“ä½œ",
            priority=80
        ))

    # æ¢ä»¶ 4ï¼šå·¥å…·èª¿ç”¨
    last_msg = state["messages"][-1]
    if hasattr(last_msg, "tool_calls") and last_msg.tool_calls:
        decisions.append(RoutingDecision(
            destination="tools",
            reason="éœ€è¦åŸ·è¡Œå·¥å…·",
            priority=50
        ))

    # æ¢ä»¶ 5ï¼šé è¨­å®Œæˆ
    decisions.append(RoutingDecision(
        destination="complete",
        reason="é è¨­è·¯å¾‘",
        priority=0
    ))

    # é¸æ“‡æœ€é«˜å„ªå…ˆç´š
    best = max(decisions, key=lambda d: d.priority)
    return best.destination
```

### 5.2.3 å‹•æ…‹è·¯ç”±è¡¨

æœ‰æ™‚è·¯ç”±ç›®æ¨™æœ¬èº«æ˜¯å‹•æ…‹çš„ï¼š

```python
def dynamic_router(state: AgentState) -> str:
    """å‹•æ…‹è·¯ç”±ï¼šæ ¹æ“šæ„åœ–é¸æ“‡è™•ç†å™¨"""
    intent = state.get("intent", "unknown")

    # å‹•æ…‹è·¯ç”±è¡¨ï¼ˆå¯å¾é…ç½®æˆ–è³‡æ–™åº«è¼‰å…¥ï¼‰
    routing_table = {
        "tech_question": "tech_qa_handler",
        "code_review": "code_review_handler",
        "code_generation": "code_gen_handler",
        "troubleshooting": "debug_handler",
        "comparison": "comparison_handler",
    }

    # æŸ¥æ‰¾æˆ–ä½¿ç”¨é è¨­
    return routing_table.get(intent, "default_handler")

# å‹•æ…‹ç›®æ¨™éœ€è¦åœ¨ Graph ä¸­é å…ˆè¨»å†Š
graph.add_conditional_edges(
    "classify",
    dynamic_router,
    {
        "tech_qa_handler": "tech_qa_handler",
        "code_review_handler": "code_review_handler",
        "code_gen_handler": "code_gen_handler",
        "debug_handler": "debug_handler",
        "comparison_handler": "comparison_handler",
        "default_handler": "default_handler",
    }
)
```

### 5.2.4 è·¯ç”±æ¨¡å¼ï¼šåˆ†å±¤æ±ºç­–

```python
def layered_router(state: AgentState) -> str:
    """åˆ†å±¤è·¯ç”±ï¼šå…ˆæª¢æŸ¥ç³»çµ±ç´šï¼Œå†æª¢æŸ¥æ¥­å‹™ç´š"""

    # Layer 1: ç³»çµ±ç´šæª¢æŸ¥
    system_route = check_system_conditions(state)
    if system_route:
        return system_route

    # Layer 2: å®‰å…¨æª¢æŸ¥
    security_route = check_security(state)
    if security_route:
        return security_route

    # Layer 3: æ¥­å‹™é‚è¼¯
    business_route = check_business_logic(state)
    if business_route:
        return business_route

    # Layer 4: é è¨­
    return "default"

def check_system_conditions(state) -> str | None:
    """ç³»çµ±ç´šæ¢ä»¶"""
    if state.get("error"):
        return "error_handler"
    if state["iteration"] >= 10:
        return "timeout_handler"
    return None

def check_security(state) -> str | None:
    """å®‰å…¨æª¢æŸ¥"""
    if contains_pii(state["messages"]):
        return "pii_handler"
    if is_injection_attempt(state["messages"]):
        return "security_block"
    return None

def check_business_logic(state) -> str | None:
    """æ¥­å‹™é‚è¼¯"""
    if state.get("needs_approval"):
        return "approval_flow"
    if state.get("is_premium_user"):
        return "premium_handler"
    return None
```

---

## 5.3 Checkpointerï¼šç‹€æ…‹æŒä¹…åŒ–

### 5.3.1 ç‚ºä»€éº¼éœ€è¦ Checkpointerï¼Ÿ

HITL æµç¨‹å¯èƒ½æŒçºŒå¾ˆé•·æ™‚é–“ï¼š

1. ç”¨æˆ¶æäº¤è«‹æ±‚
2. AI è™•ç†ä¸¦è«‹æ±‚å¯©æ ¸
3. **ç­‰å¾…æ•¸å°æ™‚**
4. ç®¡ç†å“¡å¯©æ ¸é€šé
5. AI ç¹¼çºŒåŸ·è¡Œ

åœ¨é€™å€‹éç¨‹ä¸­ï¼Œç‹€æ…‹å¿…é ˆæŒä¹…åŒ–ï¼Œå¦å‰‡ï¼š
- ç¨‹åºé‡å•Ÿæœƒä¸Ÿå¤±æ‰€æœ‰ä¸Šä¸‹æ–‡
- ç„¡æ³•è¿½è¹¤æ­·å²ç‹€æ…‹
- ç„¡æ³•å¯¦ç¾æ–·é»æ¢å¾©

### 5.3.2 MemorySaverï¼šè¨˜æ†¶é«” Checkpointer

æœ€ç°¡å–®çš„ Checkpointerï¼Œé©åˆé–‹ç™¼æ¸¬è©¦ï¼š

```python
from langgraph.checkpoint.memory import MemorySaver

# å»ºç«‹ Checkpointer
memory = MemorySaver()

# ç·¨è­¯æ™‚æŒ‡å®š Checkpointer
app = graph.compile(checkpointer=memory)

# åŸ·è¡Œæ™‚æŒ‡å®š thread_id
config = {"configurable": {"thread_id": "user-123"}}

# ç¬¬ä¸€æ¬¡åŸ·è¡Œ
result1 = app.invoke(
    {"messages": [HumanMessage(content="ä½ å¥½")]},
    config=config
)

# ç¬¬äºŒæ¬¡åŸ·è¡Œï¼ˆåŒä¸€å€‹ thread_idï¼‰æœƒç¹¼çºŒä¹‹å‰çš„å°è©±
result2 = app.invoke(
    {"messages": [HumanMessage(content="å‰›æ‰èªªäº†ä»€éº¼ï¼Ÿ")]},
    config=config
)
```

### 5.3.3 SqliteSaverï¼šæŒä¹…åŒ– Checkpointer

ç”Ÿç”¢ç’°å¢ƒä½¿ç”¨ SQLite æˆ– PostgreSQLï¼š

```python
from langgraph.checkpoint.sqlite import SqliteSaver

# ä½¿ç”¨ SQLite
with SqliteSaver.from_conn_string(":memory:") as memory:
    app = graph.compile(checkpointer=memory)

    config = {"configurable": {"thread_id": "conversation-001"}}
    result = app.invoke(initial_state, config=config)

# ä½¿ç”¨æª”æ¡ˆæŒä¹…åŒ–
import sqlite3

conn = sqlite3.connect("checkpoints.db", check_same_thread=False)
memory = SqliteSaver(conn)
app = graph.compile(checkpointer=memory)
```

### 5.3.4 æŸ¥çœ‹æ­·å²ç‹€æ…‹

```python
# ç²å–æ‰€æœ‰ç‹€æ…‹å¿«ç…§
config = {"configurable": {"thread_id": "user-123"}}

for state in app.get_state_history(config):
    print(f"æ­¥é©Ÿï¼š{state.step}")
    print(f"ç‹€æ…‹ï¼š{state.values}")
    print(f"æ™‚é–“ï¼š{state.created_at}")
    print("-" * 40)

# ç²å–ç‰¹å®šæª¢æŸ¥é»çš„ç‹€æ…‹
snapshot = app.get_state(config)
print(f"ç•¶å‰ç‹€æ…‹ï¼š{snapshot.values}")
print(f"ä¸‹ä¸€æ­¥ï¼š{snapshot.next}")  # ä¸‹ä¸€å€‹è¦åŸ·è¡Œçš„ç¯€é»
```

### 5.3.5 ç‹€æ…‹å›æº¯

```python
# å›åˆ°ä¹‹å‰çš„ç‹€æ…‹
config = {"configurable": {"thread_id": "user-123"}}

# ç²å–æ­·å²
history = list(app.get_state_history(config))

# é¸æ“‡è¦å›æº¯çš„ç‹€æ…‹ï¼ˆä¾‹å¦‚ç¬¬ 3 å€‹ï¼‰
target_state = history[2]

# å¾è©²ç‹€æ…‹ç¹¼çºŒåŸ·è¡Œ
result = app.invoke(
    None,  # ä¸æä¾›æ–°è¼¸å…¥ï¼Œä½¿ç”¨æ­·å²ç‹€æ…‹
    config={
        "configurable": {
            "thread_id": "user-123",
            "checkpoint_id": target_state.config["configurable"]["checkpoint_id"]
        }
    }
)
```

---

## 5.4 ä¸­æ–·æ©Ÿåˆ¶ï¼šå¯¦ç¾äººæ©Ÿå”ä½œ

### 5.4.1 interrupt_beforeï¼šç¯€é»åŸ·è¡Œå‰ä¸­æ–·

```python
from langgraph.graph import StateGraph, START, END

graph = StateGraph(AgentState)
graph.add_node("classify", classify_node)
graph.add_node("sensitive_action", sensitive_action_node)
graph.add_node("execute", execute_node)

# åœ¨ sensitive_action ç¯€é»**åŸ·è¡Œå‰**ä¸­æ–·
app = graph.compile(
    checkpointer=memory,
    interrupt_before=["sensitive_action"]
)
```

åŸ·è¡Œæµç¨‹ï¼š

```python
config = {"configurable": {"thread_id": "task-001"}}

# åŸ·è¡Œæœƒåœ¨ sensitive_action å‰åœæ­¢
result = app.invoke(initial_state, config=config)

# æª¢æŸ¥ç‹€æ…‹
snapshot = app.get_state(config)
print(f"ä¸‹ä¸€æ­¥ï¼š{snapshot.next}")  # ['sensitive_action']

# äººé¡å¯©æ ¸å¾Œç¹¼çºŒï¼ˆæˆ–ä¿®æ”¹ç‹€æ…‹å¾Œç¹¼çºŒï¼‰
final_result = app.invoke(None, config=config)
```

### 5.4.2 interrupt_afterï¼šç¯€é»åŸ·è¡Œå¾Œä¸­æ–·

```python
# åœ¨ generate_plan ç¯€é»**åŸ·è¡Œå¾Œ**ä¸­æ–·
app = graph.compile(
    checkpointer=memory,
    interrupt_after=["generate_plan"]
)
```

é€™è®“äººé¡èƒ½å¤ ï¼š
- æŸ¥çœ‹ AI ç”Ÿæˆçš„è¨ˆåŠƒ
- ä¿®æ”¹è¨ˆåŠƒå¾Œå†ç¹¼çºŒåŸ·è¡Œ

### 5.4.3 å‹•æ…‹ä¸­æ–·ï¼šNodeInterrupt

æœ‰æ™‚éœ€è¦åœ¨ç¯€é»å…§éƒ¨æ±ºå®šæ˜¯å¦ä¸­æ–·ï¼š

```python
from langgraph.errors import NodeInterrupt

def sensitive_operation(state: AgentState) -> dict:
    """å¯èƒ½éœ€è¦ä¸­æ–·çš„æ•æ„Ÿæ“ä½œ"""

    # æª¢æŸ¥æ˜¯å¦å·²ç²å¾—æ‰¹å‡†
    if state.get("approved"):
        # åŸ·è¡Œå¯¦éš›æ“ä½œ
        result = perform_operation()
        return {"result": result}

    # æœªæ‰¹å‡†ï¼Œä¸»å‹•ä¸­æ–·ä¸¦è«‹æ±‚å¯©æ ¸
    raise NodeInterrupt(
        "æ­¤æ“ä½œéœ€è¦ç®¡ç†å“¡æ‰¹å‡†ã€‚\n"
        f"æ“ä½œé¡å‹ï¼š{state['operation_type']}\n"
        f"å½±éŸ¿ç¯„åœï¼š{state['scope']}"
    )
```

### 5.4.4 ä¿®æ”¹ç‹€æ…‹å¾Œç¹¼çºŒ

ä¸­æ–·å¾Œï¼Œäººé¡å¯ä»¥ä¿®æ”¹ç‹€æ…‹ï¼š

```python
config = {"configurable": {"thread_id": "task-001"}}

# åŸ·è¡Œåˆ°ä¸­æ–·é»
result = app.invoke(initial_state, config=config)

# ç²å–ç•¶å‰ç‹€æ…‹
snapshot = app.get_state(config)
print(f"ç­‰å¾…å¯©æ ¸ï¼š{snapshot.values}")

# äººé¡å¯©æ ¸ï¼šæ‰¹å‡†
app.update_state(
    config,
    {"approved": True, "approver": "admin@company.com"}
)

# ç¹¼çºŒåŸ·è¡Œ
final_result = app.invoke(None, config=config)
```

---

## 5.5 å¯¦ä½œï¼šå¯©æ‰¹å·¥ä½œæµ

è®“æˆ‘å€‘å¯¦ä½œä¸€å€‹å®Œæ•´çš„å¯©æ‰¹å·¥ä½œæµï¼š

### 5.5.1 å ´æ™¯å®šç¾©

```
ç”¨æˆ¶è«‹æ±‚ â†’ AI åˆ†æ â†’ [æ•æ„Ÿæ“ä½œ?]
                        â†“
                   æ˜¯ â†’ ç­‰å¾…å¯©æ‰¹ â†’ [æ‰¹å‡†?]
                        â†“              â†“
                   å¦ â†’ åŸ·è¡Œ      æ˜¯ â†’ åŸ·è¡Œ
                                      â†“
                                 å¦ â†’ æ‹’çµ•
```

### 5.5.2 å®Œæ•´å¯¦ç¾

```python
from typing import TypedDict, Annotated, Literal
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_anthropic import ChatAnthropic
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langgraph.errors import NodeInterrupt

# ============================================================
# 1. ç‹€æ…‹å®šç¾©
# ============================================================

class ApprovalState(TypedDict):
    """å¯©æ‰¹å·¥ä½œæµç‹€æ…‹"""
    messages: Annotated[list, add_messages]

    # è«‹æ±‚è³‡è¨Š
    request_type: str
    request_details: dict

    # é¢¨éšªè©•ä¼°
    risk_level: Literal["low", "medium", "high"]
    is_sensitive: bool

    # å¯©æ‰¹è³‡è¨Š
    approval_status: Literal["pending", "approved", "rejected"] | None
    approver: str | None
    approval_reason: str | None

    # åŸ·è¡Œçµæœ
    execution_result: str | None

# ============================================================
# 2. ç¯€é»å¯¦ç¾
# ============================================================

llm = ChatAnthropic(model="claude-3-5-sonnet-20241022")

def analyze_request(state: ApprovalState) -> dict:
    """åˆ†æè«‹æ±‚ä¸¦è©•ä¼°é¢¨éšª"""
    user_request = state["messages"][-1].content

    # ä½¿ç”¨ LLM åˆ†æ
    analysis_prompt = f"""åˆ†æä»¥ä¸‹è«‹æ±‚çš„é¢¨éšªç­‰ç´šï¼š

è«‹æ±‚ï¼š{user_request}

å›è¦†æ ¼å¼ï¼š
é¢¨éšªç­‰ç´šï¼š[low/medium/high]
æ˜¯å¦æ•æ„Ÿï¼š[yes/no]
åŸå› ï¼š[ç°¡çŸ­èªªæ˜]
"""

    response = llm.invoke([HumanMessage(content=analysis_prompt)])
    content = response.content.lower()

    # ç°¡å–®è§£æ
    risk_level = "high" if "high" in content else ("medium" if "medium" in content else "low")
    is_sensitive = "yes" in content or "æ•æ„Ÿ" in content or risk_level == "high"

    return {
        "request_type": "general",  # ç°¡åŒ–
        "risk_level": risk_level,
        "is_sensitive": is_sensitive,
        "messages": [AIMessage(content=f"é¢¨éšªè©•ä¼°å®Œæˆï¼š{risk_level} é¢¨éšª")]
    }

def request_approval(state: ApprovalState) -> dict:
    """è«‹æ±‚äººå·¥å¯©æ‰¹"""
    # ä½¿ç”¨ NodeInterrupt ä¸­æ–·åŸ·è¡Œ
    raise NodeInterrupt(
        f"âš ï¸ éœ€è¦äººå·¥å¯©æ‰¹\n\n"
        f"é¢¨éšªç­‰ç´šï¼š{state['risk_level']}\n"
        f"è«‹æ±‚å…§å®¹ï¼š{state['messages'][0].content}\n\n"
        f"è«‹ç®¡ç†å“¡å¯©æ ¸å¾Œè¨­ç½® approval_status ç‚º 'approved' æˆ– 'rejected'"
    )

def execute_request(state: ApprovalState) -> dict:
    """åŸ·è¡Œè«‹æ±‚"""
    # æ¨¡æ“¬åŸ·è¡Œ
    result = f"å·²æˆåŠŸè™•ç†è«‹æ±‚ï¼š{state['request_details']}"

    return {
        "execution_result": result,
        "messages": [AIMessage(content=f"âœ… {result}")]
    }

def reject_request(state: ApprovalState) -> dict:
    """æ‹’çµ•è«‹æ±‚"""
    reason = state.get("approval_reason", "æœªæä¾›åŸå› ")

    return {
        "execution_result": "rejected",
        "messages": [AIMessage(content=f"âŒ è«‹æ±‚å·²è¢«æ‹’çµ•ã€‚åŸå› ï¼š{reason}")]
    }

def auto_execute(state: ApprovalState) -> dict:
    """è‡ªå‹•åŸ·è¡Œï¼ˆä½é¢¨éšªï¼‰"""
    return {
        "execution_result": "auto_executed",
        "messages": [AIMessage(content="âœ… ä½é¢¨éšªè«‹æ±‚ï¼Œå·²è‡ªå‹•è™•ç†ã€‚")]
    }

# ============================================================
# 3. è·¯ç”±å‡½æ•¸
# ============================================================

def route_after_analysis(state: ApprovalState) -> str:
    """åˆ†æå¾Œè·¯ç”±"""
    if state["is_sensitive"]:
        return "request_approval"
    return "auto_execute"

def route_after_approval(state: ApprovalState) -> str:
    """å¯©æ‰¹å¾Œè·¯ç”±"""
    status = state.get("approval_status")
    if status == "approved":
        return "execute"
    elif status == "rejected":
        return "reject"
    # ä»åœ¨ç­‰å¾…
    return "wait"

# ============================================================
# 4. çµ„è£ Graph
# ============================================================

def create_approval_workflow():
    graph = StateGraph(ApprovalState)

    # æ·»åŠ ç¯€é»
    graph.add_node("analyze", analyze_request)
    graph.add_node("request_approval", request_approval)
    graph.add_node("execute", execute_request)
    graph.add_node("reject", reject_request)
    graph.add_node("auto_execute", auto_execute)

    # æ·»åŠ é‚Š
    graph.add_edge(START, "analyze")

    graph.add_conditional_edges(
        "analyze",
        route_after_analysis,
        {
            "request_approval": "request_approval",
            "auto_execute": "auto_execute"
        }
    )

    # request_approval æœƒæ‹‹å‡º NodeInterruptï¼Œ
    # æ¢å¾©å¾Œæ ¹æ“š approval_status è·¯ç”±
    graph.add_conditional_edges(
        "request_approval",
        route_after_approval,
        {
            "execute": "execute",
            "reject": "reject",
            "wait": "request_approval"  # ç¹¼çºŒç­‰å¾…
        }
    )

    graph.add_edge("execute", END)
    graph.add_edge("reject", END)
    graph.add_edge("auto_execute", END)

    return graph

# ç·¨è­¯
memory = MemorySaver()
approval_app = create_approval_workflow().compile(checkpointer=memory)

# ============================================================
# 5. ä½¿ç”¨ç¯„ä¾‹
# ============================================================

def run_approval_demo():
    """æ¼”ç¤ºå¯©æ‰¹æµç¨‹"""
    thread_id = "approval-demo-001"
    config = {"configurable": {"thread_id": thread_id}}

    # åˆå§‹ç‹€æ…‹
    initial = {
        "messages": [HumanMessage(content="è«‹åˆªé™¤æ‰€æœ‰ç”¨æˆ¶è³‡æ–™")],
        "request_type": "",
        "request_details": {"action": "delete_all_users"},
        "risk_level": "low",
        "is_sensitive": False,
        "approval_status": None,
        "approver": None,
        "approval_reason": None,
        "execution_result": None,
    }

    print("=" * 60)
    print("å¯©æ‰¹å·¥ä½œæµæ¼”ç¤º")
    print("=" * 60)

    # ç¬¬ä¸€æ¬¡åŸ·è¡Œï¼šæœƒåœ¨æ•æ„Ÿæ“ä½œè™•ä¸­æ–·
    try:
        result = approval_app.invoke(initial, config=config)
    except Exception as e:
        print(f"\nâ¸ï¸ æµç¨‹å·²ä¸­æ–·ï¼š\n{e}")

    # æª¢æŸ¥ç‹€æ…‹
    snapshot = approval_app.get_state(config)
    print(f"\nç•¶å‰ç‹€æ…‹ï¼š")
    print(f"  é¢¨éšªç­‰ç´šï¼š{snapshot.values.get('risk_level')}")
    print(f"  éœ€è¦å¯©æ‰¹ï¼š{snapshot.values.get('is_sensitive')}")
    print(f"  ä¸‹ä¸€æ­¥ï¼š{snapshot.next}")

    # æ¨¡æ“¬ç®¡ç†å“¡å¯©æ‰¹
    print("\n" + "-" * 40)
    print("ç®¡ç†å“¡å¯©æ‰¹ä¸­...")
    approval_app.update_state(
        config,
        {
            "approval_status": "approved",
            "approver": "admin@company.com",
            "approval_reason": "å·²ç¢ºèªç”¨æˆ¶èº«ä»½ï¼Œæ‰¹å‡†åŸ·è¡Œ"
        }
    )

    # ç¹¼çºŒåŸ·è¡Œ
    print("\nç¹¼çºŒåŸ·è¡Œ...")
    final_result = approval_app.invoke(None, config=config)

    print(f"\næœ€çµ‚çµæœï¼š")
    print(f"  åŸ·è¡Œç‹€æ…‹ï¼š{final_result.get('execution_result')}")
    print(f"  æœ€å¾Œè¨Šæ¯ï¼š{final_result['messages'][-1].content}")

if __name__ == "__main__":
    run_approval_demo()
```

### 5.5.3 æ¸¬è©¦è¼¸å‡º

```
============================================================
å¯©æ‰¹å·¥ä½œæµæ¼”ç¤º
============================================================

â¸ï¸ æµç¨‹å·²ä¸­æ–·ï¼š
âš ï¸ éœ€è¦äººå·¥å¯©æ‰¹

é¢¨éšªç­‰ç´šï¼šhigh
è«‹æ±‚å…§å®¹ï¼šè«‹åˆªé™¤æ‰€æœ‰ç”¨æˆ¶è³‡æ–™

è«‹ç®¡ç†å“¡å¯©æ ¸å¾Œè¨­ç½® approval_status ç‚º 'approved' æˆ– 'rejected'

ç•¶å‰ç‹€æ…‹ï¼š
  é¢¨éšªç­‰ç´šï¼šhigh
  éœ€è¦å¯©æ‰¹ï¼šTrue
  ä¸‹ä¸€æ­¥ï¼š['request_approval']

----------------------------------------
ç®¡ç†å“¡å¯©æ‰¹ä¸­...

ç¹¼çºŒåŸ·è¡Œ...

æœ€çµ‚çµæœï¼š
  åŸ·è¡Œç‹€æ…‹ï¼šå·²æˆåŠŸè™•ç†è«‹æ±‚ï¼š{'action': 'delete_all_users'}
  æœ€å¾Œè¨Šæ¯ï¼šâœ… å·²æˆåŠŸè™•ç†è«‹æ±‚ï¼š{'action': 'delete_all_users'}
```

---

## 5.6 å¯¦ä½œï¼šTechAssist v0.6

å°‡ HITL æ•´åˆåˆ° TechAssistï¼š

### 5.6.1 å¢å¼·ç‹€æ…‹

```python
# techassist/state_v6.py
from typing import TypedDict, Annotated, Literal
from langgraph.graph.message import add_messages

class TechAssistStateV6(TypedDict):
    """TechAssist v0.6 ç‹€æ…‹ - æ”¯æ´ HITL"""

    # åŸºç¤
    messages: Annotated[list, add_messages]
    phase: str

    # åˆ†æçµæœ
    intent: str | None
    confidence: float
    is_sensitive: bool

    # HITL ç›¸é—œ
    requires_confirmation: bool
    user_confirmed: bool | None
    confirmation_prompt: str | None

    # æ§åˆ¶
    iteration: int
    max_iterations: int

    # åŸ·è¡Œçµæœ
    final_response: str | None
```

### 5.6.2 ç¢ºèªç¯€é»

```python
# techassist/nodes_v6.py
from langgraph.errors import NodeInterrupt

def check_confidence(state: TechAssistStateV6) -> dict:
    """æª¢æŸ¥ä¿¡å¿ƒåˆ†æ•¸ï¼Œæ±ºå®šæ˜¯å¦éœ€è¦ç¢ºèª"""
    confidence = state["confidence"]

    if confidence < 0.6:
        return {
            "requires_confirmation": True,
            "confirmation_prompt": f"æˆ‘çš„ç†è§£æ˜¯ï¼š{state.get('intent', 'æœªçŸ¥æ„åœ–')}ã€‚é€™æ¨£ç†è§£å°å—ï¼Ÿ"
        }

    return {"requires_confirmation": False}

def request_confirmation(state: TechAssistStateV6) -> dict:
    """è«‹æ±‚ç”¨æˆ¶ç¢ºèª"""
    if state.get("user_confirmed") is not None:
        # å·²ç¶“æœ‰ç¢ºèªçµæœ
        return {}

    raise NodeInterrupt(
        f"éœ€è¦ç¢ºèª\n\n"
        f"{state['confirmation_prompt']}\n\n"
        f"è«‹è¨­ç½® user_confirmed ç‚º true æˆ– false"
    )

def route_after_confidence_check(state: TechAssistStateV6) -> str:
    """ä¿¡å¿ƒæª¢æŸ¥å¾Œè·¯ç”±"""
    if state["requires_confirmation"]:
        return "request_confirmation"
    return "process"

def route_after_confirmation(state: TechAssistStateV6) -> str:
    """ç¢ºèªå¾Œè·¯ç”±"""
    if state.get("user_confirmed") is True:
        return "process"
    elif state.get("user_confirmed") is False:
        return "clarify"
    return "wait"
```

### 5.6.3 å®Œæ•´ Graph

```python
# techassist/graph_v6.py
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver

def create_techassist_v6():
    graph = StateGraph(TechAssistStateV6)

    # ç¯€é»
    graph.add_node("classify", classify_node)
    graph.add_node("check_confidence", check_confidence)
    graph.add_node("request_confirmation", request_confirmation)
    graph.add_node("clarify", clarify_node)
    graph.add_node("process", process_node)
    graph.add_node("tools", tool_node)
    graph.add_node("output", output_node)

    # é‚Š
    graph.add_edge(START, "classify")
    graph.add_edge("classify", "check_confidence")

    graph.add_conditional_edges(
        "check_confidence",
        route_after_confidence_check,
        {
            "request_confirmation": "request_confirmation",
            "process": "process"
        }
    )

    graph.add_conditional_edges(
        "request_confirmation",
        route_after_confirmation,
        {
            "process": "process",
            "clarify": "clarify",
            "wait": "request_confirmation"
        }
    )

    graph.add_edge("clarify", END)

    graph.add_conditional_edges(
        "process",
        should_use_tools,
        {
            "tools": "tools",
            "output": "output"
        }
    )

    graph.add_edge("tools", "process")
    graph.add_edge("output", END)

    # ç·¨è­¯
    memory = MemorySaver()
    return graph.compile(checkpointer=memory)

techassist_v6 = create_techassist_v6()
```

### 5.6.4 äº’å‹•å¼ CLI

```python
# techassist/cli_v6.py

def run_cli_v6():
    """TechAssist v0.6 CLI - æ”¯æ´ HITL"""
    print("=" * 60)
    print("ğŸ¤– TechAssist v0.6 - äººæ©Ÿå”ä½œç‰ˆ")
    print("=" * 60)

    session_id = f"session-{int(time.time())}"
    config = {"configurable": {"thread_id": session_id}}

    while True:
        user_input = input("\nğŸ“ ä½ çš„å•é¡Œï¼š").strip()
        if user_input.lower() in ('quit', 'exit'):
            break

        initial = create_initial_state(user_input)

        try:
            # åŸ·è¡Œ
            for event in techassist_v6.stream(initial, config=config):
                handle_event(event)

        except NodeInterrupt as interrupt:
            # è™•ç†ä¸­æ–·
            print(f"\nâ¸ï¸ {interrupt}")

            # ç²å–ç”¨æˆ¶ç¢ºèª
            confirm = input("\nç¢ºèªï¼Ÿ(y/n): ").strip().lower()
            techassist_v6.update_state(
                config,
                {"user_confirmed": confirm == 'y'}
            )

            # ç¹¼çºŒåŸ·è¡Œ
            for event in techassist_v6.stream(None, config=config):
                handle_event(event)
```

---

## 5.7 æœ¬ç« å›é¡§

### æ ¸å¿ƒæ¦‚å¿µ

| æ¦‚å¿µ | èªªæ˜ | å¯¦ç¾æ–¹å¼ |
|------|------|----------|
| **æ¢ä»¶è·¯ç”±** | æ ¹æ“šç‹€æ…‹å‹•æ…‹é¸æ“‡è·¯å¾‘ | `add_conditional_edges` |
| **Checkpointer** | ç‹€æ…‹æŒä¹…åŒ– | `MemorySaver`, `SqliteSaver` |
| **ä¸­æ–·** | æš«åœåŸ·è¡Œç­‰å¾…å¤–éƒ¨è¼¸å…¥ | `interrupt_before/after`, `NodeInterrupt` |
| **ç‹€æ…‹æ›´æ–°** | å¤–éƒ¨ä¿®æ”¹ç‹€æ…‹ | `app.update_state()` |

### HITL è¨­è¨ˆæ¨¡å¼

```mermaid
graph TD
    A[AI è™•ç†] --> B{éœ€è¦äººé¡ï¼Ÿ}
    B -->|å¦| C[ç¹¼çºŒ]
    B -->|æ˜¯| D[ä¸­æ–·]
    D --> E[äººé¡å¯©æ ¸/è¼¸å…¥]
    E --> F[æ›´æ–°ç‹€æ…‹]
    F --> A
```

### TechAssist é‡Œç¨‹ç¢‘

- âœ… v0.5ï¼šåŸºæ–¼ LangGraph çš„ç‹€æ…‹ç®¡ç†
- âœ… v0.6ï¼šå…·å‚™äººæ©Ÿå”ä½œ (HITL) èƒ½åŠ›

---

## 5.8 ä¸‹ä¸€ç« é å‘Š

TechAssist v0.6 èƒ½èˆ‡äººé¡å”ä½œï¼Œä½†å®ƒä»æ˜¯å–®ä¸€ Agentã€‚ç•¶ä»»å‹™è¤‡é›œæ™‚ï¼Œéœ€è¦å¤šå€‹å°ˆæ¥­ Agent å”ä½œï¼š

- **Coder Agent**ï¼šå°ˆé–€å¯«ç¨‹å¼ç¢¼
- **Reviewer Agent**ï¼šå°ˆé–€å¯©æŸ¥ç¨‹å¼ç¢¼
- **Researcher Agent**ï¼šå°ˆé–€æœå°‹è³‡æ–™

åœ¨ä¸‹ä¸€ç« ï¼Œæˆ‘å€‘å°‡å­¸ç¿’ **å¤šæ™ºèƒ½é«”å”ä½œâ€”â€”Supervisor æ¨¡å¼**ï¼š

- ç†è§£ Multi-Agent æ¶æ§‹
- å¯¦ç¾ Supervisor Pattern
- å»ºç«‹ Agent åœ˜éšŠå”ä½œ

---

## ç·´ç¿’é¡Œ

1. **åŸºç¤ç·´ç¿’**ï¼šå¯¦ç¾ä¸€å€‹ã€Œä¸‰ç´šå¯©æ‰¹ã€æµç¨‹ï¼šä½é¢¨éšªè‡ªå‹•é€šéã€ä¸­é¢¨éšªä¸»ç®¡å¯©æ‰¹ã€é«˜é¢¨éšªç¸½ç›£å¯©æ‰¹ã€‚

2. **é€²éšç·´ç¿’**ï¼šç‚º TechAssist v0.6 æ·»åŠ ã€Œè¶…æ™‚æ©Ÿåˆ¶ã€ï¼šå¦‚æœç­‰å¾…ç”¨æˆ¶ç¢ºèªè¶…é 5 åˆ†é˜ï¼Œè‡ªå‹•ä½¿ç”¨ä¿å®ˆç­–ç•¥å›ç­”ã€‚

3. **æŒ‘æˆ°ç·´ç¿’**ï¼šå¯¦ç¾ã€Œæ‰¹æ¬¡å¯©æ‰¹ã€ï¼šç´¯ç©å¤šå€‹å¾…å¯©æ ¸è«‹æ±‚ï¼Œè®“ç®¡ç†å“¡ä¸€æ¬¡å¯©æ ¸ã€‚

---

## å»¶ä¼¸é–±è®€

- [LangGraphï¼šHuman-in-the-Loop](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/)
- [LangGraphï¼šPersistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/)
- [è¨­è¨ˆäººæ©Ÿå”ä½œç³»çµ±çš„æœ€ä½³å¯¦è¸](https://www.nngroup.com/articles/human-ai-collaboration/)
