# Chapter 2: Prompt å·¥ç¨‹èˆ‡çµæ§‹åŒ–è¼¸å‡º

> ã€Œèˆ‡ LLM å°è©±æ˜¯ä¸€é–€è—è¡“ï¼Œä½†çµæ§‹åŒ–è¼¸å‡ºæ˜¯ä¸€é–€å·¥ç¨‹ã€‚ã€

---

## æœ¬ç« å­¸ç¿’ç›®æ¨™

å®Œæˆæœ¬ç« å¾Œï¼Œä½ å°‡èƒ½å¤ ï¼š

- æŒæ¡é€²éš Prompt æŠ€å·§ï¼šChain-of-Thought (CoT) èˆ‡ Few-Shot Learning
- ä½¿ç”¨ Pydantic å®šç¾©åš´æ ¼çš„è¼¸å‡ºçµæ§‹
- å¯¦ä½œæ„åœ–åˆ†é¡å™¨ (Intent Classifier)
- å»ºç«‹ TechAssist v0.2ï¼šå…·å‚™æ„åœ–ç†è§£èƒ½åŠ›çš„åŠ©ç†

---

## 2.1 å ´æ™¯å¼•å…¥ï¼šè®“ TechAssist æ›´è°æ˜

å›é¡§ TechAssist v0.1ï¼Œå®ƒèƒ½å›ç­”æŠ€è¡“å•é¡Œï¼Œä½†æœ‰å€‹è‡´å‘½å•é¡Œï¼š**å®ƒæŠŠæ‰€æœ‰è¼¸å…¥éƒ½ç•¶æˆæŠ€è¡“å•é¡Œ**ã€‚

æƒ³åƒé€™äº›å ´æ™¯ï¼š

| ä½¿ç”¨è€…è¼¸å…¥ | v0.1 çš„åæ‡‰ | æˆ‘å€‘æœŸæœ›çš„åæ‡‰ |
|------------|-------------|----------------|
| ã€Œä½ å¥½ã€ | é–‹å§‹è§£é‡‹æŠ€è¡“æ¦‚å¿µ | å‹å–„æ‰“æ‹›å‘¼ |
| ã€Œå¹«æˆ‘é‡æ§‹é€™æ®µç¨‹å¼ç¢¼ï¼š...ã€ | åªçµ¦å‡ºè§£é‡‹ | å¯¦éš›é€²è¡Œé‡æ§‹ |
| ã€ŒPython å’Œ Go å“ªå€‹å¥½ï¼Ÿã€ | çµ¦å‡ºåé —çš„ç­”æ¡ˆ | å®¢è§€æ¯”è¼ƒ |
| ã€Œæˆ‘å¾ˆæ²®å–ªï¼Œç¨‹å¼ä¸€ç›´è·‘ä¸å‹•ã€ | å¿½ç•¥æƒ…ç·’ | å…ˆåŒç†å†å”åŠ© |

è¦è§£æ±ºé€™å€‹å•é¡Œï¼ŒTechAssist éœ€è¦ï¼š

1. **æ„åœ–åˆ†é¡**ï¼šåˆ¤æ–·ä½¿ç”¨è€…æƒ³åšä»€éº¼
2. **çµæ§‹åŒ–è¼¸å‡º**ï¼šè®“è¼¸å‡ºå¯è¢«ç¨‹å¼è§£æ
3. **å‹•æ…‹è·¯ç”±**ï¼šæ ¹æ“šæ„åœ–æ¡å–ä¸åŒè¡Œå‹•

è®“æˆ‘å€‘å¾ Prompt å·¥ç¨‹é–‹å§‹ã€‚

---

## 2.2 é€²éš Prompt æŠ€å·§

### 2.2.1 Chain-of-Thought (CoT)ï¼šè®“ LLM å±•ç¤ºæ€è€ƒéç¨‹

ç ”ç©¶é¡¯ç¤ºï¼Œè®“ LLM ã€Œå…ˆæ€è€ƒå†å›ç­”ã€èƒ½é¡¯è‘—æå‡è¤‡é›œä»»å‹™çš„æº–ç¢ºç‡ã€‚

**åŸç†**ï¼šè¦æ±‚æ¨¡å‹åœ¨çµ¦å‡ºæœ€çµ‚ç­”æ¡ˆå‰ï¼Œå…ˆè¼¸å‡ºæ¨ç†æ­¥é©Ÿã€‚

```python
from langchain_core.prompts import ChatPromptTemplate

# âŒ ç›´æ¥è¦æ±‚ç­”æ¡ˆï¼ˆå®¹æ˜“å‡ºéŒ¯ï¼‰
naive_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯æ•¸å­¸è€å¸«ã€‚"),
    ("human", "å¦‚æœä¸€å€‹ç­ç´šæœ‰ 30 äººï¼Œå…¶ä¸­ 40% æ˜¯å¥³ç”Ÿï¼Œå¥³ç”Ÿä¸­æœ‰ 1/3 æˆ´çœ¼é¡ï¼Œæœ‰å¤šå°‘å¥³ç”Ÿæˆ´çœ¼é¡ï¼Ÿ")
])

# âœ… Chain-of-Thoughtï¼ˆé€æ­¥æ¨ç†ï¼‰
cot_prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯æ•¸å­¸è€å¸«ã€‚
å›ç­”å•é¡Œæ™‚ï¼Œè«‹æŒ‰ä»¥ä¸‹æ­¥é©Ÿé€²è¡Œï¼š

1. **ç†è§£å•é¡Œ**ï¼šé‡è¿°å•é¡Œçš„é—œéµè³‡è¨Š
2. **åˆ—å‡ºå·²çŸ¥æ¢ä»¶**ï¼šæå–æ‰€æœ‰æ•¸å€¼
3. **é€æ­¥è¨ˆç®—**ï¼šå±•ç¤ºæ¯ä¸€æ­¥è¨ˆç®—éç¨‹
4. **é©—è­‰ç­”æ¡ˆ**ï¼šç¢ºèªè¨ˆç®—æ˜¯å¦åˆç†
5. **çµ¦å‡ºæœ€çµ‚ç­”æ¡ˆ**ï¼šæ˜ç¢ºæ¨™ç¤ºç­”æ¡ˆ"""),
    ("human", "{question}")
])
```

**CoT è®Šé«”**ï¼š

| è®Šé«” | èªªæ˜ | é©ç”¨å ´æ™¯ |
|------|------|----------|
| **Zero-Shot CoT** | åªåŠ ã€Œè®“æˆ‘å€‘ä¸€æ­¥ä¸€æ­¥æ€è€ƒã€ | å¿«é€Ÿæå‡æ¨ç† |
| **Few-Shot CoT** | æä¾›å¸¶æ¨ç†éç¨‹çš„ç¯„ä¾‹ | è¤‡é›œé‚è¼¯ä»»å‹™ |
| **Self-Consistency** | å¤šæ¬¡æ¡æ¨£å–å¤šæ•¸ç­”æ¡ˆ | éœ€è¦é«˜æº–ç¢ºåº¦ |

### 2.2.2 Few-Shot Learningï¼šç”¨ç¯„ä¾‹æ•™å° LLM

ç•¶ä»»å‹™é›£ä»¥ç”¨æ–‡å­—æè¿°ï¼Œæˆ–ä½ éœ€è¦ç‰¹å®šçš„è¼¸å‡ºé¢¨æ ¼æ™‚ï¼ŒFew-Shot Learning éå¸¸æœ‰æ•ˆã€‚

```python
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate

# â€¹1â€º å®šç¾©ç¯„ä¾‹
examples = [
    {
        "input": "ä»€éº¼æ˜¯è®Šæ•¸ï¼Ÿ",
        "output": """**ç°¡ç­”**ï¼šè®Šæ•¸æ˜¯å„²å­˜è³‡æ–™çš„å®¹å™¨ã€‚

**è©³è§£**ï¼š
åœ¨ç¨‹å¼ä¸­ï¼Œè®Šæ•¸å°±åƒä¸€å€‹æœ‰åå­—çš„ç›’å­ï¼Œä½ å¯ä»¥æŠŠè³‡æ–™æ”¾é€²å»ã€‚

**ç¯„ä¾‹**ï¼š
```python
name = "Alice"  # å­—ä¸²è®Šæ•¸
age = 25        # æ•´æ•¸è®Šæ•¸
```"""
    },
    {
        "input": "è§£é‡‹ for è¿´åœˆ",
        "output": """**ç°¡ç­”**ï¼šfor è¿´åœˆç”¨æ–¼é‡è¤‡åŸ·è¡Œç¨‹å¼ç¢¼æŒ‡å®šæ¬¡æ•¸ã€‚

**è©³è§£**ï¼š
ç•¶ä½ éœ€è¦å°ä¸€ç³»åˆ—å…ƒç´ åŸ·è¡Œç›¸åŒæ“ä½œæ™‚ï¼Œä½¿ç”¨ for è¿´åœˆã€‚

**ç¯„ä¾‹**ï¼š
```python
for i in range(3):
    print(f"ç¬¬ {i+1} æ¬¡")
# è¼¸å‡ºï¼š
# ç¬¬ 1 æ¬¡
# ç¬¬ 2 æ¬¡
# ç¬¬ 3 æ¬¡
```"""
    }
]

# â€¹2â€º å»ºç«‹ç¯„ä¾‹æ¨¡æ¿
example_prompt = ChatPromptTemplate.from_messages([
    ("human", "{input}"),
    ("ai", "{output}")
])

# â€¹3â€º å»ºç«‹ Few-Shot Prompt
few_shot_prompt = FewShotChatMessagePromptTemplate(
    example_prompt=example_prompt,
    examples=examples,
)

# â€¹4â€º çµ„åˆå®Œæ•´ Prompt
final_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ TechAssistã€‚è«‹æŒ‰ç…§ç¯„ä¾‹çš„æ ¼å¼å›ç­”æŠ€è¡“å•é¡Œã€‚"),
    few_shot_prompt,
    ("human", "{question}")
])

# æª¢è¦–å®Œæ•´ Prompt
print(final_prompt.format(question="ä»€éº¼æ˜¯éè¿´ï¼Ÿ"))
```

### 2.2.3 Prompt å„ªåŒ–æª¢æŸ¥æ¸…å–®

åœ¨è¨­è¨ˆ Prompt æ™‚ï¼Œä½¿ç”¨é€™å€‹æª¢æŸ¥æ¸…å–®ï¼š

| é …ç›® | å•é¡Œ | å„ªåŒ–æ–¹å‘ |
|------|------|----------|
| **è§’è‰²å®šç¾©** | LLM çŸ¥é“è‡ªå·±æ˜¯èª°å—ï¼Ÿ | æ˜ç¢ºå®šç¾©è§’è‰²èˆ‡å°ˆé•· |
| **ä»»å‹™æè¿°** | ç›®æ¨™æ¸…æ¥šå—ï¼Ÿ | ä½¿ç”¨å‹•è©é–‹é ­æè¿°æœŸæœ›è¡Œç‚º |
| **è¼¸å‡ºæ ¼å¼** | è¼¸å‡ºçµæ§‹æ˜ç¢ºå—ï¼Ÿ | æä¾›æ ¼å¼ç¯„ä¾‹æˆ– Schema |
| **é™åˆ¶æ¢ä»¶** | æœ‰æ²’æœ‰æ˜ç¢ºçš„ç¦æ­¢äº‹é …ï¼Ÿ | åˆ—å‡ºã€Œä¸è¦åšä»€éº¼ã€ |
| **ç¯„ä¾‹** | éœ€è¦ Few-Shot å—ï¼Ÿ | æä¾› 2-5 å€‹ä»£è¡¨æ€§ç¯„ä¾‹ |
| **æ€è€ƒå¼•å°** | éœ€è¦ CoT å—ï¼Ÿ | åŠ å…¥ã€Œè«‹å…ˆæ€è€ƒå†å›ç­”ã€ |

---

## 2.3 çµæ§‹åŒ–è¼¸å‡ºï¼šç”¨ Pydantic é¦´æœ LLM

### 2.3.1 ç‚ºä»€éº¼éœ€è¦çµæ§‹åŒ–è¼¸å‡ºï¼Ÿ

è‡ªç”±æ–‡æœ¬è¼¸å‡ºæœ‰å¹¾å€‹å•é¡Œï¼š

```python
# LLM å¯èƒ½é€™æ¨£å›ç­”ï¼š
response_1 = "é›£åº¦æ˜¯ä¸­ç­‰"
response_2 = "é€™æ˜¯ä¸€å€‹ä¸­ç­‰é›£åº¦çš„å•é¡Œ"
response_3 = "Difficulty: Medium"
```

é€™ä¸‰å€‹å›ç­”éƒ½è¡¨é”åŒæ¨£çš„æ„æ€ï¼Œä½†ç¨‹å¼å¾ˆé›£çµ±ä¸€è™•ç†ã€‚

**çµæ§‹åŒ–è¼¸å‡º**è®“ LLM æŒ‰ç…§é å®šç¾©çš„ Schema è¼¸å‡ºï¼š

```python
{
    "difficulty": "medium",
    "confidence": 0.85
}
```

### 2.3.2 ä½¿ç”¨ PydanticOutputParser

Pydantic æ˜¯ Python æœ€æµè¡Œçš„è³‡æ–™é©—è­‰åº«ï¼ŒLangChain æ·±åº¦æ•´åˆäº†å®ƒï¼š

```python
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
from enum import Enum

# â€¹1â€º å®šç¾©é›£åº¦ç­‰ç´š
class DifficultyLevel(str, Enum):
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"

# â€¹2â€º å®šç¾©è¼¸å‡º Schema
class TechExplanation(BaseModel):
    """æŠ€è¡“æ¦‚å¿µçš„çµæ§‹åŒ–è§£é‡‹"""

    concept: str = Field(description="æ¦‚å¿µåç¨±")
    one_liner: str = Field(description="ä¸€å¥è©±è§£é‡‹ï¼Œä¸è¶…é 30 å­—")
    explanation: str = Field(description="è©³ç´°è§£é‡‹ï¼Œ150-300 å­—")
    use_cases: list[str] = Field(description="3-5 å€‹å¯¦éš›ä½¿ç”¨å ´æ™¯")
    code_example: str | None = Field(
        default=None,
        description="ç¨‹å¼ç¢¼ç¯„ä¾‹ï¼ˆå¦‚é©ç”¨ï¼‰"
    )
    difficulty: DifficultyLevel = Field(description="é›£åº¦ç­‰ç´š")
    related_concepts: list[str] = Field(description="ç›¸é—œæ¦‚å¿µï¼Œ2-4 å€‹")

# â€¹3â€º å»ºç«‹è§£æå™¨
parser = PydanticOutputParser(pydantic_object=TechExplanation)

# â€¹4â€º æŸ¥çœ‹æ ¼å¼èªªæ˜
print(parser.get_format_instructions())
```

è¼¸å‡ºçš„æ ¼å¼èªªæ˜ï¼ˆç°¡åŒ–ï¼‰ï¼š

```
The output should be formatted as a JSON instance that conforms to the JSON schema below.

{
    "concept": "string",
    "one_liner": "string",
    "explanation": "string",
    "use_cases": ["string"],
    "code_example": "string or null",
    "difficulty": "beginner|intermediate|advanced",
    "related_concepts": ["string"]
}
```

### 2.3.3 æ•´åˆåˆ° Chain

```python
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate

# â€¹1â€º å»ºç«‹åŒ…å«æ ¼å¼èªªæ˜çš„ Prompt
prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ TechAssistï¼Œå°ˆæ¥­çš„æŠ€è¡“æ•™è‚²å°ˆå®¶ã€‚
è«‹æŒ‰ç…§æŒ‡å®šçš„ JSON æ ¼å¼è¼¸å‡ºä½ çš„è§£é‡‹ã€‚

{format_instructions}"""),
    ("human", "è«‹è§£é‡‹ï¼š{concept}")
])

# â€¹2â€º æ³¨å…¥æ ¼å¼èªªæ˜
prompt_with_format = prompt.partial(
    format_instructions=parser.get_format_instructions()
)

# â€¹3â€º å»ºç«‹ Chain
llm = ChatAnthropic(model="claude-3-5-sonnet-20241022")

chain = prompt_with_format | llm | parser

# â€¹4â€º èª¿ç”¨ä¸¦ç²å¾—çµæ§‹åŒ–è¼¸å‡º
result = chain.invoke({"concept": "ä¾è³´æ³¨å…¥"})

# result æ˜¯ TechExplanation ç‰©ä»¶
print(f"æ¦‚å¿µï¼š{result.concept}")
print(f"ä¸€å¥è©±ï¼š{result.one_liner}")
print(f"é›£åº¦ï¼š{result.difficulty.value}")
print(f"ä½¿ç”¨å ´æ™¯ï¼š{', '.join(result.use_cases)}")
```

### 2.3.4 è™•ç†è§£æéŒ¯èª¤

LLM æœ‰æ™‚å€™æœƒè¼¸å‡ºä¸ç¬¦åˆæ ¼å¼çš„å…§å®¹ï¼Œæˆ‘å€‘éœ€è¦å„ªé›…åœ°è™•ç†ï¼š

```python
from langchain_core.output_parsers import PydanticOutputParser
from langchain.output_parsers import OutputFixingParser

# â€¹1â€º åŸå§‹è§£æå™¨
base_parser = PydanticOutputParser(pydantic_object=TechExplanation)

# â€¹2â€º åŒ…è£æˆè‡ªå‹•ä¿®å¾©è§£æå™¨
fixing_parser = OutputFixingParser.from_llm(
    parser=base_parser,
    llm=llm
)

# ç•¶è§£æå¤±æ•—æ™‚ï¼ŒOutputFixingParser æœƒï¼š
# 1. æ•ç²éŒ¯èª¤
# 2. å°‡éŒ¯èª¤å’ŒåŸå§‹è¼¸å‡ºç™¼é€çµ¦ LLM
# 3. è«‹æ±‚ LLM ä¿®æ­£è¼¸å‡ºæ ¼å¼
```

### 2.3.5 ä½¿ç”¨ with_structured_outputï¼ˆæ¨è–¦ï¼‰

Claude å’Œ GPT-4 éƒ½æ”¯æ´åŸç”Ÿçš„çµæ§‹åŒ–è¼¸å‡ºåŠŸèƒ½ï¼Œæ›´åŠ å¯é ï¼š

```python
from langchain_anthropic import ChatAnthropic
from pydantic import BaseModel, Field

class TechExplanation(BaseModel):
    concept: str
    one_liner: str
    difficulty: str

llm = ChatAnthropic(model="claude-3-5-sonnet-20241022")

# â€¹1â€º ä½¿ç”¨ with_structured_output
structured_llm = llm.with_structured_output(TechExplanation)

# â€¹2â€º ç›´æ¥èª¿ç”¨ï¼Œè¼¸å‡ºå·²ç¶“æ˜¯ Pydantic ç‰©ä»¶
result = structured_llm.invoke("è§£é‡‹ä»€éº¼æ˜¯ API")
print(result.concept)  # ç›´æ¥å­˜å–å±¬æ€§
```

é€™ç¨®æ–¹å¼çš„å„ªé»ï¼š

- æ›´å¯é ï¼šæ¨¡å‹åŸç”Ÿæ”¯æ´
- æ›´ç°¡æ½”ï¼šä¸éœ€è¦åœ¨ Prompt ä¸­åŠ å…¥æ ¼å¼èªªæ˜
- æ›´å¿«é€Ÿï¼šæ¸›å°‘ token æ¶ˆè€—

---

## 2.4 å¯¦ä½œï¼šæ„åœ–åˆ†é¡å™¨

ç¾åœ¨ï¼Œè®“æˆ‘å€‘å»ºç«‹ä¸€å€‹æ„åœ–åˆ†é¡å™¨ï¼Œè®“ TechAssist èƒ½å¤ åˆ¤æ–·ä½¿ç”¨è€…æƒ³åšä»€éº¼ã€‚

### 2.4.1 å®šç¾©æ„åœ–é¡å‹

```python
# techassist/intents.py
from enum import Enum
from pydantic import BaseModel, Field

class Intent(str, Enum):
    """ä½¿ç”¨è€…æ„åœ–é¡å‹"""
    GREETING = "greeting"           # æ‰“æ‹›å‘¼
    FAREWELL = "farewell"           # é“åˆ¥
    TECH_QUESTION = "tech_question" # æŠ€è¡“å•é¡Œ
    CODE_REVIEW = "code_review"     # ç¨‹å¼ç¢¼å¯©æŸ¥
    CODE_GENERATION = "code_generation"  # ç¨‹å¼ç¢¼ç”Ÿæˆ
    COMPARISON = "comparison"       # æŠ€è¡“æ¯”è¼ƒ
    TROUBLESHOOTING = "troubleshooting"  # å•é¡Œæ’è§£
    OFF_TOPIC = "off_topic"         # éæŠ€è¡“è©±é¡Œ
    UNCLEAR = "unclear"             # ä¸æ¸…æ¥š


class IntentClassification(BaseModel):
    """æ„åœ–åˆ†é¡çµæœ"""

    intent: Intent = Field(description="åˆ¤æ–·çš„æ„åœ–é¡å‹")
    confidence: float = Field(
        description="ä¿¡å¿ƒåˆ†æ•¸ï¼Œ0.0-1.0",
        ge=0.0,
        le=1.0
    )
    reasoning: str = Field(
        description="åˆ¤æ–·ç†ç”±ï¼Œç°¡çŸ­èªªæ˜ç‚ºä»€éº¼æ˜¯é€™å€‹æ„åœ–"
    )
    extracted_topic: str | None = Field(
        default=None,
        description="æå–çš„ä¸»é¡Œï¼ˆå¦‚é©ç”¨ï¼‰"
    )
    suggested_action: str = Field(
        description="å»ºè­°çš„ä¸‹ä¸€æ­¥è¡Œå‹•"
    )
```

### 2.4.2 å»ºç«‹åˆ†é¡å™¨ Chain

```python
# techassist/classifier.py
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate

from .intents import IntentClassification, Intent

# â€¹1â€º åˆ†é¡å™¨ Prompt
CLASSIFIER_PROMPT = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ TechAssist çš„æ„åœ–åˆ†é¡æ¨¡çµ„ã€‚

## ä»»å‹™
åˆ†æä½¿ç”¨è€…çš„è¼¸å…¥ï¼Œåˆ¤æ–·å…¶æ„åœ–é¡å‹ã€‚

## æ„åœ–é¡å‹èªªæ˜
- greeting: æ‰“æ‹›å‘¼ã€å•å€™ï¼ˆå¦‚ï¼šä½ å¥½ã€Hiã€æ—©å®‰ï¼‰
- farewell: é“åˆ¥ï¼ˆå¦‚ï¼šå†è¦‹ã€æ‹œæ‹œã€æ„Ÿè¬ï¼‰
- tech_question: è©¢å•æŠ€è¡“æ¦‚å¿µï¼ˆå¦‚ï¼šä»€éº¼æ˜¯ APIï¼Ÿï¼‰
- code_review: è«‹æ±‚å¯©æŸ¥ç¨‹å¼ç¢¼ï¼ˆå¦‚ï¼šå¹«æˆ‘çœ‹çœ‹é€™æ®µç¨‹å¼ç¢¼ï¼‰
- code_generation: è«‹æ±‚ç”Ÿæˆç¨‹å¼ç¢¼ï¼ˆå¦‚ï¼šå¹«æˆ‘å¯«ä¸€å€‹å‡½æ•¸ï¼‰
- comparison: æ¯”è¼ƒæŠ€è¡“é¸é …ï¼ˆå¦‚ï¼šPython å’Œ Java å“ªå€‹å¥½ï¼Ÿï¼‰
- troubleshooting: æ’è§£å•é¡Œï¼ˆå¦‚ï¼šæˆ‘çš„ç¨‹å¼å ±éŒ¯äº†ï¼‰
- off_topic: èˆ‡æŠ€è¡“ç„¡é—œçš„è©±é¡Œ
- unclear: ç„¡æ³•åˆ¤æ–·æ„åœ–

## åˆ¤æ–·åŸå‰‡
1. å„ªå…ˆè€ƒæ…®æ˜ç¢ºçš„æ„åœ–æŒ‡ç¤ºè©
2. å¦‚æœåŒ…å«ç¨‹å¼ç¢¼ï¼Œè€ƒæ…®æ˜¯ code_review æˆ– troubleshooting
3. å¦‚æœæœ‰ã€Œå¥½ã€ã€ã€Œå„ªã€ã€ã€Œé¸ã€ç­‰è©ï¼Œè€ƒæ…®æ˜¯ comparison
4. ä¿¡å¿ƒåˆ†æ•¸åæ˜ ç¢ºå®šç¨‹åº¦ï¼Œæ¨¡ç³Šæ™‚çµ¦è¼ƒä½åˆ†æ•¸

## å»ºè­°è¡Œå‹•
æ ¹æ“šæ„åœ–çµ¦å‡ºå…·é«”çš„è™•ç†å»ºè­°ã€‚"""),
    ("human", "è«‹åˆ†æé€™å€‹è¼¸å…¥çš„æ„åœ–ï¼š\n\n{user_input}")
])


def create_intent_classifier():
    """å»ºç«‹æ„åœ–åˆ†é¡å™¨"""
    llm = ChatAnthropic(model="claude-3-5-sonnet-20241022")

    # â€¹2â€º ä½¿ç”¨ with_structured_output
    structured_llm = llm.with_structured_output(IntentClassification)

    # â€¹3â€º çµ„åˆ Chain
    chain = CLASSIFIER_PROMPT | structured_llm

    return chain
```

### 2.4.3 æ¸¬è©¦åˆ†é¡å™¨

```python
# test_classifier.py
from techassist.classifier import create_intent_classifier

classifier = create_intent_classifier()

test_cases = [
    "ä½ å¥½ï¼",
    "ä»€éº¼æ˜¯ REST APIï¼Ÿ",
    "å¹«æˆ‘çœ‹çœ‹é€™æ®µç¨‹å¼ç¢¼æœ‰æ²’æœ‰å•é¡Œï¼šdef foo(): pass",
    "Python å’Œ Go å“ªå€‹æ•ˆèƒ½æ¯”è¼ƒå¥½ï¼Ÿ",
    "æˆ‘çš„ç¨‹å¼ä¸€ç›´å ± TypeErrorï¼Œæ€éº¼è¾¦ï¼Ÿ",
    "ä»Šå¤©å¤©æ°£çœŸå¥½",
    "asdfghjkl",
]

for user_input in test_cases:
    result = classifier.invoke({"user_input": user_input})
    print(f"\nè¼¸å…¥ï¼š{user_input}")
    print(f"æ„åœ–ï¼š{result.intent.value}")
    print(f"ä¿¡å¿ƒï¼š{result.confidence:.2f}")
    print(f"ç†ç”±ï¼š{result.reasoning}")
    print(f"å»ºè­°ï¼š{result.suggested_action}")
    print("-" * 50)
```

é æœŸè¼¸å‡ºï¼š

```
è¼¸å…¥ï¼šä½ å¥½ï¼
æ„åœ–ï¼šgreeting
ä¿¡å¿ƒï¼š0.98
ç†ç”±ï¼šé€™æ˜¯ä¸€å€‹æ¨™æº–çš„ä¸­æ–‡å•å€™èª
å»ºè­°ï¼šå›è¦†å•å€™ï¼Œä¸¦è©¢å•æœ‰ä»€éº¼å¯ä»¥å¹«åŠ©çš„

--------------------------------------------------

è¼¸å…¥ï¼šä»€éº¼æ˜¯ REST APIï¼Ÿ
æ„åœ–ï¼štech_question
ä¿¡å¿ƒï¼š0.95
ç†ç”±ï¼šä½¿ç”¨ã€Œä»€éº¼æ˜¯ã€å¥å‹è©¢å•æŠ€è¡“æ¦‚å¿µ
å»ºè­°ï¼šæä¾› REST API çš„æ¸…æ™°è§£é‡‹ï¼ŒåŒ…å«å®šç¾©ã€ç‰¹é»å’Œç¯„ä¾‹

--------------------------------------------------

è¼¸å…¥ï¼šPython å’Œ Go å“ªå€‹æ•ˆèƒ½æ¯”è¼ƒå¥½ï¼Ÿ
æ„åœ–ï¼šcomparison
ä¿¡å¿ƒï¼š0.92
ç†ç”±ï¼šä½¿ç”¨ã€Œå“ªå€‹...æ¯”è¼ƒå¥½ã€çš„æ¯”è¼ƒå¥å‹
å»ºè­°ï¼šå®¢è§€æ¯”è¼ƒå…©ç¨®èªè¨€çš„æ•ˆèƒ½ç‰¹é»ï¼Œé¿å…åé —
```

### 2.4.4 å»ºç«‹æ„åœ–è·¯ç”±å™¨

æ ¹æ“šæ„åœ–ï¼Œæˆ‘å€‘å¯ä»¥å°‡è«‹æ±‚è·¯ç”±åˆ°ä¸åŒçš„è™•ç†å™¨ï¼š

```python
# techassist/router.py
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from .intents import Intent, IntentClassification
from .classifier import create_intent_classifier

def route_by_intent(classification: IntentClassification) -> str:
    """æ ¹æ“šæ„åœ–è¿”å›å°æ‡‰çš„è™•ç†å™¨åç¨±"""
    routing_map = {
        Intent.GREETING: "greeting_handler",
        Intent.FAREWELL: "farewell_handler",
        Intent.TECH_QUESTION: "tech_qa_handler",
        Intent.CODE_REVIEW: "code_review_handler",
        Intent.CODE_GENERATION: "code_gen_handler",
        Intent.COMPARISON: "comparison_handler",
        Intent.TROUBLESHOOTING: "troubleshoot_handler",
        Intent.OFF_TOPIC: "off_topic_handler",
        Intent.UNCLEAR: "clarification_handler",
    }
    return routing_map.get(classification.intent, "default_handler")


def create_routing_chain():
    """å»ºç«‹è·¯ç”± Chain"""
    classifier = create_intent_classifier()

    chain = (
        {"user_input": RunnablePassthrough()}
        | classifier
        | RunnableLambda(lambda x: {
            "classification": x,
            "handler": route_by_intent(x)
        })
    )

    return chain
```

---

## 2.5 å¯¦ä½œï¼šTechAssist v0.2

ç¾åœ¨ï¼Œè®“æˆ‘å€‘å°‡æ„åœ–åˆ†é¡æ•´åˆåˆ° TechAssist ä¸­ã€‚

### 2.5.1 è™•ç†å™¨æ¨¡çµ„

```python
# techassist/handlers.py
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

llm = ChatAnthropic(model="claude-3-5-sonnet-20241022")
parser = StrOutputParser()

# â€¹1â€º å•å€™è™•ç†å™¨
greeting_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯ TechAssistã€‚ç”¨æˆ¶åœ¨æ‰“æ‹›å‘¼ï¼Œè«‹å‹å–„å›æ‡‰ä¸¦è©¢å•æœ‰ä»€éº¼å¯ä»¥å¹«åŠ©çš„ã€‚ä¿æŒç°¡çŸ­ï¼ˆ2-3 å¥è©±ï¼‰ã€‚"),
    ("human", "{user_input}")
])
greeting_handler = greeting_prompt | llm | parser

# â€¹2â€º æŠ€è¡“å•ç­”è™•ç†å™¨
tech_qa_prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ TechAssistï¼Œå°ˆæ¥­çš„æŠ€è¡“åŠ©ç†ã€‚

å›ç­”æ™‚è«‹ï¼š
1. å…ˆçµ¦ä¸€å¥è©±ç¸½çµ
2. å†è©³ç´°è§£é‡‹ï¼ˆ100-200 å­—ï¼‰
3. å¦‚é©ç”¨ï¼Œæä¾›ç¨‹å¼ç¢¼ç¯„ä¾‹
4. ä½¿ç”¨ç¹é«”ä¸­æ–‡"""),
    ("human", "{user_input}")
])
tech_qa_handler = tech_qa_prompt | llm | parser

# â€¹3â€º æ¯”è¼ƒè™•ç†å™¨
comparison_prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ TechAssistï¼Œå°ˆæ¥­çš„æŠ€è¡“é¡§å•ã€‚

æ¯”è¼ƒæŠ€è¡“é¸é …æ™‚ï¼š
1. ä¿æŒå®¢è§€ï¼Œä¸è¦æœ‰åè¦‹
2. åˆ—å‡ºå„è‡ªçš„å„ªç¼ºé»
3. èªªæ˜é©ç”¨å ´æ™¯
4. å¦‚æœé©åˆï¼Œçµ¦å‡ºå»ºè­°
5. ä½¿ç”¨è¡¨æ ¼å‘ˆç¾æ¯”è¼ƒçµæœ"""),
    ("human", "{user_input}")
])
comparison_handler = comparison_prompt | llm | parser

# â€¹4â€º å•é¡Œæ’è§£è™•ç†å™¨
troubleshoot_prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ TechAssistï¼Œå°ˆæ¥­çš„é™¤éŒ¯å°ˆå®¶ã€‚

æ’è§£å•é¡Œæ™‚ï¼š
1. ç¢ºèªéŒ¯èª¤è¨Šæ¯å’Œç—‡ç‹€
2. åˆ—å‡ºå¯èƒ½çš„åŸå› ï¼ˆå¾æœ€å¸¸è¦‹é–‹å§‹ï¼‰
3. æä¾›é€æ­¥çš„è§£æ±ºæ–¹æ¡ˆ
4. å¦‚æœ‰ç¨‹å¼ç¢¼ï¼Œåˆ†æå¯èƒ½çš„å•é¡Œé»"""),
    ("human", "{user_input}")
])
troubleshoot_handler = troubleshoot_prompt | llm | parser

# â€¹5â€º éæŠ€è¡“è©±é¡Œè™•ç†å™¨
off_topic_prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ TechAssistï¼Œå°ˆæ¥­çš„æŠ€è¡“åŠ©ç†ã€‚
ç”¨æˆ¶çš„å•é¡Œä¸æ˜¯æŠ€è¡“ç›¸é—œã€‚è«‹ç¦®è²Œåœ°å‘ŠçŸ¥ä½ å°ˆæ³¨æ–¼æŠ€è¡“å•é¡Œï¼Œä¸¦è©¢å•æ˜¯å¦æœ‰æŠ€è¡“å•é¡Œéœ€è¦å¹«åŠ©ã€‚ä¿æŒå‹å–„ï¼Œä¸è¦è®“ç”¨æˆ¶æ„Ÿåˆ°è¢«æ‹’çµ•ã€‚"""),
    ("human", "{user_input}")
])
off_topic_handler = off_topic_prompt | llm | parser

# â€¹6â€º è™•ç†å™¨æ˜ å°„
HANDLERS = {
    "greeting_handler": greeting_handler,
    "farewell_handler": greeting_handler,  # ä½¿ç”¨ç›¸åŒè™•ç†å™¨
    "tech_qa_handler": tech_qa_handler,
    "code_review_handler": tech_qa_handler,  # å¾ŒçºŒç« ç¯€æœƒå°ˆé–€å¯¦ä½œ
    "code_gen_handler": tech_qa_handler,     # å¾ŒçºŒç« ç¯€æœƒå°ˆé–€å¯¦ä½œ
    "comparison_handler": comparison_handler,
    "troubleshoot_handler": troubleshoot_handler,
    "off_topic_handler": off_topic_handler,
    "clarification_handler": off_topic_handler,
    "default_handler": tech_qa_handler,
}
```

### 2.5.2 æ•´åˆä¸»æµç¨‹

```python
# techassist/core.py
from .classifier import create_intent_classifier
from .router import route_by_intent
from .handlers import HANDLERS

class TechAssistV2:
    """TechAssist v0.2 - å…·å‚™æ„åœ–ç†è§£èƒ½åŠ›"""

    def __init__(self):
        self.classifier = create_intent_classifier()

    def process(self, user_input: str) -> dict:
        """è™•ç†ä½¿ç”¨è€…è¼¸å…¥

        Args:
            user_input: ä½¿ç”¨è€…çš„è¼¸å…¥æ–‡å­—

        Returns:
            åŒ…å«åˆ†é¡çµæœå’Œå›æ‡‰çš„å­—å…¸
        """
        # â€¹1â€º åˆ†é¡æ„åœ–
        classification = self.classifier.invoke({"user_input": user_input})

        # â€¹2â€º è·¯ç”±åˆ°è™•ç†å™¨
        handler_name = route_by_intent(classification)
        handler = HANDLERS.get(handler_name, HANDLERS["default_handler"])

        # â€¹3â€º ç”Ÿæˆå›æ‡‰
        response = handler.invoke({"user_input": user_input})

        return {
            "intent": classification.intent.value,
            "confidence": classification.confidence,
            "reasoning": classification.reasoning,
            "response": response
        }

    def stream_process(self, user_input: str):
        """ä¸²æµè™•ç†ä½¿ç”¨è€…è¼¸å…¥"""
        # å…ˆåˆ†é¡
        classification = self.classifier.invoke({"user_input": user_input})

        # è·¯ç”±ä¸¦ä¸²æµå›æ‡‰
        handler_name = route_by_intent(classification)
        handler = HANDLERS.get(handler_name, HANDLERS["default_handler"])

        yield {
            "type": "classification",
            "intent": classification.intent.value,
            "confidence": classification.confidence
        }

        for chunk in handler.stream({"user_input": user_input}):
            yield {"type": "content", "content": chunk}
```

### 2.5.3 æ›´æ–° CLI

```python
# techassist/cli_v2.py
from .core import TechAssistV2

def run_cli_v2():
    """åŸ·è¡Œ TechAssist v0.2 CLI"""
    print("=" * 60)
    print("ğŸ¤– TechAssist v0.2 - æ™ºèƒ½æ„åœ–è­˜åˆ¥ç‰ˆ")
    print("=" * 60)
    print("æˆ‘ç¾åœ¨èƒ½æ›´å¥½åœ°ç†è§£ä½ çš„å•é¡Œäº†ï¼")
    print("è¼¸å…¥ 'quit' é›¢é–‹ã€‚")
    print("-" * 60)

    assistant = TechAssistV2()

    while True:
        try:
            user_input = input("\nğŸ“ ä½ çš„å•é¡Œï¼š").strip()

            if not user_input:
                continue

            if user_input.lower() in ('quit', 'exit', 'q'):
                print("\nğŸ‘‹ æ„Ÿè¬ä½¿ç”¨ TechAssistï¼Œå†è¦‹ï¼")
                break

            print("\nğŸ” åˆ†æä¸­...")

            # ä¸²æµè™•ç†
            first_chunk = True
            for item in assistant.stream_process(user_input):
                if item["type"] == "classification":
                    print(f"ğŸ“Š æ„åœ–ï¼š{item['intent']} (ä¿¡å¿ƒï¼š{item['confidence']:.0%})")
                    print("\nğŸ“– å›ç­”ï¼š")
                elif item["type"] == "content":
                    print(item["content"], end="", flush=True)

            print("\n")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ æ„Ÿè¬ä½¿ç”¨ TechAssistï¼Œå†è¦‹ï¼")
            break
        except Exception as e:
            print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
```

---

## 2.6 é€²éšæŠ€å·§ï¼šå‹•æ…‹ Few-Shot

æœ‰æ™‚å€™ï¼Œä½ éœ€è¦æ ¹æ“šè¼¸å…¥å‹•æ…‹é¸æ“‡ç›¸é—œçš„ç¯„ä¾‹ï¼š

```python
from langchain_core.prompts import FewShotChatMessagePromptTemplate
from langchain_core.example_selectors import SemanticSimilarityExampleSelector
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

# â€¹1â€º å®šç¾©ç¯„ä¾‹æ± 
examples = [
    {"input": "ä»€éº¼æ˜¯ REST APIï¼Ÿ", "output": "REST API æ˜¯..."},
    {"input": "Python åˆ—è¡¨æ€éº¼ç”¨ï¼Ÿ", "output": "Python åˆ—è¡¨æ˜¯..."},
    {"input": "Docker æ˜¯ä»€éº¼ï¼Ÿ", "output": "Docker æ˜¯..."},
    {"input": "å¦‚ä½•ä½¿ç”¨ Gitï¼Ÿ", "output": "Git æ˜¯ç‰ˆæœ¬æ§åˆ¶å·¥å…·..."},
    {"input": "ä»€éº¼æ˜¯å¾®æœå‹™ï¼Ÿ", "output": "å¾®æœå‹™æ˜¯ä¸€ç¨®æ¶æ§‹æ¨¡å¼..."},
    # ... æ›´å¤šç¯„ä¾‹
]

# â€¹2â€º å»ºç«‹èªç¾©ç›¸ä¼¼åº¦é¸æ“‡å™¨
example_selector = SemanticSimilarityExampleSelector.from_examples(
    examples,
    OpenAIEmbeddings(),
    FAISS,
    k=2  # é¸æ“‡æœ€ç›¸ä¼¼çš„ 2 å€‹ç¯„ä¾‹
)

# â€¹3â€º å»ºç«‹å‹•æ…‹ Few-Shot Prompt
example_prompt = ChatPromptTemplate.from_messages([
    ("human", "{input}"),
    ("ai", "{output}")
])

dynamic_few_shot = FewShotChatMessagePromptTemplate(
    example_selector=example_selector,
    example_prompt=example_prompt,
)

# â€¹4â€º ä½¿ç”¨
final_prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯æŠ€è¡“åŠ©ç†ã€‚è«‹åƒè€ƒé¡ä¼¼å•é¡Œçš„å›ç­”é¢¨æ ¼ã€‚"),
    dynamic_few_shot,
    ("human", "{question}")
])

# ç•¶å•ã€ŒKubernetes æ˜¯ä»€éº¼ï¼Ÿã€æ™‚ï¼Œ
# æœƒè‡ªå‹•é¸æ“‡ã€ŒDocker æ˜¯ä»€éº¼ï¼Ÿã€å’Œã€Œä»€éº¼æ˜¯å¾®æœå‹™ï¼Ÿã€ä½œç‚ºç¯„ä¾‹
```

---

## 2.7 æœ¬ç« å›é¡§

### æ ¸å¿ƒæŠ€å·§

| æŠ€å·§ | ç”¨é€” | ä½•æ™‚ä½¿ç”¨ |
|------|------|----------|
| **Chain-of-Thought** | æå‡æ¨ç†èƒ½åŠ› | è¤‡é›œé‚è¼¯ã€æ•¸å­¸å•é¡Œ |
| **Few-Shot Learning** | æŒ‡å°è¼¸å‡ºé¢¨æ ¼ | ç‰¹å®šæ ¼å¼ã€ç‰¹å®šèªæ°£ |
| **Pydantic çµæ§‹åŒ–è¼¸å‡º** | ç¢ºä¿æ ¼å¼ä¸€è‡´ | éœ€è¦ç¨‹å¼è§£æè¼¸å‡ºæ™‚ |
| **with_structured_output** | åŸç”Ÿçµæ§‹åŒ–è¼¸å‡º | æ¨¡å‹æ”¯æ´æ™‚å„ªå…ˆä½¿ç”¨ |
| **å‹•æ…‹ Few-Shot** | ä¸Šä¸‹æ–‡ç›¸é—œç¯„ä¾‹ | ç¯„ä¾‹æ± å¤§ã€éœ€è¦ç²¾æº–åŒ¹é… |

### è¨­è¨ˆåŸå‰‡

1. **æ˜ç¢ºå‹ééš±æ™¦**ï¼šåœ¨ Prompt ä¸­æ˜ç¢ºèªªæ˜æœŸæœ›
2. **çµæ§‹åŒ–è³‡æ–™æµ**ï¼šä½¿ç”¨ Pydantic ç¢ºä¿è³‡æ–™ä¸€è‡´æ€§
3. **å¤±æ•—å„ªé›…è™•ç†**ï¼šä½¿ç”¨ OutputFixingParser è™•ç†è§£æéŒ¯èª¤

### TechAssist é‡Œç¨‹ç¢‘

- âœ… v0.1ï¼šåŸºæ–¼ Chain çš„ç°¡å–®å•ç­”
- âœ… v0.2ï¼šå…·å‚™æ„åœ–åˆ†é¡èˆ‡å‹•æ…‹è·¯ç”±

---

## 2.8 ä¸‹ä¸€ç« é å‘Š

TechAssist v0.2 èƒ½ç†è§£æ„åœ–ï¼Œä½†å®ƒä»ç„¶åªèƒ½ã€Œèªªã€ä¸èƒ½ã€Œåšã€ã€‚ç•¶ä½¿ç”¨è€…èªªã€Œå¹«æˆ‘æŸ¥ä¸€ä¸‹ Python 3.12 çš„æ–°åŠŸèƒ½ã€ï¼Œå®ƒåªèƒ½æ ¹æ“šè¨“ç·´è³‡æ–™å›ç­”ï¼Œç„¡æ³•å­˜å–æœ€æ–°è³‡è¨Šã€‚

åœ¨ä¸‹ä¸€ç« ï¼Œæˆ‘å€‘å°‡å­¸ç¿’ **Tool Useâ€”â€”è³¦äºˆ AI æ‰‹è…³**ï¼š

- ç†è§£ Function Calling çš„åŸç†
- å¯¦ä½œè‡ªå®šç¾©å·¥å…·ï¼ˆç¶²é æœå°‹ã€API èª¿ç”¨ã€æ–‡ä»¶è®€å–ï¼‰
- å»ºç«‹ TechAssist v0.3ï¼šèƒ½å¤ æœå°‹æ–‡ä»¶çš„æ™ºèƒ½åŠ©ç†

---

## ç·´ç¿’é¡Œ

1. **åŸºç¤ç·´ç¿’**ï¼šç‚ºæ„åœ–åˆ†é¡å™¨æ–°å¢ä¸€å€‹ `feedback` æ„åœ–ï¼Œç”¨æ–¼è­˜åˆ¥ä½¿ç”¨è€…çš„è®šç¾æˆ–æŠ±æ€¨ã€‚

2. **é€²éšç·´ç¿’**ï¼šå¯¦ä½œä¸€å€‹ `CodeReviewResult` Pydantic æ¨¡å‹ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
   - `issues`: å•é¡Œåˆ—è¡¨ï¼ˆåŒ…å«è¡Œè™Ÿã€å•é¡Œæè¿°ã€åš´é‡ç¨‹åº¦ï¼‰
   - `suggestions`: æ”¹é€²å»ºè­°
   - `overall_score`: æ•´é«”è©•åˆ†ï¼ˆ1-10ï¼‰

3. **æŒ‘æˆ°ç·´ç¿’**ï¼šå¯¦ä½œå‹•æ…‹ Few-Shot é¸æ“‡å™¨ï¼Œæ ¹æ“šå•é¡Œçš„æŠ€è¡“é ˜åŸŸï¼ˆå‰ç«¯/å¾Œç«¯/DevOpsï¼‰é¸æ“‡ç›¸é—œç¯„ä¾‹ã€‚

---

## å»¶ä¼¸é–±è®€

- [Pydantic å®˜æ–¹æ–‡ä»¶ï¼šModel Configuration](https://docs.pydantic.dev/latest/concepts/config/)
- [LangChainï¼šStructured Output](https://python.langchain.com/docs/how_to/structured_output/)
- [Chain-of-Thought Prompting è«–æ–‡](https://arxiv.org/abs/2201.11903)
