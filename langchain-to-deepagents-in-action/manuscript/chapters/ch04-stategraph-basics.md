# Chapter 4: ç‹€æ…‹æ©Ÿæ€ç¶­â€”â€”StateGraph åŸºç¤Ž

> ã€Œè¤‡é›œç³»çµ±çš„é—œéµä¸åœ¨æ–¼åšä»€éº¼ï¼Œè€Œåœ¨æ–¼å¦‚ä½•ç®¡ç†ç‹€æ…‹ã€‚ã€

---

## æœ¬ç« å­¸ç¿’ç›®æ¨™

å®Œæˆæœ¬ç« å¾Œï¼Œä½ å°‡èƒ½å¤ ï¼š

- ç†è§£ç‚ºä»€éº¼éœ€è¦å¾ž Chain æ¼”é€²åˆ° Graph
- æŽŒæ¡ LangGraph çš„æ ¸å¿ƒæ¦‚å¿µï¼šStateã€Nodeã€Edge
- è¨­è¨ˆå¯é çš„ç‹€æ…‹ Schema
- å¯¦ç¾å¾ªç’°ã€é‡è©¦èˆ‡éŒ¯èª¤æ¢å¾©æ©Ÿåˆ¶
- å®Œæˆ TechAssist v0.5ï¼šå…·å‚™ç‹€æ…‹ç®¡ç†çš„å·¥ä½œæµ

---

## 4.1 å ´æ™¯å¼•å…¥ï¼šç•¶ Chain ä¸å¤ ç”¨æ™‚

TechAssist v0.3 èƒ½ä½¿ç”¨å·¥å…·ï¼Œä½†ä»”ç´°è§€å¯Ÿå®ƒçš„å·¥ä½œæ–¹å¼ï¼š

```python
# v0.3 çš„æ ¸å¿ƒé‚è¼¯
response = llm_with_tools.invoke(messages)
while response.tool_calls:
    # åŸ·è¡Œå·¥å…·
    for tool_call in response.tool_calls:
        result = tool.invoke(tool_call["args"])
        messages.append(tool_message)
    # å†æ¬¡èª¿ç”¨ LLM
    response = llm_with_tools.invoke(messages)
```

é€™å€‹ `while` è¿´åœˆçœ‹èµ·ä¾†ç°¡å–®ï¼Œä½†å­˜åœ¨åš´é‡å•é¡Œï¼š

| å•é¡Œ | èªªæ˜Ž | å¾Œæžœ |
|------|------|------|
| **ç„¡é™å¾ªç’°** | å¦‚æžœ LLM ä¸€ç›´èª¿ç”¨å·¥å…·å‘¢ï¼Ÿ | ç³»çµ±å´©æ½°æˆ–å¸³å–®çˆ†ç‚¸ |
| **éŒ¯èª¤è™•ç†** | å·¥å…·åŸ·è¡Œå¤±æ•—æ€Žéº¼è¾¦ï¼Ÿ | æ•´å€‹æµç¨‹çµ‚æ­¢ |
| **ç‹€æ…‹ä¸Ÿå¤±** | å¦‚æžœç¨‹åºä¸­æ–·ï¼Ÿ | å¿…é ˆå¾žé ­é–‹å§‹ |
| **å¯è§€æ¸¬æ€§** | ç¾åœ¨åŸ·è¡Œåˆ°å“ªä¸€æ­¥ï¼Ÿ | å®Œå…¨ç„¡æ³•è¿½è¹¤ |
| **æ¸¬è©¦å›°é›£** | å¦‚ä½•æ¸¬è©¦ç‰¹å®šå ´æ™¯ï¼Ÿ | é›£ä»¥éš”é›¢æ¸¬è©¦ |

é€™äº›å•é¡Œçš„æ ¹æºåœ¨æ–¼ï¼š**Chain æ˜¯ç„¡ç‹€æ…‹çš„ç·šæ€§åŸ·è¡Œï¼Œç¼ºä¹å°åŸ·è¡Œæµç¨‹çš„ç²¾ç´°æŽ§åˆ¶**ã€‚

### 4.1.1 çœŸå¯¦å ´æ™¯ï¼šè¤‡é›œçš„å·¥ä½œæµ

è€ƒæ…®é€™å€‹çœŸå¯¦éœ€æ±‚â€”â€”TechAssist éœ€è¦è™•ç†ç¨‹å¼ç¢¼å¯©æŸ¥ï¼š

```mermaid
graph TD
    A[æŽ¥æ”¶ç¨‹å¼ç¢¼] --> B{æ˜¯å¦æœ‰æ•ˆç¨‹å¼ç¢¼ï¼Ÿ}
    B -->|å¦| C[è«‹æ±‚æ¾„æ¸…]
    C --> A
    B -->|æ˜¯| D[éœæ…‹åˆ†æž]
    D --> E{ç™¼ç¾å•é¡Œï¼Ÿ}
    E -->|æ˜¯| F[ç”Ÿæˆä¿®å¾©å»ºè­°]
    F --> G{å»ºè­°å¯åŸ·è¡Œï¼Ÿ}
    G -->|å¦| H[äººå·¥å¯©æ ¸]
    G -->|æ˜¯| I[è‡ªå‹•æ‡‰ç”¨ä¿®å¾©]
    E -->|å¦| J[ç”Ÿæˆå¯©æŸ¥å ±å‘Š]
    I --> J
    H --> J
    J --> K[å®Œæˆ]
```

é€™å€‹æµç¨‹æœ‰ï¼š
- **æ¢ä»¶åˆ†æ”¯**ï¼šæ ¹æ“šçµæžœèµ°ä¸åŒè·¯å¾‘
- **å¾ªç’°**ï¼šç„¡æ•ˆè¼¸å…¥éœ€è¦é‡æ–°é–‹å§‹
- **äººæ©Ÿå”ä½œ**ï¼šæŸäº›æ±ºç­–éœ€è¦äººå·¥ä»‹å…¥
- **ç‹€æ…‹ä¿æŒ**ï¼šéœ€è¦è¨˜ä½ä¹‹å‰çš„åˆ†æžçµæžœ

ç”¨ Chain å¯¦ç¾é€™å€‹æµç¨‹æœƒè®Šæˆä¸€å †å·¢ç‹€çš„ if-elseï¼Œé›£ä»¥ç¶­è­·ã€‚

**é€™å°±æ˜¯ LangGraph è¦è§£æ±ºçš„å•é¡Œã€‚**

---

## 4.2 LangGraph æ ¸å¿ƒæ¦‚å¿µ

### 4.2.1 å¾ž Chain åˆ° Graph

LangGraph å°‡æ‡‰ç”¨å»ºæ¨¡ç‚º**æœ‰å‘åœ– (Directed Graph)**ï¼š

| æ¦‚å¿µ | Chain æ€ç¶­ | Graph æ€ç¶­ |
|------|-----------|-----------|
| **çµæ§‹** | ç·šæ€§åºåˆ— | æœ‰å‘åœ– |
| **æµç¨‹æŽ§åˆ¶** | å›ºå®šé †åº | æ¢ä»¶åˆ†æ”¯ã€å¾ªç’° |
| **ç‹€æ…‹** | éš±å¼å‚³éž | é¡¯å¼å®šç¾© |
| **éŒ¯èª¤è™•ç†** | æ‹‹å‡ºç•°å¸¸ | å¯æ¢å¾©çš„ç‹€æ…‹ |
| **å¯è§€æ¸¬æ€§** | é»‘ç›’ | æ¯å€‹ç¯€é»žå¯è¿½è¹¤ |

```mermaid
graph LR
    subgraph "Chain æ€ç¶­"
        A1[Step 1] --> A2[Step 2] --> A3[Step 3]
    end

    subgraph "Graph æ€ç¶­"
        B1[Node A] --> B2[Node B]
        B2 --> B3[Node C]
        B2 --> B4[Node D]
        B3 --> B5[Node E]
        B4 --> B5
        B5 -->|loop| B2
    end
```

### 4.2.2 ä¸‰å¤§æ ¸å¿ƒå…ƒç´ 

LangGraph çš„ä¸‰å¤§æ ¸å¿ƒï¼š

```python
from langgraph.graph import StateGraph

# 1. Stateï¼šå®šç¾©è³‡æ–™çµæ§‹
class MyState(TypedDict):
    messages: list
    current_step: str

# 2. Nodeï¼šå®šç¾©è™•ç†é‚è¼¯
def my_node(state: MyState) -> dict:
    # è™•ç†é‚è¼¯
    return {"current_step": "next"}

# 3. Edgeï¼šå®šç¾©æµç¨‹èµ°å‘
graph = StateGraph(MyState)
graph.add_node("my_node", my_node)
graph.add_edge("my_node", "next_node")
```

è®“æˆ‘å€‘é€ä¸€æ·±å…¥ã€‚

---

## 4.3 Stateï¼šé¡¯å¼çš„ç‹€æ…‹ç®¡ç†

### 4.3.1 TypedDict å®šç¾©ç‹€æ…‹

LangGraph ä½¿ç”¨ TypedDict å®šç¾©ç‹€æ…‹çµæ§‹ï¼š

```python
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages

class AgentState(TypedDict):
    """Agent çš„ç‹€æ…‹å®šç¾©

    æ¯å€‹æ¬„ä½ä»£è¡¨ç‹€æ…‹çš„ä¸€å€‹é¢å‘ã€‚
    """
    # â€¹1â€º å°è©±è¨Šæ¯åˆ—è¡¨
    messages: Annotated[list, add_messages]

    # â€¹2â€º ç•¶å‰è™•ç†éšŽæ®µ
    current_phase: str

    # â€¹3â€º éŒ¯èª¤è¨ˆæ•¸
    error_count: int

    # â€¹4â€º ä¸­é–“çµæžœ
    intermediate_results: dict
```

**é—œéµé»žè§£æž**ï¼š

- â€¹1â€º `Annotated[list, add_messages]`ï¼šç‰¹æ®Šæ¨™è¨˜ï¼Œè¡¨ç¤ºæ–°è¨Šæ¯æœƒ**è¿½åŠ **è€Œéžè¦†è“‹
- â€¹2â€º ä¸€èˆ¬æ¬„ä½ï¼šæ¯æ¬¡æ›´æ–°æœƒ**è¦†è“‹**èˆŠå€¼
- â€¹3â€º è¨ˆæ•¸å™¨ï¼šç”¨æ–¼è¿½è¹¤é‡è©¦æ¬¡æ•¸
- â€¹4â€º ä¸­é–“çµæžœï¼šå„²å­˜è™•ç†éŽç¨‹ä¸­çš„è³‡æ–™

### 4.3.2 Reducerï¼šç‹€æ…‹åˆä½µç­–ç•¥

ç•¶ç¯€é»žè¿”å›žæ›´æ–°æ™‚ï¼ŒLangGraph éœ€è¦çŸ¥é“å¦‚ä½•åˆä½µæ–°èˆŠç‹€æ…‹ï¼š

```python
from typing import Annotated
from operator import add

class CounterState(TypedDict):
    # é è¨­è¡Œç‚ºï¼šè¦†è“‹
    value: int  # æ–°å€¼æœƒè¦†è“‹èˆŠå€¼

    # ä½¿ç”¨ add reducerï¼šç´¯åŠ 
    total: Annotated[int, add]  # æ–°å€¼æœƒåŠ åˆ°èˆŠå€¼ä¸Š

    # ä½¿ç”¨è‡ªè¨‚ reducerï¼šè¿½åŠ åˆ—è¡¨
    history: Annotated[list, lambda old, new: old + new]
```

å¸¸è¦‹çš„ Reducerï¼š

| Reducer | è¡Œç‚º | ä½¿ç”¨å ´æ™¯ |
|---------|------|----------|
| `è¦†è“‹ï¼ˆé è¨­ï¼‰` | æ–°å€¼å–ä»£èˆŠå€¼ | ç‹€æ…‹æ¨™è¨˜ã€å–®ä¸€çµæžœ |
| `add_messages` | è¿½åŠ è¨Šæ¯ | å°è©±æ­·å² |
| `operator.add` | æ•¸å€¼ç´¯åŠ  | è¨ˆæ•¸å™¨ã€åˆ†æ•¸ |
| `lambda old, new: old + new` | åˆ—è¡¨è¿½åŠ  | æ—¥èªŒã€æ­¥é©Ÿè¨˜éŒ„ |

### 4.3.3 è¨­è¨ˆè‰¯å¥½çš„ç‹€æ…‹ Schema

**åŽŸå‰‡ 1ï¼šæœ€å°åŒ–ç‹€æ…‹**

```python
# âŒ ä¸å¥½ï¼šç‹€æ…‹éŽæ–¼è‡ƒè…«
class BadState(TypedDict):
    raw_input: str
    processed_input: str
    llm_response_1: str
    llm_response_2: str
    tool_result_1: str
    tool_result_2: str
    final_output: str
    # ... æ›´å¤š

# âœ… å¥½ï¼šåªä¿ç•™å¿…è¦è³‡è¨Š
class GoodState(TypedDict):
    messages: Annotated[list, add_messages]  # åŒ…å«æ‰€æœ‰å°è©±
    phase: str                                # ç•¶å‰éšŽæ®µ
    result: dict | None                       # æœ€çµ‚çµæžœ
```

**åŽŸå‰‡ 2ï¼šé¡žåž‹æ¸…æ™°**

```python
from enum import Enum

class Phase(str, Enum):
    INIT = "init"
    PROCESSING = "processing"
    REVIEW = "review"
    COMPLETE = "complete"

class TypedState(TypedDict):
    phase: Phase  # ä½¿ç”¨ Enum è€Œéžå­—ä¸²
    retry_count: int  # æ˜Žç¢ºçš„æ•¸å€¼é¡žåž‹
    is_approved: bool  # æ˜Žç¢ºçš„å¸ƒæž—
```

**åŽŸå‰‡ 3ï¼šå¯åºåˆ—åŒ–**

```python
# âŒ ä¸å¥½ï¼šåŒ…å«ä¸å¯åºåˆ—åŒ–çš„ç‰©ä»¶
class BadState(TypedDict):
    llm: ChatAnthropic  # LLM å¯¦ä¾‹ä¸æ‡‰æ”¾åœ¨ç‹€æ…‹ä¸­
    connection: DatabaseConnection  # é€£ç·šç‰©ä»¶

# âœ… å¥½ï¼šåªä¿ç•™å¯åºåˆ—åŒ–çš„è³‡æ–™
class GoodState(TypedDict):
    llm_config: dict  # é…ç½®å­—å…¸
    query_results: list[dict]  # ç´”è³‡æ–™
```

---

## 4.4 Nodeï¼šè™•ç†é‚è¼¯çš„å°è£

### 4.4.1 ç¯€é»žå‡½æ•¸çš„çµæ§‹

æ¯å€‹ç¯€é»žæ˜¯ä¸€å€‹å‡½æ•¸ï¼ŒæŽ¥æ”¶ç‹€æ…‹ã€è¿”å›žæ›´æ–°ï¼š

```python
def my_node(state: AgentState) -> dict:
    """ç¯€é»žè™•ç†å‡½æ•¸

    Args:
        state: ç•¶å‰ç‹€æ…‹ï¼ˆå®Œæ•´çš„ AgentStateï¼‰

    Returns:
        è¦æ›´æ–°çš„ç‹€æ…‹æ¬„ä½ï¼ˆéƒ¨åˆ†æ›´æ–°ï¼‰
    """
    # è®€å–ç•¶å‰ç‹€æ…‹
    messages = state["messages"]
    current_phase = state["phase"]

    # è™•ç†é‚è¼¯
    result = do_something(messages)

    # è¿”å›žè¦æ›´æ–°çš„æ¬„ä½ï¼ˆåªéœ€è¿”å›žè¦æ›´æ–°çš„éƒ¨åˆ†ï¼‰
    return {
        "messages": [result_message],  # æœƒè¿½åŠ ï¼ˆå› ç‚ºæœ‰ add_messagesï¼‰
        "phase": "next_phase"          # æœƒè¦†è“‹
    }
```

### 4.4.2 ç¯€é»žé¡žåž‹

**é¡žåž‹ 1ï¼šè™•ç†ç¯€é»ž**

```python
def process_node(state: AgentState) -> dict:
    """åŸ·è¡ŒæŸç¨®è™•ç†"""
    input_data = state["messages"][-1].content
    result = process(input_data)
    return {"result": result}
```

**é¡žåž‹ 2ï¼šLLM ç¯€é»ž**

```python
def llm_node(state: AgentState) -> dict:
    """èª¿ç”¨ LLM"""
    llm = ChatAnthropic(model="claude-3-5-sonnet-20241022")
    response = llm.invoke(state["messages"])
    return {"messages": [response]}
```

**é¡žåž‹ 3ï¼šå·¥å…·ç¯€é»ž**

```python
from langgraph.prebuilt import ToolNode

# ä½¿ç”¨é å»ºçš„ ToolNode
tool_node = ToolNode(tools)
```

**é¡žåž‹ 4ï¼šæ¢ä»¶æª¢æŸ¥ç¯€é»ž**

```python
def check_node(state: AgentState) -> dict:
    """æª¢æŸ¥ä¸¦è¨­ç½®æ¨™è¨˜ï¼Œä¾›å¾ŒçºŒè·¯ç”±ä½¿ç”¨"""
    if some_condition(state):
        return {"should_continue": True}
    return {"should_continue": False}
```

### 4.4.3 ç¯€é»žçš„æœ€ä½³å¯¦è¸

**å¯¦è¸ 1ï¼šå–®ä¸€è·è²¬**

```python
# âŒ ä¸å¥½ï¼šä¸€å€‹ç¯€é»žåšå¤ªå¤šäº‹
def do_everything(state):
    # é©—è­‰è¼¸å…¥
    # èª¿ç”¨ LLM
    # åŸ·è¡Œå·¥å…·
    # æ ¼å¼åŒ–è¼¸å‡º
    pass

# âœ… å¥½ï¼šæ¯å€‹ç¯€é»žå°ˆæ³¨ä¸€ä»¶äº‹
def validate_input(state): ...
def call_llm(state): ...
def execute_tools(state): ...
def format_output(state): ...
```

**å¯¦è¸ 2ï¼šå†ªç­‰æ€§**

```python
# âœ… å¥½ï¼šç›¸åŒè¼¸å…¥ç”¢ç”Ÿç›¸åŒè¼¸å‡º
def idempotent_node(state: AgentState) -> dict:
    # åŸºæ–¼ç‹€æ…‹æ±ºå®šè¡Œç‚ºï¼Œä¸ä¾è³´å¤–éƒ¨å¯è®Šç‹€æ…‹
    if state["processed"]:
        return {}  # å·²è™•ç†éŽï¼Œä¸é‡è¤‡è™•ç†
    result = process(state["input"])
    return {"result": result, "processed": True}
```

**å¯¦è¸ 3ï¼šéŒ¯èª¤è™•ç†**

```python
def robust_node(state: AgentState) -> dict:
    """å¸¶æœ‰éŒ¯èª¤è™•ç†çš„ç¯€é»ž"""
    try:
        result = risky_operation(state)
        return {"result": result, "error": None}
    except ValueError as e:
        return {"error": f"é©—è­‰éŒ¯èª¤ï¼š{e}", "error_count": state["error_count"] + 1}
    except Exception as e:
        return {"error": f"æœªé æœŸéŒ¯èª¤ï¼š{e}", "error_count": state["error_count"] + 1}
```

---

## 4.5 Edgeï¼šå®šç¾©æµç¨‹èµ°å‘

### 4.5.1 æ™®é€šé‚Š (Normal Edge)

å›ºå®šçš„æµç¨‹èµ°å‘ï¼š

```python
from langgraph.graph import StateGraph, START, END

graph = StateGraph(AgentState)

# æ·»åŠ ç¯€é»ž
graph.add_node("step1", step1_func)
graph.add_node("step2", step2_func)
graph.add_node("step3", step3_func)

# æ™®é€šé‚Šï¼šå›ºå®šèµ°å‘
graph.set_entry_point("step1")  # START -> step1
graph.add_edge("step1", "step2")  # step1 -> step2
graph.add_edge("step2", "step3")  # step2 -> step3
graph.add_edge("step3", END)      # step3 -> END
```

### 4.5.2 æ¢ä»¶é‚Š (Conditional Edge)

æ ¹æ“šç‹€æ…‹æ±ºå®šèµ°å‘ï¼š

```python
def route_function(state: AgentState) -> str:
    """è·¯ç”±å‡½æ•¸ï¼šæ ¹æ“šç‹€æ…‹è¿”å›žä¸‹ä¸€å€‹ç¯€é»žåç¨±"""
    if state.get("error"):
        return "error_handler"
    if state.get("needs_review"):
        return "human_review"
    return "continue"

# æ·»åŠ æ¢ä»¶é‚Š
graph.add_conditional_edges(
    "check_node",      # ä¾†æºç¯€é»ž
    route_function,    # è·¯ç”±å‡½æ•¸
    {
        "error_handler": "error_handler",  # è·¯ç”±çµæžœ -> ç›®æ¨™ç¯€é»ž
        "human_review": "human_review",
        "continue": "next_step",
    }
)
```

### 4.5.3 å¾ªç’°é‚Š

å‰µå»ºå¾ªç’°çµæ§‹ï¼š

```python
def should_continue(state: AgentState) -> str:
    """åˆ¤æ–·æ˜¯å¦ç¹¼çºŒå¾ªç’°"""
    if state["iteration"] >= state["max_iterations"]:
        return "exit"
    if state["goal_achieved"]:
        return "exit"
    return "continue"

graph.add_conditional_edges(
    "process",
    should_continue,
    {
        "continue": "process",  # å¾ªç’°å›žè‡ªå·±
        "exit": "finalize"
    }
)
```

### 4.5.4 è·¯ç”±æ¨¡å¼å¤§å…¨

**æ¨¡å¼ 1ï¼šäºŒå…ƒåˆ†æ”¯**

```python
def binary_route(state) -> str:
    return "yes" if state["condition"] else "no"

graph.add_conditional_edges("check", binary_route, {
    "yes": "path_a",
    "no": "path_b"
})
```

**æ¨¡å¼ 2ï¼šå¤šè·¯åˆ†æ”¯**

```python
def multi_route(state) -> str:
    intent = state["intent"]
    return {
        "question": "qa_handler",
        "command": "cmd_handler",
        "chat": "chat_handler"
    }.get(intent, "default_handler")
```

**æ¨¡å¼ 3ï¼šå·¥å…·èª¿ç”¨è·¯ç”±**

```python
def tools_condition(state) -> str:
    """æª¢æŸ¥ LLM æ˜¯å¦è¦èª¿ç”¨å·¥å…·"""
    last_message = state["messages"][-1]
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"
    return "end"

graph.add_conditional_edges("agent", tools_condition, {
    "tools": "tool_executor",
    "end": END
})
```

---

## 4.6 çµ„è£å®Œæ•´çš„ Graph

### 4.6.1 åŸºæœ¬æµç¨‹

```python
from typing import TypedDict, Annotated
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

# â€¹1â€º å®šç¾©ç‹€æ…‹
class State(TypedDict):
    messages: Annotated[list, add_messages]
    step: str

# â€¹2â€º å®šç¾©ç¯€é»ž
def node_a(state: State) -> dict:
    return {"step": "a_done"}

def node_b(state: State) -> dict:
    return {"step": "b_done"}

# â€¹3â€º å»ºç«‹åœ–
graph = StateGraph(State)

# â€¹4â€º æ·»åŠ ç¯€é»ž
graph.add_node("a", node_a)
graph.add_node("b", node_b)

# â€¹5â€º æ·»åŠ é‚Š
graph.add_edge(START, "a")
graph.add_edge("a", "b")
graph.add_edge("b", END)

# â€¹6â€º ç·¨è­¯
app = graph.compile()

# â€¹7â€º åŸ·è¡Œ
result = app.invoke({"messages": [], "step": "init"})
```

### 4.6.2 è¦–è¦ºåŒ– Graph

```python
# ç”Ÿæˆ Mermaid åœ–è¡¨
print(app.get_graph().draw_mermaid())

# æˆ–è€…ä¿å­˜ç‚º PNGï¼ˆéœ€è¦ graphvizï¼‰
app.get_graph().draw_png("graph.png")
```

### 4.6.3 ä¸²æµåŸ·è¡Œ

```python
# ä¸²æµåŸ·è¡Œï¼Œè§€å¯Ÿæ¯ä¸€æ­¥
for event in app.stream({"messages": [], "step": "init"}):
    print(f"äº‹ä»¶ï¼š{event}")

# è¼¸å‡ºï¼š
# äº‹ä»¶ï¼š{'a': {'step': 'a_done'}}
# äº‹ä»¶ï¼š{'b': {'step': 'b_done'}}
```

---

## 4.7 å¯¦ä½œï¼šReAct Agent

è®“æˆ‘å€‘å¯¦ä½œç¶“å…¸çš„ ReAct (Reasoning + Acting) Agentï¼š

### 4.7.1 ReAct æž¶æ§‹

```mermaid
graph TD
    A[START] --> B[Agent: æ€è€ƒä¸¦æ±ºå®š]
    B --> C{éœ€è¦å·¥å…·ï¼Ÿ}
    C -->|æ˜¯| D[åŸ·è¡Œå·¥å…·]
    D --> B
    C -->|å¦| E[END]
```

### 4.7.2 å®Œæ•´å¯¦ç¾

```python
from typing import TypedDict, Annotated
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode

# ============================================================
# 1. å®šç¾©ç‹€æ…‹
# ============================================================

class AgentState(TypedDict):
    """ReAct Agent çš„ç‹€æ…‹"""
    messages: Annotated[list, add_messages]
    iteration: int

# ============================================================
# 2. å®šç¾©å·¥å…·
# ============================================================

from langchain_core.tools import tool

@tool
def search(query: str) -> str:
    """æœå°‹æŠ€è¡“æ–‡ä»¶"""
    return f"æœå°‹çµæžœï¼šé—œæ–¼ '{query}' çš„è³‡è¨Š..."

@tool
def calculator(expression: str) -> str:
    """è¨ˆç®—æ•¸å­¸è¡¨é”å¼"""
    try:
        return f"è¨ˆç®—çµæžœï¼š{eval(expression)}"
    except:
        return "è¨ˆç®—éŒ¯èª¤"

tools = [search, calculator]

# ============================================================
# 3. å®šç¾©ç¯€é»ž
# ============================================================

# LLM ç¯€é»ž
llm = ChatAnthropic(model="claude-3-5-sonnet-20241022")
llm_with_tools = llm.bind_tools(tools)

def agent_node(state: AgentState) -> dict:
    """Agent æ€è€ƒç¯€é»žï¼šæ±ºå®šä¸‹ä¸€æ­¥è¡Œå‹•"""
    response = llm_with_tools.invoke(state["messages"])
    return {
        "messages": [response],
        "iteration": state["iteration"] + 1
    }

# å·¥å…·åŸ·è¡Œç¯€é»žï¼ˆä½¿ç”¨é å»ºçš„ ToolNodeï¼‰
tool_node = ToolNode(tools)

# ============================================================
# 4. å®šç¾©è·¯ç”±
# ============================================================

def should_continue(state: AgentState) -> str:
    """åˆ¤æ–·æ˜¯å¦ç¹¼çºŒåŸ·è¡Œå·¥å…·"""
    # æª¢æŸ¥è¿­ä»£æ¬¡æ•¸é™åˆ¶
    if state["iteration"] >= 10:
        return "end"

    # æª¢æŸ¥æœ€å¾Œä¸€æ¢è¨Šæ¯æ˜¯å¦æœ‰å·¥å…·èª¿ç”¨
    last_message = state["messages"][-1]
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"

    return "end"

# ============================================================
# 5. çµ„è£ Graph
# ============================================================

graph = StateGraph(AgentState)

# æ·»åŠ ç¯€é»ž
graph.add_node("agent", agent_node)
graph.add_node("tools", tool_node)

# æ·»åŠ é‚Š
graph.add_edge(START, "agent")
graph.add_conditional_edges(
    "agent",
    should_continue,
    {
        "tools": "tools",
        "end": END
    }
)
graph.add_edge("tools", "agent")  # å·¥å…·åŸ·è¡Œå¾Œå›žåˆ° agent

# ç·¨è­¯
react_agent = graph.compile()

# ============================================================
# 6. åŸ·è¡Œ
# ============================================================

def run_agent(question: str):
    """é‹è¡Œ ReAct Agent"""
    initial_state = {
        "messages": [HumanMessage(content=question)],
        "iteration": 0
    }

    print(f"å•é¡Œï¼š{question}\n")
    print("åŸ·è¡ŒéŽç¨‹ï¼š")
    print("-" * 50)

    for event in react_agent.stream(initial_state):
        for node_name, output in event.items():
            print(f"[{node_name}]")
            if "messages" in output:
                for msg in output["messages"]:
                    if hasattr(msg, "tool_calls") and msg.tool_calls:
                        for tc in msg.tool_calls:
                            print(f"  èª¿ç”¨å·¥å…·ï¼š{tc['name']}({tc['args']})")
                    elif hasattr(msg, "content") and msg.content:
                        print(f"  {msg.content[:200]}...")
        print()

    # ç²å–æœ€çµ‚çµæžœ
    final_state = react_agent.invoke(initial_state)
    return final_state["messages"][-1].content

# æ¸¬è©¦
if __name__ == "__main__":
    result = run_agent("æœå°‹ Python asyncio çš„ç”¨æ³•ï¼Œç„¶å¾Œè¨ˆç®— 2^10")
    print("æœ€çµ‚å›žç­”ï¼š")
    print(result)
```

---

## 4.8 å¯¦ä½œï¼šTechAssist v0.5

ç¾åœ¨è®“æˆ‘å€‘å°‡ TechAssist å‡ç´šç‚ºåŸºæ–¼ LangGraph çš„ç‰ˆæœ¬ã€‚

### 4.8.1 è¨­è¨ˆç‹€æ…‹

```python
# techassist/state.py
from typing import TypedDict, Annotated, Literal
from langgraph.graph.message import add_messages
from enum import Enum

class Phase(str, Enum):
    """è™•ç†éšŽæ®µ"""
    INIT = "init"
    CLASSIFYING = "classifying"
    PROCESSING = "processing"
    TOOL_EXECUTING = "tool_executing"
    REVIEWING = "reviewing"
    COMPLETE = "complete"
    ERROR = "error"

class TechAssistState(TypedDict):
    """TechAssist v0.5 ç‹€æ…‹"""

    # å°è©±è¨Šæ¯
    messages: Annotated[list, add_messages]

    # ç•¶å‰éšŽæ®µ
    phase: Phase

    # åˆ†é¡žçµæžœ
    intent: str | None
    confidence: float

    # å·¥å…·åŸ·è¡Œ
    pending_tools: list[dict]
    tool_results: list[dict]

    # æŽ§åˆ¶æ¨™è¨˜
    iteration: int
    max_iterations: int
    needs_human_review: bool

    # éŒ¯èª¤è™•ç†
    error: str | None
    error_count: int
```

### 4.8.2 å®šç¾©ç¯€é»ž

```python
# techassist/nodes.py
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

from .state import TechAssistState, Phase
from .tools import TECHASSIST_TOOLS

llm = ChatAnthropic(model="claude-3-5-sonnet-20241022")
llm_with_tools = llm.bind_tools(TECHASSIST_TOOLS)

# ------------------------------------------------------------
# å…¥å£ç¯€é»ž
# ------------------------------------------------------------

def entry_node(state: TechAssistState) -> dict:
    """å…¥å£ç¯€é»žï¼šåˆå§‹åŒ–ç‹€æ…‹"""
    return {
        "phase": Phase.CLASSIFYING,
        "iteration": 0,
        "error_count": 0
    }

# ------------------------------------------------------------
# æ„åœ–åˆ†é¡žç¯€é»ž
# ------------------------------------------------------------

CLASSIFY_PROMPT = """åˆ†æžç”¨æˆ¶çš„è¼¸å…¥ï¼Œåˆ¤æ–·æ„åœ–ï¼š
- tech_question: æŠ€è¡“å•é¡Œ
- code_help: ç¨‹å¼ç¢¼ç›¸é—œ
- general: ä¸€èˆ¬å°è©±

åªå›žè¦†æ„åœ–é¡žåž‹ï¼Œä¸è¦å…¶ä»–å…§å®¹ã€‚"""

def classify_node(state: TechAssistState) -> dict:
    """æ„åœ–åˆ†é¡žç¯€é»ž"""
    messages = [
        SystemMessage(content=CLASSIFY_PROMPT),
        state["messages"][-1]
    ]

    response = llm.invoke(messages)
    intent = response.content.strip().lower()

    # ç°¡å–®çš„ä¿¡å¿ƒåˆ†æ•¸é‚è¼¯
    confidence = 0.9 if intent in ["tech_question", "code_help", "general"] else 0.5

    return {
        "intent": intent,
        "confidence": confidence,
        "phase": Phase.PROCESSING
    }

# ------------------------------------------------------------
# ä¸»è™•ç†ç¯€é»ž
# ------------------------------------------------------------

SYSTEM_PROMPT = """ä½ æ˜¯ TechAssistï¼Œå°ˆæ¥­çš„æŠ€è¡“åŠ©ç†ã€‚
ä½¿ç”¨ç¹é«”ä¸­æ–‡å›žç­”ã€‚å¦‚éœ€è¦å¤–éƒ¨è³‡è¨Šï¼Œä½¿ç”¨æä¾›çš„å·¥å…·ã€‚"""

def process_node(state: TechAssistState) -> dict:
    """ä¸»è™•ç†ç¯€é»žï¼šèª¿ç”¨ LLMï¼ˆå¯èƒ½èª¿ç”¨å·¥å…·ï¼‰"""
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        *state["messages"]
    ]

    response = llm_with_tools.invoke(messages)

    return {
        "messages": [response],
        "iteration": state["iteration"] + 1,
        "phase": Phase.TOOL_EXECUTING if response.tool_calls else Phase.COMPLETE
    }

# ------------------------------------------------------------
# å·¥å…·åŸ·è¡Œç¯€é»ž
# ------------------------------------------------------------

from langgraph.prebuilt import ToolNode

tool_executor = ToolNode(TECHASSIST_TOOLS)

def tool_node(state: TechAssistState) -> dict:
    """å·¥å…·åŸ·è¡Œç¯€é»ž"""
    # ToolNode æœƒè‡ªå‹•è™•ç†å·¥å…·èª¿ç”¨
    result = tool_executor.invoke(state)

    return {
        **result,
        "phase": Phase.PROCESSING  # å›žåˆ°è™•ç†ç¯€é»žç¹¼çºŒ
    }

# ------------------------------------------------------------
# éŒ¯èª¤è™•ç†ç¯€é»ž
# ------------------------------------------------------------

def error_node(state: TechAssistState) -> dict:
    """éŒ¯èª¤è™•ç†ç¯€é»ž"""
    error_message = AIMessage(
        content=f"æŠ±æ­‰ï¼Œè™•ç†éŽç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{state['error']}\nè«‹å˜—è©¦é‡æ–°æè¿°æ‚¨çš„å•é¡Œã€‚"
    )

    return {
        "messages": [error_message],
        "phase": Phase.COMPLETE,
        "error_count": state["error_count"] + 1
    }

# ------------------------------------------------------------
# å®Œæˆç¯€é»ž
# ------------------------------------------------------------

def complete_node(state: TechAssistState) -> dict:
    """å®Œæˆç¯€é»žï¼šæœ€çµ‚è™•ç†"""
    return {"phase": Phase.COMPLETE}
```

### 4.8.3 å®šç¾©è·¯ç”±

```python
# techassist/routing.py
from .state import TechAssistState, Phase

def route_after_process(state: TechAssistState) -> str:
    """è™•ç†ç¯€é»žå¾Œçš„è·¯ç”±"""
    # æª¢æŸ¥è¿­ä»£é™åˆ¶
    if state["iteration"] >= state["max_iterations"]:
        return "complete"

    # æª¢æŸ¥æ˜¯å¦æœ‰å·¥å…·èª¿ç”¨
    last_message = state["messages"][-1]
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"

    # æª¢æŸ¥æ˜¯å¦éœ€è¦äººå·¥å¯©æ ¸
    if state.get("needs_human_review"):
        return "review"

    return "complete"

def route_after_classify(state: TechAssistState) -> str:
    """åˆ†é¡žå¾Œçš„è·¯ç”±"""
    if state["confidence"] < 0.5:
        return "clarify"
    return "process"
```

### 4.8.4 çµ„è£ Graph

```python
# techassist/graph.py
from langgraph.graph import StateGraph, START, END

from .state import TechAssistState, Phase
from .nodes import (
    entry_node,
    classify_node,
    process_node,
    tool_node,
    error_node,
    complete_node,
)
from .routing import route_after_process, route_after_classify

def create_techassist_graph():
    """å»ºç«‹ TechAssist v0.5 Graph"""

    graph = StateGraph(TechAssistState)

    # æ·»åŠ ç¯€é»ž
    graph.add_node("entry", entry_node)
    graph.add_node("classify", classify_node)
    graph.add_node("process", process_node)
    graph.add_node("tools", tool_node)
    graph.add_node("error", error_node)
    graph.add_node("complete", complete_node)

    # æ·»åŠ é‚Š
    graph.add_edge(START, "entry")
    graph.add_edge("entry", "classify")

    # åˆ†é¡žå¾Œçš„æ¢ä»¶è·¯ç”±
    graph.add_conditional_edges(
        "classify",
        route_after_classify,
        {
            "process": "process",
            "clarify": "complete"  # ç°¡åŒ–ï¼šä½Žä¿¡å¿ƒç›´æŽ¥å®Œæˆ
        }
    )

    # è™•ç†å¾Œçš„æ¢ä»¶è·¯ç”±
    graph.add_conditional_edges(
        "process",
        route_after_process,
        {
            "tools": "tools",
            "complete": "complete",
            "review": "complete"  # ç°¡åŒ–ï¼šäººå·¥å¯©æ ¸æš«æ™‚è·³éŽ
        }
    )

    # å·¥å…·åŸ·è¡Œå¾Œå›žåˆ°è™•ç†
    graph.add_edge("tools", "process")

    # éŒ¯èª¤å’Œå®Œæˆéƒ½çµæŸ
    graph.add_edge("error", END)
    graph.add_edge("complete", END)

    return graph.compile()

# å»ºç«‹æ‡‰ç”¨å¯¦ä¾‹
techassist_app = create_techassist_graph()
```

### 4.8.5 CLI ä»‹é¢

```python
# techassist/cli_v5.py
from langchain_core.messages import HumanMessage

from .graph import techassist_app
from .state import Phase

def run_cli_v5():
    """åŸ·è¡Œ TechAssist v0.5 CLI"""
    print("=" * 60)
    print("ðŸ¤– TechAssist v0.5 - LangGraph ç‰ˆæœ¬")
    print("=" * 60)
    print("ç¾åœ¨ä½¿ç”¨ LangGraph é€²è¡Œç‹€æ…‹ç®¡ç†ï¼")
    print("è¼¸å…¥ 'quit' é›¢é–‹ã€‚")
    print("-" * 60)

    while True:
        try:
            user_input = input("\nðŸ“ ä½ çš„å•é¡Œï¼š").strip()

            if not user_input:
                continue

            if user_input.lower() in ('quit', 'exit', 'q'):
                print("\nðŸ‘‹ æ„Ÿè¬ä½¿ç”¨ TechAssistï¼Œå†è¦‹ï¼")
                break

            print("\nðŸ’­ è™•ç†ä¸­...\n")

            # åˆå§‹ç‹€æ…‹
            initial_state = {
                "messages": [HumanMessage(content=user_input)],
                "phase": Phase.INIT,
                "intent": None,
                "confidence": 0.0,
                "pending_tools": [],
                "tool_results": [],
                "iteration": 0,
                "max_iterations": 5,
                "needs_human_review": False,
                "error": None,
                "error_count": 0,
            }

            # ä¸²æµåŸ·è¡Œ
            for event in techassist_app.stream(initial_state):
                for node_name, output in event.items():
                    if node_name == "classify":
                        print(f"ðŸ“Š æ„åœ–ï¼š{output.get('intent')} (ä¿¡å¿ƒï¼š{output.get('confidence', 0):.0%})")
                    elif node_name == "tools":
                        print("ðŸ”§ åŸ·è¡Œå·¥å…·...")
                    elif node_name == "process":
                        msgs = output.get("messages", [])
                        for msg in msgs:
                            if hasattr(msg, "tool_calls") and msg.tool_calls:
                                for tc in msg.tool_calls:
                                    print(f"  â†’ èª¿ç”¨ï¼š{tc['name']}")

            # ç²å–æœ€çµ‚çµæžœ
            final_state = techassist_app.invoke(initial_state)
            final_message = final_state["messages"][-1]

            print(f"\nðŸ“– å›žç­”ï¼š\n{final_message.content}")

        except KeyboardInterrupt:
            print("\n\nðŸ‘‹ æ„Ÿè¬ä½¿ç”¨ TechAssistï¼Œå†è¦‹ï¼")
            break
        except Exception as e:
            print(f"\nâŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

if __name__ == "__main__":
    run_cli_v5()
```

---

## 4.9 æœ¬ç« å›žé¡§

### æ ¸å¿ƒæ¦‚å¿µ

| æ¦‚å¿µ | èªªæ˜Ž | é—œéµæ–¹æ³• |
|------|------|----------|
| **State** | é¡¯å¼å®šç¾©çš„ç‹€æ…‹çµæ§‹ | `TypedDict`, `Annotated` |
| **Node** | è™•ç†é‚è¼¯çš„å°è£ | å‡½æ•¸ï¼ŒæŽ¥æ”¶ state è¿”å›žæ›´æ–° |
| **Edge** | æµç¨‹èµ°å‘å®šç¾© | `add_edge`, `add_conditional_edges` |
| **Reducer** | ç‹€æ…‹åˆä½µç­–ç•¥ | `add_messages`, `operator.add` |

### è¨­è¨ˆåŽŸå‰‡

1. **é¡¯å¼ç‹€æ…‹**ï¼šæ‰€æœ‰é‡è¦è³‡è¨Šéƒ½åœ¨ç‹€æ…‹ä¸­ï¼Œä¸ä¾è³´éš±å¼å‚³éž
2. **å–®ä¸€è·è²¬**ï¼šæ¯å€‹ç¯€é»žåªåšä¸€ä»¶äº‹
3. **å¯æ¢å¾©æ€§**ï¼šç‹€æ…‹å¯åºåˆ—åŒ–ï¼Œæ”¯æ´æ–·é»žæ¢å¾©
4. **å¯è§€æ¸¬æ€§**ï¼šæ¯å€‹ç¯€é»žçš„åŸ·è¡Œéƒ½å¯è¿½è¹¤

### TechAssist é‡Œç¨‹ç¢‘

- âœ… v0.1ï¼šåŸºæ–¼ Chain çš„ç°¡å–®å•ç­”
- âœ… v0.2ï¼šå…·å‚™æ„åœ–åˆ†é¡žèˆ‡å‹•æ…‹è·¯ç”±
- âœ… v0.3ï¼šå…·å‚™å·¥å…·ä½¿ç”¨èƒ½åŠ›
- âœ… v0.5ï¼šåŸºæ–¼ LangGraph çš„ç‹€æ…‹ç®¡ç†

---

## 4.10 ä¸‹ä¸€ç« é å‘Š

TechAssist v0.5 æœ‰äº†ç‹€æ…‹ç®¡ç†ï¼Œä½†é‚„ç¼ºå°‘ä¸€äº›é—œéµèƒ½åŠ›ï¼š

- **äººæ©Ÿå”ä½œ**ï¼šæŸäº›æ±ºç­–éœ€è¦äººå·¥ç¢ºèª
- **å‹•æ…‹è·¯ç”±**ï¼šæ ¹æ“šä¿¡å¿ƒåˆ†æ•¸é¸æ“‡ä¸åŒè·¯å¾‘
- **ä¸­æ–·èˆ‡æ¢å¾©**ï¼šé•·æ™‚é–“ä»»å‹™çš„æ–·é»žçºŒå‚³

åœ¨ä¸‹ä¸€ç« ï¼Œæˆ‘å€‘å°‡å­¸ç¿’ **è·¯ç”±æ¨¡å¼èˆ‡äººæ©Ÿå”ä½œ (HITL)**ï¼š

- å¯¦ç¾ Human-in-the-Loop æµç¨‹
- ä½¿ç”¨ Checkpointer ä¿å­˜ç‹€æ…‹
- å»ºç«‹ä¸­æ–·èˆ‡æ¢å¾©æ©Ÿåˆ¶

---

## ç·´ç¿’é¡Œ

1. **åŸºç¤Žç·´ç¿’**ï¼šç‚º ReAct Agent æ·»åŠ ä¸€å€‹ `get_time` å·¥å…·ï¼Œè®“å®ƒèƒ½å›žç­”ç•¶å‰æ™‚é–“ã€‚

2. **é€²éšŽç·´ç¿’**ï¼šä¿®æ”¹ TechAssist v0.5ï¼Œç•¶è¿­ä»£æ¬¡æ•¸è¶…éŽé™åˆ¶æ™‚ï¼Œè¿”å›žä¸€å€‹å‹å–„çš„æç¤ºè¨Šæ¯è€Œéžç›´æŽ¥çµæŸã€‚

3. **æŒ‘æˆ°ç·´ç¿’**ï¼šå¯¦ç¾ä¸€å€‹ã€Œä»£ç¢¼å¯©æŸ¥ã€Graphï¼ŒåŒ…å«ï¼šè§£æžä»£ç¢¼ â†’ éœæ…‹åˆ†æž â†’ ç”Ÿæˆå»ºè­° â†’ æ ¼å¼åŒ–è¼¸å‡º å››å€‹ç¯€é»žã€‚

---

## å»¶ä¼¸é–±è®€

- [LangGraph å®˜æ–¹æ–‡ä»¶](https://langchain-ai.github.io/langgraph/)
- [LangGraph æ¦‚å¿µæŒ‡å—](https://langchain-ai.github.io/langgraph/concepts/)
- [ç‹€æ…‹æ©Ÿè¨­è¨ˆæ¨¡å¼](https://refactoring.guru/design-patterns/state)
