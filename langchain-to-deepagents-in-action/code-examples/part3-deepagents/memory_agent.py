"""
Chapter 8: è¨˜æ†¶æ¨¡å¼ (The Memory Pattern) - ç¨ç«‹ç¯„ä¾‹

ä¸‰å±¤è¨˜æ†¶æ¶æ§‹ + èªç¾©æ³¨å…¥å¯¦ç¾
"""

import os
import json
import hashlib
from datetime import datetime
from typing import TypedDict, Annotated, Literal
from dataclasses import dataclass, field, asdict
from pydantic import BaseModel, Field
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage
from langchain_core.embeddings import Embeddings
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages


# ============================================================
# 1. è¨˜æ†¶è³‡æ–™çµæ§‹
# ============================================================

@dataclass
class MemoryEntry:
    """è¨˜æ†¶æ¢ç›®"""
    content: str
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    importance: float = 0.5
    access_count: int = 0
    metadata: dict = field(default_factory=dict)

    def to_dict(self) -> dict:
        return asdict(self)


@dataclass
class SessionMemory:
    """æœƒè©±è¨˜æ†¶"""
    session_id: str
    user_id: str
    topic: str = ""
    summary: str = ""
    key_decisions: list[str] = field(default_factory=list)
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    updated_at: str = field(default_factory=lambda: datetime.now().isoformat())


class RetrievedMemory(BaseModel):
    """æª¢ç´¢åˆ°çš„è¨˜æ†¶"""
    content: str
    relevance_score: float
    source: Literal["short_term", "session", "long_term"]
    timestamp: str


# ============================================================
# 2. è¨˜æ†¶ç®¡ç†å™¨
# ============================================================

class SimpleEmbeddings:
    """ç°¡åŒ–çš„åµŒå…¥å¯¦ç¾ï¼ˆç”¨æ–¼æ¼”ç¤ºï¼‰"""

    def embed_query(self, text: str) -> list[float]:
        """ç”Ÿæˆç°¡å–®çš„æ–‡æœ¬å“ˆå¸Œä½œç‚ºåµŒå…¥å‘é‡"""
        # å¯¦éš›æ‡‰ç”¨ä¸­æ‡‰ä½¿ç”¨çœŸæ­£çš„åµŒå…¥æ¨¡å‹
        hash_bytes = hashlib.sha256(text.encode()).digest()
        return [float(b) / 255.0 for b in hash_bytes[:64]]

    def embed_documents(self, texts: list[str]) -> list[list[float]]:
        return [self.embed_query(t) for t in texts]


class ShortTermMemory:
    """â€¹1â€º çŸ­æœŸè¨˜æ†¶ï¼šç•¶å‰å°è©±ä¸Šä¸‹æ–‡"""

    def __init__(self, max_messages: int = 20):
        self.max_messages = max_messages
        self.messages: list[BaseMessage] = []

    def add(self, message: BaseMessage) -> None:
        self.messages.append(message)
        # æ»‘å‹•çª—å£
        if len(self.messages) > self.max_messages:
            self.messages = self.messages[-self.max_messages:]

    def get_recent(self, n: int = 10) -> list[BaseMessage]:
        return self.messages[-n:]

    def get_context_string(self) -> str:
        return "\n".join([
            f"{'ç”¨æˆ¶' if isinstance(m, HumanMessage) else 'AI'}: {m.content}"
            for m in self.messages[-5:]
        ])


class SessionMemoryStore:
    """â€¹2â€º æœƒè©±è¨˜æ†¶ï¼šè·¨å°è©±çš„æœƒè©±ç‹€æ…‹"""

    def __init__(self):
        self.sessions: dict[str, SessionMemory] = {}

    def get_or_create(self, session_id: str, user_id: str) -> SessionMemory:
        if session_id not in self.sessions:
            self.sessions[session_id] = SessionMemory(
                session_id=session_id,
                user_id=user_id
            )
        return self.sessions[session_id]

    def update_summary(self, session_id: str, summary: str) -> None:
        if session_id in self.sessions:
            self.sessions[session_id].summary = summary
            self.sessions[session_id].updated_at = datetime.now().isoformat()

    def add_decision(self, session_id: str, decision: str) -> None:
        if session_id in self.sessions:
            self.sessions[session_id].key_decisions.append(decision)


class LongTermMemory:
    """â€¹3â€º é•·æœŸè¨˜æ†¶ï¼šå‘é‡åŒ–çš„æŒä¹…è¨˜æ†¶"""

    def __init__(self, embeddings: SimpleEmbeddings | None = None):
        self.embeddings = embeddings or SimpleEmbeddings()
        self.memories: list[MemoryEntry] = []
        self.vectors: list[list[float]] = []

    def add(self, content: str, importance: float = 0.5, metadata: dict | None = None) -> None:
        entry = MemoryEntry(
            content=content,
            importance=importance,
            metadata=metadata or {}
        )
        self.memories.append(entry)
        self.vectors.append(self.embeddings.embed_query(content))
        print(f"  ğŸ’¾ ä¿å­˜é•·æœŸè¨˜æ†¶ï¼š{content[:50]}...")

    def search(self, query: str, top_k: int = 3) -> list[tuple[MemoryEntry, float]]:
        """èªç¾©æœå°‹ç›¸é—œè¨˜æ†¶"""
        if not self.memories:
            return []

        query_vector = self.embeddings.embed_query(query)

        # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
        scores = []
        for vec in self.vectors:
            dot_product = sum(a * b for a, b in zip(query_vector, vec))
            norm_q = sum(a * a for a in query_vector) ** 0.5
            norm_v = sum(b * b for b in vec) ** 0.5
            similarity = dot_product / (norm_q * norm_v) if norm_q * norm_v > 0 else 0
            scores.append(similarity)

        # çµåˆç›¸ä¼¼åº¦å’Œé‡è¦æ€§æ’åº
        scored_memories = [
            (mem, score * 0.7 + mem.importance * 0.3)
            for mem, score in zip(self.memories, scores)
        ]
        scored_memories.sort(key=lambda x: x[1], reverse=True)

        # æ›´æ–°è¨ªå•è¨ˆæ•¸
        for mem, _ in scored_memories[:top_k]:
            mem.access_count += 1

        return scored_memories[:top_k]


# ============================================================
# 3. èªç¾©æ³¨å…¥å™¨
# ============================================================

class SemanticInjector:
    """â€¹4â€º èªç¾©æ³¨å…¥å™¨ï¼šå°‡ç›¸é—œè¨˜æ†¶æ³¨å…¥æç¤º"""

    def __init__(
        self,
        short_term: ShortTermMemory,
        session_store: SessionMemoryStore,
        long_term: LongTermMemory
    ):
        self.short_term = short_term
        self.session_store = session_store
        self.long_term = long_term

    def inject(self, query: str, session_id: str) -> str:
        """æ ¹æ“šæŸ¥è©¢æ³¨å…¥ç›¸é—œä¸Šä¸‹æ–‡"""
        context_parts = []

        # â€¹5â€º çŸ­æœŸè¨˜æ†¶ï¼šæœ€è¿‘å°è©±
        recent_context = self.short_term.get_context_string()
        if recent_context:
            context_parts.append(f"ã€æœ€è¿‘å°è©±ã€‘\n{recent_context}")

        # â€¹6â€º æœƒè©±è¨˜æ†¶ï¼šç•¶å‰æœƒè©±æ‘˜è¦
        if session_id in self.session_store.sessions:
            session = self.session_store.sessions[session_id]
            if session.summary:
                context_parts.append(f"ã€æœƒè©±æ‘˜è¦ã€‘\n{session.summary}")
            if session.key_decisions:
                decisions = "\n".join(f"- {d}" for d in session.key_decisions[-3:])
                context_parts.append(f"ã€é—œéµæ±ºç­–ã€‘\n{decisions}")

        # â€¹7â€º é•·æœŸè¨˜æ†¶ï¼šèªç¾©ç›¸é—œè¨˜æ†¶
        relevant_memories = self.long_term.search(query, top_k=3)
        if relevant_memories:
            memory_text = "\n".join([
                f"- [{mem.timestamp[:10]}] {mem.content}"
                for mem, score in relevant_memories
                if score > 0.3  # ç›¸é—œåº¦é–¾å€¼
            ])
            if memory_text:
                context_parts.append(f"ã€ç›¸é—œæ­·å²ã€‘\n{memory_text}")

        if not context_parts:
            return ""

        return "\n\n".join(context_parts)


# ============================================================
# 4. ç‹€æ…‹å®šç¾©
# ============================================================

class MemoryState(TypedDict):
    messages: Annotated[list, add_messages]
    user_id: str
    session_id: str
    current_query: str
    injected_context: str | None
    response: str | None
    should_memorize: bool


# ============================================================
# 5. ç¯€é»å¯¦ç¾
# ============================================================

# å…¨å±€è¨˜æ†¶å¯¦ä¾‹ï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­æ‡‰ä½¿ç”¨ä¾è³´æ³¨å…¥ï¼‰
short_term_memory = ShortTermMemory()
session_memory_store = SessionMemoryStore()
long_term_memory = LongTermMemory()
semantic_injector = SemanticInjector(
    short_term_memory,
    session_memory_store,
    long_term_memory
)

llm = ChatAnthropic(model="claude-sonnet-4-20250514", temperature=0)


def memory_injection_node(state: MemoryState) -> dict:
    """â€¹8â€º è¨˜æ†¶æ³¨å…¥ç¯€é»ï¼šæª¢ç´¢ä¸¦æ³¨å…¥ç›¸é—œä¸Šä¸‹æ–‡"""
    query = state["current_query"]
    session_id = state["session_id"]

    print(f"\nğŸ” æª¢ç´¢ç›¸é—œè¨˜æ†¶...")
    injected_context = semantic_injector.inject(query, session_id)

    if injected_context:
        print(f"  âœ… æ³¨å…¥ä¸Šä¸‹æ–‡ï¼š{len(injected_context)} å­—ç¬¦")
    else:
        print(f"  â„¹ï¸ ç„¡ç›¸é—œä¸Šä¸‹æ–‡")

    return {"injected_context": injected_context}


def response_generation_node(state: MemoryState) -> dict:
    """â€¹9â€º å›æ‡‰ç”Ÿæˆç¯€é»ï¼šåŸºæ–¼æ³¨å…¥ä¸Šä¸‹æ–‡ç”Ÿæˆå›æ‡‰"""
    query = state["current_query"]
    context = state["injected_context"]

    system_prompt = """ä½ æ˜¯ TechAssistï¼Œä¸€å€‹å…·æœ‰è¨˜æ†¶èƒ½åŠ›çš„ä¼æ¥­åŠ©ç†ã€‚

ä½ å¯ä»¥è¨˜ä½ä¹‹å‰çš„å°è©±å’Œé‡è¦è³‡è¨Šï¼Œè«‹åŸºæ–¼æä¾›çš„ä¸Šä¸‹æ–‡çµ¦å‡ºé€£è²«çš„å›æ‡‰ã€‚

å¦‚æœç”¨æˆ¶æåˆ°ä¹‹å‰è¨è«–éçš„å…§å®¹ï¼Œè«‹é©ç•¶å¼•ç”¨ã€‚"""

    messages = [SystemMessage(content=system_prompt)]

    if context:
        messages.append(SystemMessage(content=f"ç›¸é—œä¸Šä¸‹æ–‡ï¼š\n{context}"))

    messages.append(HumanMessage(content=query))

    response = llm.invoke(messages)

    # æ›´æ–°çŸ­æœŸè¨˜æ†¶
    short_term_memory.add(HumanMessage(content=query))
    short_term_memory.add(AIMessage(content=response.content))

    return {"response": response.content}


def importance_evaluation_node(state: MemoryState) -> dict:
    """â€¹10â€º é‡è¦æ€§è©•ä¼°ç¯€é»ï¼šæ±ºå®šæ˜¯å¦éœ€è¦é•·æœŸè¨˜æ†¶"""
    query = state["current_query"]
    response = state["response"]

    # ä½¿ç”¨ LLM è©•ä¼°å°è©±é‡è¦æ€§
    evaluation_prompt = f"""è©•ä¼°ä»¥ä¸‹å°è©±æ˜¯å¦åŒ…å«å€¼å¾—é•·æœŸè¨˜æ†¶çš„é‡è¦è³‡è¨Šï¼š

ç”¨æˆ¶ï¼š{query}
AIï¼š{response[:500]}

é‡è¦è³‡è¨ŠåŒ…æ‹¬ï¼š
- ç”¨æˆ¶åå¥½
- å°ˆæ¡ˆæ±ºç­–
- æŠ€è¡“é¸æ“‡
- æ¥­å‹™è¦å‰‡
- é‡è¦äº‹å¯¦

åªå›ç­” "æ˜¯" æˆ– "å¦"ã€‚"""

    result = llm.invoke([HumanMessage(content=evaluation_prompt)])
    should_memorize = "æ˜¯" in result.content

    if should_memorize:
        print("  ğŸ“Œ æ¨™è¨˜ç‚ºé‡è¦ï¼Œå°‡ä¿å­˜åˆ°é•·æœŸè¨˜æ†¶")

    return {"should_memorize": should_memorize}


def memory_consolidation_node(state: MemoryState) -> dict:
    """â€¹11â€º è¨˜æ†¶æ•´åˆç¯€é»ï¼šä¿å­˜é‡è¦è³‡è¨Šåˆ°é•·æœŸè¨˜æ†¶"""
    if not state["should_memorize"]:
        return {}

    query = state["current_query"]
    response = state["response"]
    session_id = state["session_id"]
    user_id = state["user_id"]

    # ç”Ÿæˆè¨˜æ†¶æ‘˜è¦
    summary_prompt = f"""è«‹ç”¨ä¸€å¥è©±ç¸½çµä»¥ä¸‹å°è©±ä¸­çš„é—œéµè³‡è¨Šï¼ˆç”¨æ–¼é•·æœŸè¨˜æ†¶ï¼‰ï¼š

ç”¨æˆ¶ï¼š{query}
AIï¼š{response[:500]}

æ‘˜è¦ï¼š"""

    summary_result = llm.invoke([HumanMessage(content=summary_prompt)])
    memory_content = summary_result.content.strip()

    # ä¿å­˜åˆ°é•·æœŸè¨˜æ†¶
    long_term_memory.add(
        content=memory_content,
        importance=0.7,
        metadata={
            "user_id": user_id,
            "session_id": session_id,
            "original_query": query[:100]
        }
    )

    # æ›´æ–°æœƒè©±è¨˜æ†¶
    session = session_memory_store.get_or_create(session_id, user_id)
    session_memory_store.add_decision(session_id, memory_content)

    return {}


# ============================================================
# 6. æ§‹å»ºåœ–
# ============================================================

def build_memory_graph() -> StateGraph:
    """æ§‹å»ºè¨˜æ†¶æ¨¡å¼åœ–"""
    graph = StateGraph(MemoryState)

    # æ·»åŠ ç¯€é»
    graph.add_node("inject_memory", memory_injection_node)
    graph.add_node("generate_response", response_generation_node)
    graph.add_node("evaluate_importance", importance_evaluation_node)
    graph.add_node("consolidate_memory", memory_consolidation_node)

    # æ·»åŠ é‚Š
    graph.add_edge(START, "inject_memory")
    graph.add_edge("inject_memory", "generate_response")
    graph.add_edge("generate_response", "evaluate_importance")
    graph.add_edge("evaluate_importance", "consolidate_memory")
    graph.add_edge("consolidate_memory", END)

    return graph.compile()


# ============================================================
# 7. ä¸»ç¨‹å¼
# ============================================================

def main():
    """åŸ·è¡Œè¨˜æ†¶æ¨¡å¼ç¯„ä¾‹"""
    print("=" * 60)
    print("Chapter 8: è¨˜æ†¶æ¨¡å¼ (The Memory Pattern)")
    print("=" * 60)

    # æ§‹å»ºåœ–
    app = build_memory_graph()

    # é è¨­ä¸€äº›é•·æœŸè¨˜æ†¶ï¼ˆæ¨¡æ“¬æ­·å²ï¼‰
    long_term_memory.add(
        "ç”¨æˆ¶åå¥½ä½¿ç”¨ Python é€²è¡Œé–‹ç™¼",
        importance=0.8,
        metadata={"type": "preference"}
    )
    long_term_memory.add(
        "å°ˆæ¡ˆä½¿ç”¨ PostgreSQL ä½œç‚ºä¸»è³‡æ–™åº«",
        importance=0.9,
        metadata={"type": "decision"}
    )
    long_term_memory.add(
        "åœ˜éšŠæ±ºå®šæ¡ç”¨å¾®æœå‹™æ¶æ§‹",
        importance=0.85,
        metadata={"type": "decision"}
    )

    # æ¨¡æ“¬å¤šè¼ªå°è©±
    user_id = "user_001"
    session_id = "session_001"

    conversations = [
        "æˆ‘å€‘å°ˆæ¡ˆç¾åœ¨éœ€è¦æ·»åŠ ä¸€å€‹æ–°çš„æœå‹™ï¼Œä½ æœ‰ä»€éº¼å»ºè­°ï¼Ÿ",
        "é€™å€‹æœå‹™éœ€è¦è™•ç†å¤§é‡çš„æ•¸æ“šæŸ¥è©¢ï¼Œæ•ˆèƒ½å¾ˆé‡è¦",
        "ä¹‹å‰æˆ‘å€‘æ˜¯æ€éº¼æ±ºå®šæ¶æ§‹çš„ä¾†è‘—ï¼Ÿ",
        "å¥½çš„ï¼Œé‚£å°±æŒ‰ç…§ä½ çš„å»ºè­°ï¼Œä½¿ç”¨ Redis åšå¿«å–å§",
    ]

    for i, query in enumerate(conversations, 1):
        print(f"\n{'='*60}")
        print(f"å°è©± {i}")
        print("=" * 60)
        print(f"ğŸ‘¤ ç”¨æˆ¶ï¼š{query}")

        initial_state = {
            "messages": [],
            "user_id": user_id,
            "session_id": session_id,
            "current_query": query,
            "injected_context": None,
            "response": None,
            "should_memorize": False
        }

        result = app.invoke(initial_state)

        print(f"\nğŸ¤– TechAssistï¼š{result['response']}")

        if i < len(conversations):
            input("\næŒ‰ Enter ç¹¼çºŒä¸‹ä¸€è¼ªå°è©±...")

    # é¡¯ç¤ºè¨˜æ†¶ç‹€æ…‹
    print("\n" + "=" * 60)
    print("è¨˜æ†¶ç‹€æ…‹æ‘˜è¦")
    print("=" * 60)
    print(f"çŸ­æœŸè¨˜æ†¶ï¼š{len(short_term_memory.messages)} æ¢è¨Šæ¯")
    print(f"é•·æœŸè¨˜æ†¶ï¼š{len(long_term_memory.memories)} æ¢è¨˜æ†¶")

    if session_id in session_memory_store.sessions:
        session = session_memory_store.sessions[session_id]
        print(f"æœƒè©±æ±ºç­–ï¼š{len(session.key_decisions)} é …")
        for d in session.key_decisions:
            print(f"  - {d}")


if __name__ == "__main__":
    main()
