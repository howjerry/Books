#!/usr/bin/env python3
"""å¤š Agent ç³»çµ±ç¯„ä¾‹ (Chapter 6)

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ LangGraph å¯¦ç¾ Supervisor Pattern å¤š Agent å”ä½œã€‚
"""

from typing import TypedDict, Annotated, Literal
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from dotenv import load_dotenv

load_dotenv()


# ============================================================
# 1. Worker å®šç¾©
# ============================================================

WORKERS = {
    "coder": {
        "description": "å°ˆé–€ç·¨å¯«å’Œä¿®æ”¹ç¨‹å¼ç¢¼",
        "system_prompt": """ä½ æ˜¯å°ˆæ¥­çš„ç¨‹å¼ç¢¼å·¥ç¨‹å¸«ã€‚
ä½ çš„ä»»å‹™æ˜¯ç·¨å¯«é«˜å“è³ªã€å¯ç¶­è­·çš„ç¨‹å¼ç¢¼ã€‚
åªå›è¦†ç¨‹å¼ç¢¼å’Œå¿…è¦çš„èªªæ˜ï¼Œä¸è¦è™•ç†å…¶ä»–ä»»å‹™ã€‚
ä½¿ç”¨ç¹é«”ä¸­æ–‡èªªæ˜ã€‚"""
    },
    "reviewer": {
        "description": "å°ˆé–€å¯©æŸ¥ç¨‹å¼ç¢¼å“è³ª",
        "system_prompt": """ä½ æ˜¯åš´æ ¼çš„ç¨‹å¼ç¢¼å¯©æŸ¥å“¡ã€‚
æª¢æŸ¥ï¼šç¨‹å¼ç¢¼é¢¨æ ¼ã€æ½›åœ¨ bugã€æ•ˆèƒ½å•é¡Œã€å®‰å…¨æ¼æ´ã€‚
çµ¦å‡ºå…·é«”çš„æ”¹é€²å»ºè­°ã€‚
ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"""
    },
    "researcher": {
        "description": "å°ˆé–€æœå°‹å’Œæ•´ç†æŠ€è¡“è³‡è¨Š",
        "system_prompt": """ä½ æ˜¯æŠ€è¡“ç ”ç©¶å“¡ã€‚
æœå°‹æœ€æ–°çš„æŠ€è¡“è³‡è¨Šã€æœ€ä½³å¯¦è¸ã€æ–‡ä»¶ã€‚
æ•´ç†æˆæ¸…æ™°çš„æ‘˜è¦ã€‚
ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"""
    },
    "explainer": {
        "description": "ç”¨æ¸…æ™°æ˜“æ‡‚çš„æ–¹å¼è§£é‡‹æŠ€è¡“æ¦‚å¿µ",
        "system_prompt": """ä½ æ˜¯æŠ€è¡“æ•™è‚²å°ˆå®¶ã€‚
ç”¨ä»¥ä¸‹æ–¹å¼è§£é‡‹æŠ€è¡“æ¦‚å¿µï¼š
- ä½¿ç”¨é¡æ¯”å’Œæ¯”å–»
- å¾ç°¡å–®åˆ°è¤‡é›œ
- æä¾›å…·é«”ç¯„ä¾‹

ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œè®“åˆå­¸è€…ä¹Ÿèƒ½ç†è§£ã€‚"""
    },
}


def get_worker_descriptions() -> str:
    """ç²å– Worker æè¿°"""
    lines = []
    for name, config in WORKERS.items():
        lines.append(f"- {name}: {config['description']}")
    return "\n".join(lines)


# ============================================================
# 2. ç‹€æ…‹å®šç¾©
# ============================================================

class MultiAgentState(TypedDict):
    """å¤š Agent ç³»çµ±ç‹€æ…‹"""
    messages: Annotated[list, add_messages]
    current_task: str
    subtasks: list[dict]  # [{worker, task, status, result}]
    next_worker: str | None
    iteration: int
    max_iterations: int
    final_answer: str | None


# ============================================================
# 3. Supervisor å¯¦ç¾
# ============================================================

class RouteDecision(BaseModel):
    """Supervisor çš„è·¯ç”±æ±ºç­–"""
    next_worker: Literal["coder", "reviewer", "researcher", "explainer", "FINISH"] = Field(
        description="ä¸‹ä¸€å€‹è¦åŸ·è¡Œçš„ Worker åç¨±ï¼Œæˆ– 'FINISH' è¡¨ç¤ºå®Œæˆ"
    )
    task_for_worker: str = Field(
        description="åˆ†é…çµ¦ Worker çš„å…·é«”ä»»å‹™æè¿°"
    )
    reasoning: str = Field(
        description="é¸æ“‡é€™å€‹ Worker çš„åŸå› "
    )


SUPERVISOR_PROMPT = f"""ä½ æ˜¯ä¸€å€‹ä»»å‹™å”èª¿è€… (Supervisor)ã€‚

ä½ ç®¡ç†ä»¥ä¸‹å°ˆæ¥­åœ˜éšŠæˆå“¡ï¼š
{get_worker_descriptions()}

ä½ çš„è·è²¬ï¼š
1. åˆ†æç”¨æˆ¶çš„è«‹æ±‚
2. æ±ºå®šéœ€è¦å“ªäº›åœ˜éšŠæˆå“¡å”åŠ©
3. åˆ†é…å…·é«”ä»»å‹™
4. ç•¶æ‰€æœ‰å¿…è¦å·¥ä½œå®Œæˆå¾Œï¼Œé¸æ“‡ 'FINISH'

æ±ºç­–åŸå‰‡ï¼š
- ç°¡å–®çš„æ¦‚å¿µå•é¡Œï¼šè®“ explainer è§£é‡‹
- éœ€è¦æŠ€è¡“è³‡è¨Šï¼šå…ˆè®“ researcher æœå°‹
- ç¨‹å¼ç¢¼ç›¸é—œï¼šè®“ coder è™•ç†
- éœ€è¦å¯©æŸ¥ï¼šè®“ reviewer æª¢æŸ¥

æ¯æ¬¡åªé¸æ“‡ä¸€å€‹ Workerã€‚
ä»»å‹™å®Œæˆå¾Œé¸æ“‡ 'FINISH'ã€‚"""


llm = ChatAnthropic(model="claude-3-5-sonnet-20241022")


def supervisor_node(state: MultiAgentState) -> dict:
    """Supervisor æ±ºç­–ç¯€é»"""
    structured_llm = llm.with_structured_output(RouteDecision)

    messages = [
        SystemMessage(content=SUPERVISOR_PROMPT),
        *state["messages"]
    ]

    # æ·»åŠ å·²å®Œæˆçš„å­ä»»å‹™è³‡è¨Š
    if state["subtasks"]:
        completed = [t for t in state["subtasks"] if t["status"] == "completed"]
        if completed:
            summary = "\n".join([
                f"- {t['worker']} å®Œæˆäº†ï¼š{t['result'][:100]}..."
                for t in completed
            ])
            messages.append(SystemMessage(
                content=f"å·²å®Œæˆçš„å­ä»»å‹™ï¼š\n{summary}\n\nç¾åœ¨æ±ºå®šä¸‹ä¸€æ­¥ã€‚"
            ))

    decision = structured_llm.invoke(messages)

    updates = {
        "iteration": state["iteration"] + 1
    }

    if decision.next_worker == "FINISH":
        updates["next_worker"] = None
    else:
        updates["next_worker"] = decision.next_worker
        new_subtask = {
            "worker": decision.next_worker,
            "task": decision.task_for_worker,
            "status": "pending",
            "result": None
        }
        updates["subtasks"] = state["subtasks"] + [new_subtask]
        updates["messages"] = [AIMessage(
            content=f"[Supervisor] åˆ†é…ä»»å‹™çµ¦ {decision.next_worker}ï¼š{decision.task_for_worker}"
        )]

    return updates


# ============================================================
# 4. Worker ç¯€é»
# ============================================================

def create_worker_node(worker_name: str):
    """å·¥å» å‡½æ•¸ï¼šå‰µå»º Worker ç¯€é»"""
    config = WORKERS[worker_name]

    def worker_node(state: MultiAgentState) -> dict:
        # ç²å–ç•¶å‰ä»»å‹™
        current_task = None
        task_index = -1
        for i, task in enumerate(state["subtasks"]):
            if task["worker"] == worker_name and task["status"] == "pending":
                current_task = task
                task_index = i
                break

        if not current_task:
            return {}

        # åŸ·è¡Œä»»å‹™
        messages = [
            SystemMessage(content=config["system_prompt"]),
            HumanMessage(content=current_task["task"])
        ]

        response = llm.invoke(messages)

        # æ›´æ–°å­ä»»å‹™
        updated_subtasks = state["subtasks"].copy()
        updated_subtasks[task_index] = {
            **current_task,
            "status": "completed",
            "result": response.content
        }

        return {
            "subtasks": updated_subtasks,
            "messages": [AIMessage(
                content=f"[{worker_name}] å®Œæˆä»»å‹™"
            )]
        }

    return worker_node


# ============================================================
# 5. æœ€çµ‚æ•´åˆç¯€é»
# ============================================================

def finalize_node(state: MultiAgentState) -> dict:
    """æ•´åˆæ‰€æœ‰çµæœ"""
    subtasks = state.get("subtasks", [])
    completed = [t for t in subtasks if t["status"] == "completed"]

    if not completed:
        return {"final_answer": "æŠ±æ­‰ï¼Œç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ã€‚"}

    # æ•´åˆçµæœ
    results_summary = "\n\n".join([
        f"## {t['worker']} çš„è²¢ç»\n{t['result']}"
        for t in completed
    ])

    # ä½¿ç”¨ LLM ç”Ÿæˆæœ€çµ‚å›ç­”
    synthesis_prompt = f"""è«‹æ•´åˆä»¥ä¸‹åœ˜éšŠæˆå“¡çš„å·¥ä½œçµæœï¼Œçµ¦ç”¨æˆ¶ä¸€å€‹å®Œæ•´ã€é€£è²«çš„å›ç­”ï¼š

{results_summary}

åŸå§‹è«‹æ±‚ï¼š{state['messages'][0].content}

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œä¿æŒå°ˆæ¥­ä½†å‹å–„çš„èªæ°£ã€‚"""

    response = llm.invoke([HumanMessage(content=synthesis_prompt)])

    return {
        "final_answer": response.content,
        "messages": [AIMessage(content=response.content)]
    }


# ============================================================
# 6. è·¯ç”±
# ============================================================

def route_supervisor(state: MultiAgentState) -> str:
    """Supervisor è·¯ç”±"""
    if state["iteration"] >= state["max_iterations"]:
        return "finalize"

    next_worker = state.get("next_worker")
    if next_worker is None:
        return "finalize"

    return next_worker


# ============================================================
# 7. çµ„è£ Graph
# ============================================================

def create_multi_agent_system():
    """å‰µå»ºå¤š Agent ç³»çµ±"""
    graph = StateGraph(MultiAgentState)

    # æ·»åŠ ç¯€é»
    graph.add_node("supervisor", supervisor_node)
    for worker_name in WORKERS:
        graph.add_node(worker_name, create_worker_node(worker_name))
    graph.add_node("finalize", finalize_node)

    # æ·»åŠ é‚Š
    graph.add_edge(START, "supervisor")

    graph.add_conditional_edges(
        "supervisor",
        route_supervisor,
        {
            **{name: name for name in WORKERS},
            "finalize": "finalize"
        }
    )

    for worker_name in WORKERS:
        graph.add_edge(worker_name, "supervisor")

    graph.add_edge("finalize", END)

    return graph.compile()


# ============================================================
# 8. æ¼”ç¤º
# ============================================================

def run_demo(query: str):
    """é‹è¡Œæ¼”ç¤º"""
    app = create_multi_agent_system()

    initial = {
        "messages": [HumanMessage(content=query)],
        "current_task": query,
        "subtasks": [],
        "next_worker": None,
        "iteration": 0,
        "max_iterations": 10,
        "final_answer": None,
    }

    print(f"\n{'=' * 60}")
    print(f"å•é¡Œï¼š{query}")
    print("=" * 60)
    print("\nğŸ”„ åœ˜éšŠå”ä½œä¸­...\n")

    for event in app.stream(initial):
        for node, output in event.items():
            if node == "supervisor":
                next_w = output.get("next_worker")
                if next_w:
                    print(f"  ğŸ“‹ Supervisor â†’ {next_w}")
            elif node in WORKERS:
                print(f"  âœ… {node} å®Œæˆä»»å‹™")
            elif node == "finalize":
                pass  # æœ€å¾Œè¼¸å‡º

    # ç²å–æœ€çµ‚çµæœ
    result = app.invoke(initial)
    print(f"\nğŸ“– æœ€çµ‚å›ç­”ï¼š\n{'-' * 40}")
    print(result["final_answer"])


def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 60)
    print("å¤š Agent ç³»çµ±æ¼”ç¤º (Supervisor Pattern)")
    print("=" * 60)

    # æ¸¬è©¦æ¡ˆä¾‹
    test_cases = [
        "ä»€éº¼æ˜¯ REST APIï¼Ÿè«‹ç°¡å–®è§£é‡‹ã€‚",
        "å¹«æˆ‘å¯«ä¸€å€‹ Python å‡½æ•¸ä¾†è¨ˆç®—éšä¹˜",
        "æ¯”è¼ƒ Docker å’Œ Kubernetes çš„å·®ç•°",
    ]

    for query in test_cases:
        run_demo(query)
        print("\n")


if __name__ == "__main__":
    main()
